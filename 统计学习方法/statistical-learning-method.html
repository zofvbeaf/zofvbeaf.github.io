<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">






  
  
  <link rel="stylesheet" media="all" href="/lib/Han/dist/han.min.css?v=3.3">




<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">




  
  
  
  

  
    
    
  

  

  

  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="统计学习方法,machine learning,book,">










<meta name="description" content="前言 只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向 学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 — Herbert A. Simon  1.统计学习 统计学习的特点，对象，目的，方法，研究 本章主要将监督学习  监督学习 从给定有限的训练数据出发, 假定数据是独立同分布的, 而且假设模型属于某个假设空间, 应用某一评价准则, 从假设空间中选取一个最优的模型, 使">
<meta name="keywords" content="统计学习方法,machine learning,book">
<meta property="og:type" content="article">
<meta property="og:title" content="《统计学习方法》">
<meta property="og:url" content="http://zofvbeaf.github.io/统计学习方法/statistical-learning-method.html">
<meta property="og:site_name" content="ZOFVBEAF&#39;S BLOG">
<meta property="og:description" content="前言 只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向 学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 — Herbert A. Simon  1.统计学习 统计学习的特点，对象，目的，方法，研究 本章主要将监督学习  监督学习 从给定有限的训练数据出发, 假定数据是独立同分布的, 而且假设模型属于某个假设空间, 应用某一评价准则, 从假设空间中选取一个最优的模型, 使">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2019-06-27T07:11:06.311Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="《统计学习方法》">
<meta name="twitter:description" content="前言 只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向 学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 — Herbert A. Simon  1.统计学习 统计学习的特点，对象，目的，方法，研究 本章主要将监督学习  监督学习 从给定有限的训练数据出发, 假定数据是独立同分布的, 而且假设模型属于某个假设空间, 应用某一评价准则, 从假设空间中选取一个最优的模型, 使">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://zofvbeaf.github.io/统计学习方法/statistical-learning-method.html">





  <title>《统计学习方法》 | ZOFVBEAF'S BLOG</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">ZOFVBEAF'S BLOG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <h1 class="site-subtitle" itemprop="description">Bazinga !</h1>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://zofvbeaf.github.io/统计学习方法/statistical-learning-method.html">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zofvbeaf">
      <meta itemprop="description" content="浮世梦中梦，布衣裁不裁，弹狭狂歌莫浪猜。埋，贤愚何用哉。青山在，月明归去来。">
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="ZOFVBEAF'S BLOG">
    </span>

    
      <header class="post-header">

        
        
          <h2 class="post-title" itemprop="name headline">《统计学习方法》</h2>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-09T10:51:47+08:00">
                2018-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/统计学习方法/" itemprop="url" rel="index">
                    <span itemprop="name">统计学习方法</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body han-init-context" itemprop="articleBody">

      
      

      
        <h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><ul>
<li>只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向</li>
<li>学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 — Herbert A. Simon</li>
</ul>
<h1 id="1-统计学习"><a href="#1-统计学习" class="headerlink" title="1.统计学习"></a>1.统计学习</h1><ul>
<li>统计学习的特点，对象，目的，方法，研究</li>
<li>本章主要将监督学习</li>
</ul>
<h2 id="监督学习"><a href="#监督学习" class="headerlink" title="监督学习"></a>监督学习</h2><ul>
<li>从给定有限的训练数据出发, 假定数据是独立同分布的, 而且假设模型属于某个假设空间, 应用某一评价准则, 从假设空间中选取一个最优的模型, 使它对已给训练数据及未知测试数据再给定评价标准意义下有最准确的预测.</li>
<li>基本概念：<strong>input space, output space, feature space</strong></li>
<li>其它名词：<strong>instance, feature vector, 联合概率分布</strong></li>
<li>假设空间: $ \mathcal{F} = \{ f\;|  \mathit{Y} = f(X) \} $</li>
<li>最终变成求 $\min\limits_{f\in\mathcal{F}}R_{emp}(f)$ 或 $min_{f\in\mathcal{F}}R_{srm}(f)$ 的问题</li>
</ul>
<a id="more"></a>
<h2 id="统计学习三要素"><a href="#统计学习三要素" class="headerlink" title="统计学习三要素"></a>统计学习三要素</h2><ul>
<li>方法 = 模型 + 策略 + 算法</li>
</ul>
<h3 id="策略"><a href="#策略" class="headerlink" title="策略"></a>策略</h3><ul>
<li>损失函数: 0-1, quadratic, absolute, logarithmic</li>
<li>风险函数(期望损失): $ R_{exp}(f) = E_{p}[L(Y, f(X))] = \int_{x\times y}L(y, f(x))P(x,y)dxdy $</li>
<li>经验风险(经验损失)(empirical loss): $\displaystyle R_{emp}(f) = \frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i)) $</li>
<li>根据大数定理, 可用$R_{emp}(f)$估计$R_{exp}(f)$, 但由于现实中样本有限, 甚至很少，所以需要矫正$R_{emp}(f)$</li>
<li>经验风险最小化(ERM)和结构风险最小化(SRM)<ul>
<li>ERM: 用最优化方法求解$\min\limits_{f\in\mathcal{F}}R_{emp}(f)$<ul>
<li>样本容量很小时容易过拟合(over-fitting), 但样本容量大时，学习效果很好</li>
<li>当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计(MLE)(<a href="http://datahonor.com/2017/03/03/最大似然估计与经验风险最小化/" target="_blank" rel="noopener">证明</a>). </li>
</ul>
</li>
<li>SRM: 等价于正则化(regularizer), 即求 $\min\limits_{f\in\mathcal{F}}R_{srm}(f)$<ul>
<li>结构风险: $\displaystyle R_{srm}(f) = R_{emp}(f) + \lambda J(f)$ <ul>
<li>其中 $\lambda J(f)$ 位正则化项或罚项(penalty term)</li>
<li>$J(f)$是模型空间复杂度, 为定义在$\mathcal{F}$上的泛函. $f$越复杂, $J(f)$越大.</li>
<li>$\lambda \ge 0$是系数, 用以权衡经验风险和模型复杂度</li>
<li>$R_{srm}(f)$小要求$R_{emp}(f)$和$J(f)$同时小, $R_{srm}(f)$小的模型往往对训练数据以及未知的测试数据都有较好的预测</li>
<li>当模型是条件概率分布, 损失函数是对数损失函数, 模型复杂度由模型的先验概率分布表示时，结构风险最小化就等价于最大后验概率估计(MAP)(证明)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="模型评估与选择"><a href="#模型评估与选择" class="headerlink" title="模型评估与选择"></a>模型评估与选择</h2><ul>
<li>训练误差(<strong>tranning error</strong>): 模型关于训练数据集的平均损失</li>
<li>测试误差(<strong>test error</strong>): 模型关于测试数据集的平均损失, 反映了模型的预测能力(泛化能力 <strong>generalization ability</strong>)</li>
<li>过拟合: 所选模型参数过多, 对训练数据预测的很好, 对测试数据预测的很差</li>
<li>模型选择时要选择复杂度适当的模型, 防止过拟合.</li>
</ul>
<h2 id="正则化与交叉验证"><a href="#正则化与交叉验证" class="headerlink" title="正则化与交叉验证"></a>正则化与交叉验证</h2><ul>
<li>此为常用的两种模型选择方法</li>
</ul>
<h3 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h3><ul>
<li>$\min\limits_{f\in\mathcal{F}}R_{srm}(f)$</li>
<li>正则化项: 一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大<blockquote>
<p>如参数向量$w$的$L_1$范数$\parallel w_1 \parallel$或$L_2$范数$\frac{1}{2}\parallel w_1 \parallel^2$</p>
</blockquote>
</li>
<li>模型越复杂, 先验概率越大</li>
</ul>
<h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><ul>
<li>样本充足时, 可随机切成训练集(用于训练模型), 验证集(用于模型选择, 选择预测误差最小的模型)和测试集(模型评估)</li>
<li>交叉验证: 重复使用数据, 反复切, 反复训练, 测试及模型选择</li>
<li>简单交叉验证: 随机切成训练集和测试集, 选测试误差最小的模型</li>
<li>$S$折交叉验证(S-fold cross validation): 切成$S$份, 每次选$S-1$份训练, $1$份测试, 重复$S$次</li>
<li>留一交叉验证: $S=N$, 数据集为$N$, 数据集较少时用</li>
</ul>
<h2 id="泛化能力"><a href="#泛化能力" class="headerlink" title="泛化能力"></a>泛化能力</h2><ul>
<li>即模型$\hat{f}$的预测能力, 用$R_{exp}(\hat{f})$来表示</li>
<li>泛化误差上界: $R(f) \le \hat{R}(f) + \varepsilon(d, N, \delta)$<blockquote>
<p>$R(f)$为泛化误差<br>$\le$右边为泛化误差上界<br>$\hat{R}(f)$为训练误差<br>$\varepsilon(d, N, \delta) = \sqrt{\frac{1}{2N}(\log d + \log \frac{1}{\delta})}$</p>
</blockquote>
</li>
<li>训练误差小的模型, 泛化误差也会小</li>
</ul>
<h2 id="生成模型与判别模型"><a href="#生成模型与判别模型" class="headerlink" title="生成模型与判别模型"></a>生成模型与判别模型</h2><ul>
<li>监督学习的方法可以分为: 生成方法(<strong>generative approach</strong>)和判别方法(<strong>discriminative approach</strong>)</li>
<li>生成方法: 先学习$P(X,Y)$再求出$P(Y|X) = \frac{P(X,Y)}{P(X)}$<blockquote>
<p>如:朴素贝叶斯法和隐马尔可夫模型</p>
</blockquote>
</li>
<li>判别方法: 直接学习$f(X)$或$P(Y|X)$<blockquote>
<p>如:$k$近邻法, 感知机, 决策树,  逻辑斯蒂回归模型, 最大熵模型, 支持向量机, 提升方法和条件随机场等<br>存在隐变量时, 判别方法不能用</p>
</blockquote>
</li>
</ul>
<h2 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h2><ul>
<li>$P(Y|X)$作为分类器 </li>
<li>分类准确率(<strong>accuracy</strong>): 对于给定的测试数据集, 分类正确的样本数与总样本数之比</li>
<li>精确率(<strong>precision</strong>):$P = \frac{TP}{TP+FP}$ <blockquote>
<p>True, False, Positive, Negative</p>
</blockquote>
</li>
<li>召回率(<strong>recall</strong>): $R = \frac{TP}{TP+FN}$</li>
<li>$P$和$R$的调和均值$F_1$: $\frac{1}{F_1} = \frac{1}{P} + \frac{1}{R}$, 即$F_1 = \frac{2TP}{2TP+FP+FN}$</li>
<li>许多统计学习方法可以用于分类<blockquote>
<p>如: $k$近邻法, 感知机, 朴素贝叶斯法, 决策树, 决策列表, 逻辑斯蒂回归模型, 支持向量机, 提升方法, 贝叶斯网络, 神经网络, Winnow等</p>
</blockquote>
</li>
</ul>
<h2 id="标注-tagging-问题"><a href="#标注-tagging-问题" class="headerlink" title="标注(tagging)问题"></a>标注(tagging)问题</h2><ul>
<li>可以认为书分类问题的推广，也是更复杂的结构预测(<strong>structure prediction</strong>)问题的简单形式</li>
<li>输入一个观测序列$x_{N+1} = (x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, … ,x_{N+1}^{(n)})^T$, 找到使条件概率$$P((y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, … ,y_{N+1}^{(n)})|(x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, … ,x_{N+1}^{(n)})$$最大的标记序列$y_{N+1} = (y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, … ,y_{N+1}^{(n)})^T$<blockquote>
<p>常用的标注方法:隐马尔科夫模型`和条件随机场</p>
</blockquote>
</li>
</ul>
<h2 id="回归问题"><a href="#回归问题" class="headerlink" title="回归问题"></a>回归问题</h2><ul>
<li>等价于函数拟合: 选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据</li>
<li>分类<blockquote>
<p>按输入变量的个数: 一元回归和多元回归<br>输入与输出变量的关系模型: 线性回归和非线性回归<br>损失函数是平方损失函数时: 可用最小二乘法(<strong>least squares</strong>)求解</p>
</blockquote>
</li>
</ul>
<h1 id="2-感知机-preceptron"><a href="#2-感知机-preceptron" class="headerlink" title="2.感知机(preceptron)"></a>2.感知机(preceptron)</h1><blockquote>
<p>属于判别模型, 输入为实例的特征向量, 输出为实例的类别<br>是一种线性分类模型</p>
</blockquote>
<h2 id="感知机模型"><a href="#感知机模型" class="headerlink" title="感知机模型"></a>感知机模型</h2><ul>
<li>$f(x) = sign(\omega\cdot x + b), 其中sign(x) = \begin{cases} +1, &amp;{x \ge 0} \\ -1, &amp;{x \lt 0} \end{cases} $</li>
<li>线性分类器: $f(x) = \lbrace f|f(x) = \omega\cdot x + b \rbrace$</li>
</ul>
<h2 id="感知机学习策略"><a href="#感知机学习策略" class="headerlink" title="感知机学习策略"></a>感知机学习策略</h2><ul>
<li>数据集的线性可分性: 存在某个超平面$ S: \omega\cdot x + b = 0 $能够将数据集的正实例点和负实例点完全正确的划分到超平面的两侧<blockquote>
<p>即对所有实例$i$有: $y_i = \begin{cases} +1, &amp;{\omega\cdot x + b \ge 0} \\ -1, &amp;{\omega\cdot x + b\lt 0} \end{cases} $</p>
</blockquote>
</li>
<li>感知机就是要找出这样一个超平面，即确定$\omega$和$b$, 定义(经验)损失函数并将损失函数极小化<blockquote>
<p>损失函数: $\displaystyle L(\omega, b) = -\sum_{x_i \in M} y_i(\omega\cdot x_i + b)$<br>其中$M$为所有误分类点的集合</p>
</blockquote>
</li>
</ul>
<h2 id="感知机学习算法"><a href="#感知机学习算法" class="headerlink" title="感知机学习算法"></a>感知机学习算法</h2><ul>
<li>即求解$\displaystyle \min_{\omega, b} L(\omega, b)$的最优化问题<blockquote>
<p>任意选取一个超平面$\omega_0, b_0$, 然后用梯度下降法不断地极小化目标函数<br>选取$y_i(\omega\cdot x_i + b) \le 0$<br>$$ \omega \gets \omega + \eta y_i x_i$$ $$ b \gets b + \eta y_i $$<br>$\eta(0\le\eta\lt 0)$是步长, 又称为学习率</p>
</blockquote>
</li>
<li>算法的收敛性证明<blockquote>
<p>即证明: 设数据集是线性可分的, 经过有限次迭代可以得到一个将训练数据集完全正确划分的分离超平面及感知机模型<br>最终得到误分类次数$k \le (\frac{R}{\gamma})^2$, 其中$\displaystyle R = \max_{1\le i \le N}\parallel \hat{x}_i \parallel$<br>当训练集线性不可分时, 算法不收敛, 迭代结果会发生震荡</p>
</blockquote>
</li>
<li>对偶形式<blockquote>
<p>感知机模型$\displaystyle f(x) = sign(\sum_{j=1}^N \alpha_j y_j x_j\cdot x + b)$<br>其中$\alpha_i = n_i\eta$, 且迭代过程为: $\begin{cases} \alpha_i &amp; \gets \alpha_i + \eta \\ b &amp; \gets b + \eta y_i \end{cases}$</p>
</blockquote>
</li>
</ul>
<h1 id="3-k-NN-k-nearest-neighbor"><a href="#3-k-NN-k-nearest-neighbor" class="headerlink" title="3.$k$-NN ($k$-nearest neighbor)"></a>3.$k$-NN ($k$-nearest neighbor)</h1><blockquote>
<p>一种基本的分类与回归的方法</p>
</blockquote>
<h2 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h2><ul>
<li>实例 $x$ 所属的类$y$, 有:<br>$$\displaystyle y = \arg\max_{c_j}\sum_{x_i \in N_k(x)} I(y_i = c_j), \;\;\;\; i = 1,2,\cdots ,N; \;\; j=1,2,\cdots ,K$$</li>
<li>$k=1$时为最近邻法</li>
</ul>
<h2 id="k-近邻模型"><a href="#k-近邻模型" class="headerlink" title="$k$近邻模型"></a>$k$近邻模型</h2><ul>
<li>模型三要素: 距离度量, $k$值的选择和分类决策规则的确定</li>
<li>距离度量<ul>
<li>一般用欧式距离, 也可以是其它距离, 如$L_p$距离(Minkowski距离): $\displaystyle L_p(x_i, x_j) = \left(\sum_{l = 1}^n |x_i^{(l)} - x_j^{(l)}|^p\right)^{\frac{1}{p}}$<blockquote>
<p>欧式距离: $p=2$<br>曼哈顿距离: $p=1$<br>各个坐标距离的最大值: $p=\infty$</p>
</blockquote>
</li>
</ul>
</li>
<li>$k$的选择<ul>
<li>较小: 近似误差小, 估计误差大</li>
<li>较大: 近似误差大, 估计误差小</li>
<li>应用中通常选取较小的$k$值, 采用交叉验证法选取最优的$k$值</li>
</ul>
</li>
<li>分类决策规则<ul>
<li>经验风险最小化: 即$\displaystyle \sum_{x_i \in N_k(x)} I(y_i = c_j)$最大化</li>
</ul>
</li>
</ul>
<h2 id="k-近邻法的实现-kd-树"><a href="#k-近邻法的实现-kd-树" class="headerlink" title="$k$近邻法的实现: $kd$树"></a>$k$近邻法的实现: $kd$树</h2><ul>
<li>$kd$树是一种对$k$维空间进行存储以便对其进行快速检索的树形数据结构.</li>
<li>$kd$树的每个节点对应于一个$k$维超矩形区域.</li>
<li>此处的$k$与$k$近邻法的$k$不同.</li>
<li>$kd$树搜索的平均时间复杂度为$O(\log N)$, 更适用于训练实例数远大于空间维数时的$k$近邻搜索.</li>
<li>当空间维数接近训练实例数时, 它的效率会迅速下降, 几乎接近线性扫描.</li>
</ul>
<h1 id="4-朴素贝叶斯法"><a href="#4-朴素贝叶斯法" class="headerlink" title="4.朴素贝叶斯法 "></a>4.朴素贝叶斯法 </h1><ul>
<li>朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法 </li>
<li>朴素贝叶斯法与贝叶斯估计时不同的概念</li>
</ul>
<h2 id="朴素贝叶斯法的学习与分类"><a href="#朴素贝叶斯法的学习与分类" class="headerlink" title="朴素贝叶斯法的学习与分类"></a>朴素贝叶斯法的学习与分类</h2><ul>
<li>朴素贝叶斯分类器可以表示为:<br>$$\displaystyle y = \arg\max_{c_k} P(Y=c_k) \prod_j P(X^{(j)}=x^{(j)}|Y=c_k) $$   </li>
<li>即后验概率最大化</li>
<li>后验概率最大化的含义: 根据期望风险最小化准则可以得到后验概率最大化准则 </li>
</ul>
<h2 id="朴素贝叶斯法的参数估计"><a href="#朴素贝叶斯法的参数估计" class="headerlink" title="朴素贝叶斯法的参数估计"></a>朴素贝叶斯法的参数估计</h2><ul>
<li><p>极大似然法</p>
<ul>
<li>在朴素贝叶斯法中, 学习意味着估计$P(Y=c_k)$和$P(X^{(j)}=x^{(j)}|Y=c_k)$</li>
<li>先验概率$P(Y=c_k)$的极大似然估计为: $\displaystyle P(Y=c_k) = \frac{\displaystyle\sum_{i=1}^N I(y_i = c_k)}{N}, \;\; k=1,2,\cdots,K$</li>
<li>设第$j$个特征$x^{(j)}$可能取值的集合为$\lbrace a_j1, a_j2, \cdots, a_{jS_j} \rbrace$, 条件概率$P(x^{(j)}=a_{jl} |y=c_k)$的极大似然估计是:<br>$$P(X^{(j)}=a_{jl} |Y=c_k) = \frac{\displaystyle \sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k)}{\displaystyle\sum_{i=1}^N I(y_i = c_k)}$$<br>$$j=1,2,\cdots,n; \;\; l=1,2,\cdots,S_j; \;\; k=1,2,\cdots,K$$</li>
</ul>
</li>
<li><p>朴素贝叶斯算法</p>
</li>
<li>贝叶斯估计:<blockquote>
<p>极大似然估计可能出现所要估计的概率为$0$的情况, 这会影响到后验概率的计算结果, 使分类产生偏差, 解决这一问题的方法是采用贝叶斯估计<br>$$P_\lambda (X^{(j)}=a_{jl} |Y=c_k) = \frac{\displaystyle \sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k) + \lambda}{\displaystyle\sum_{i=1}^N I(y_i = c_k) + S_j \lambda } \;\;\;\;$$<br>$$P_\lambda (Y=c_k) = \frac{\displaystyle\sum_{i=1}^N I(y_i = c_k) + \lambda}{N + K\lambda}$$<br>其中$\lambda \ge 0$, $\lambda = 0$是极大似然估计, $\lambda = 1$是拉普拉斯平滑(<strong>Laplace smoothing</strong>)</p>
</blockquote>
</li>
</ul>
<h1 id="5-决策树"><a href="#5-决策树" class="headerlink" title="5.决策树"></a>5.决策树</h1><ul>
<li>决策树是一种基本的分类与回归方法</li>
<li>本质上是从训练数据集归纳出一组分类规则</li>
<li>决策树学习通常包括三个步骤: 特征选择, 决策树的生成和决策树的修剪</li>
<li>内部节点表示一个特征或属性, 叶节点表示一个类</li>
</ul>
<h2 id="决策树模型与学习"><a href="#决策树模型与学习" class="headerlink" title="决策树模型与学习"></a>决策树模型与学习</h2><ul>
<li>损失函数通常是正则化的极大似然函数</li>
<li>需要自下而上进行剪枝, 去掉过于细分的叶节点, 使其回退到父节点, 甚至更高的节点, 避免过拟合, 使其有更好的泛化能力</li>
<li>决策树的生成只考虑局部最优, 决策树的生成则考虑全局最优</li>
</ul>
<h2 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h2><ul>
<li>通常的特征选择的准则是信息增益或信息增益比</li>
<li>熵(<strong>entropy</strong>): $\displaystyle H(p) = \sum_{i=1}^n p_i \log p_i$</li>
<li>条件熵(<strong>conditional entropy</strong>): $\displaystyle H(Y|X) = \sum_{i=1}^n p_i H(Y|X=x_i)$</li>
<li>当熵和条件熵中的概率由数据估计(特别是极大似然估计得到)时, 所对应的熵与条件熵分别称为经验熵与经验条件熵</li>
<li>信息增益表示得知特征$X$的信息而使得类$Y$的信息的不确定性减少的程度</li>
<li>特征$A$对训练数据集$D$的信息增益$g(D,A) = H(D) - H(D|A)$, 也成为互信息(<strong>mutual information</strong>)</li>
<li>信息增益比:<br>$$g_R (D,A) = \frac{g(D,A)}{H_A(D)}$$<br>其中，$H_A (D)$表示训练数据集$D$关于特征$A$的值的熵<br>$$\displaystyle H_A (D) = -\sum_{i=1}^n \frac{|D_i|}{D} \log_2 \frac{|D_i|}{D}$$</li>
</ul>
<h2 id="决策树的生成"><a href="#决策树的生成" class="headerlink" title="决策树的生成"></a>决策树的生成</h2><h3 id="ID3算法"><a href="#ID3算法" class="headerlink" title="ID3算法"></a>ID3算法</h3><blockquote>
<p>输入: 训练数据集D, 特征集A, 阈值\varepsilon<br>每次选择$ g(D,A) $最大的特征点递归构建, 直到所有特征的$g(D,A)$均很小($\lt\varepsilon$)或没有特征可以选择为止</p>
</blockquote>
<h3 id="C4-5算法"><a href="#C4-5算法" class="headerlink" title="C4.5算法"></a>C4.5算法</h3><ul>
<li>用信息增益比来选择特征</li>
</ul>
<h2 id="决策树的剪枝"><a href="#决策树的剪枝" class="headerlink" title="决策树的剪枝"></a>决策树的剪枝</h2><ul>
<li>损失函数: $C_\alpha (T) = C(T) + \alpha |T|$, 其中<br>$$\displaystyle C(T) = \sum_{t=1}^{|T|}N_t H_t (T) \;\;\;\;\;  H_t (T) = -\sum_k \frac{N_{tk}}{N_t} \log \frac{N_{tk}}{N_t}$$<br>$N_{tk}$表示树$T$的某一叶节点$t$的第$k$类样本点的数量</li>
<li>若一组叶节点回缩前后的树分别为$T_B$和$T_A$, 当$C_\alpha (T_A) \le C_\alpha (T_B)$时进行剪枝, 将父节点变为新的叶节点</li>
<li>利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择 </li>
</ul>
<h2 id="CART算法"><a href="#CART算法" class="headerlink" title="CART算法"></a>CART算法</h2><blockquote>
<p>分类与回归树(Classification and Regression Trees)<br>递归构建二叉决策树再剪枝<br>具体见《统计学习方法》</p>
</blockquote>
<h3 id="CART生成"><a href="#CART生成" class="headerlink" title="CART生成"></a>CART生成</h3><ul>
<li>回归树的生成: 用平方误差最小化准则, 最小二乘回归树生成算法</li>
<li>分类树的生成: 用基尼系数选择最优特征, 同时决定该特征的最优二值切分点</li>
</ul>
<h3 id="CART剪枝"><a href="#CART剪枝" class="headerlink" title="CART剪枝"></a>CART剪枝</h3><ul>
<li>首先从生成算法产生的决策树$T_0$底端开始不断剪枝, 直到$T_0$的根节点, 形成一个子树序列$\lbrace T_0, T_1, \cdots, T_n \rbrace$;<br>然后通过交叉验证法再独立的验证数据集上对子树序列进行测试, 从中选择最优子树</li>
</ul>
<h1 id="6-逻辑斯蒂回归与最大熵模型"><a href="#6-逻辑斯蒂回归与最大熵模型" class="headerlink" title="6.逻辑斯蒂回归与最大熵模型"></a>6.逻辑斯蒂回归与最大熵模型</h1><blockquote>
<p>逻辑斯蒂回归(<strong>logistic regression</strong>)是统计学习中的经典<strong>分类</strong>方法<br>最大熵是概率学习的一个准则, 将其推广到分类问题得到最大熵模型(<strong>maximum entropy model</strong>)<br>两者都属于对数线性模型</p>
</blockquote>
<h2 id="逻辑斯蒂回归"><a href="#逻辑斯蒂回归" class="headerlink" title="逻辑斯蒂回归"></a>逻辑斯蒂回归</h2><ul>
<li>设$X$是连续随机变量, $X$服从逻辑斯蒂分布是指$X$具有下列分布函数和密度函数:<br>$$ F(x) = P(X \le x) = \frac{1}{1+e^{-(x-\mu)/\gamma}} $$<br>$$ f(x) = F’(x) = \frac{e^{-(x-\mu)/\gamma}}{\gamma(1+e^{-(x-\mu)/\gamma})^2} $$</li>
<li>该曲线是以点$(\mu, \frac{1}{2})$为中心堆成的$S$型曲线</li>
</ul>
<h1 id="7-支持向量机"><a href="#7-支持向量机" class="headerlink" title="7.支持向量机"></a>7.支持向量机</h1><blockquote>
<p>支持向量机(<strong>support vector machines SVM</strong>)是一种二分类模型</p>
</blockquote>
<h2 id="线性可分支持向量机与硬间隔最大化"><a href="#线性可分支持向量机与硬间隔最大化" class="headerlink" title="线性可分支持向量机与硬间隔最大化"></a>线性可分支持向量机与硬间隔最大化</h2><ul>
<li>线性可分支持向量机<blockquote>
<p>给定线性可分的训练数据集, 通过间隔最大化或等价地求解相应的凸二次规划问题学习得到的分离超平面为 $$ w^\ast \cdot x + b^\ast = 0 $$ 以及相应的分类决策函数 $$ f(x) = sign(w^\ast \cdot x + b^\ast) $$ 称为线性可分支持向量机</p>
</blockquote>
</li>
<li>函数间隔: <blockquote>
<p>对于给定的训练数据集$T$和超平面$(w,b)$, 定义超平面$(w,b)$关于样本点$(x_i, y_i)$的函数间隔为$$\hat{\gamma_i} = y_i(w\dot x_i + b)$$<br>定义超平面$(w,b)$关于训练数据集$T$函数间隔为超平面$(w,b)$关于$T$中所有样本点$(x_i, y_i)$的函数间隔之最小值, 即$$\displaystyle \hat{\gamma} =  \min_{i=1,2,\cdots,N} \hat{\gamma_i}$$</p>
</blockquote>
</li>
<li>几何间隔: $$\gamma_i = y_i\left(\frac{w}{\parallel w \parallel} \cdot x_i + \frac{b}{\parallel w \parallel} \right)$$ $$\displaystyle \gamma = \min_{i=1,2,\cdots,N} \gamma_i$$</li>
<li>间隔最大化</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/统计学习方法/" rel="tag"><i class="fa fa-tag"></i> 统计学习方法</a>
          
            <a href="/tags/machine-learning/" rel="tag"><i class="fa fa-tag"></i> machine learning</a>
          
            <a href="/tags/book/" rel="tag"><i class="fa fa-tag"></i> book</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/paper-reading/Self-Driving-Database-Management-Systems.html" rel="next" title="Self-Driving Database Management Systems (CIDR’17)">
                <i class="fa fa-chevron-left"></i> Self-Driving Database Management Systems (CIDR’17)
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/database/tpch.html" rel="prev" title="TPCH test scripts">
                TPCH test scripts <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="zofvbeaf">
            
              <p class="site-author-name" itemprop="name">zofvbeaf</p>
              <p class="site-description motion-element" itemprop="description">浮世梦中梦，布衣裁不裁，弹狭狂歌莫浪猜。埋，贤愚何用哉。青山在，月明归去来。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/zofvbeaf" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:zofvbeaf@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#前言"><span class="nav-number">1.</span> <span class="nav-text">前言</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#1-统计学习"><span class="nav-number">2.</span> <span class="nav-text">1.统计学习</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#监督学习"><span class="nav-number">2.1.</span> <span class="nav-text">监督学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#统计学习三要素"><span class="nav-number">2.2.</span> <span class="nav-text">统计学习三要素</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#策略"><span class="nav-number">2.2.1.</span> <span class="nav-text">策略</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#模型评估与选择"><span class="nav-number">2.3.</span> <span class="nav-text">模型评估与选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化与交叉验证"><span class="nav-number">2.4.</span> <span class="nav-text">正则化与交叉验证</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#正则化"><span class="nav-number">2.4.1.</span> <span class="nav-text">正则化</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#交叉验证"><span class="nav-number">2.4.2.</span> <span class="nav-text">交叉验证</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#泛化能力"><span class="nav-number">2.5.</span> <span class="nav-text">泛化能力</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#生成模型与判别模型"><span class="nav-number">2.6.</span> <span class="nav-text">生成模型与判别模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#分类问题"><span class="nav-number">2.7.</span> <span class="nav-text">分类问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#标注-tagging-问题"><span class="nav-number">2.8.</span> <span class="nav-text">标注(tagging)问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#回归问题"><span class="nav-number">2.9.</span> <span class="nav-text">回归问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-感知机-preceptron"><span class="nav-number">3.</span> <span class="nav-text">2.感知机(preceptron)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#感知机模型"><span class="nav-number">3.1.</span> <span class="nav-text">感知机模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#感知机学习策略"><span class="nav-number">3.2.</span> <span class="nav-text">感知机学习策略</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#感知机学习算法"><span class="nav-number">3.3.</span> <span class="nav-text">感知机学习算法</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-k-NN-k-nearest-neighbor"><span class="nav-number">4.</span> <span class="nav-text">3.$k$-NN ($k$-nearest neighbor)</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#算法"><span class="nav-number">4.1.</span> <span class="nav-text">算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#k-近邻模型"><span class="nav-number">4.2.</span> <span class="nav-text">$k$近邻模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#k-近邻法的实现-kd-树"><span class="nav-number">4.3.</span> <span class="nav-text">$k$近邻法的实现: $kd$树</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-朴素贝叶斯法"><span class="nav-number">5.</span> <span class="nav-text">4.朴素贝叶斯法 </span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#朴素贝叶斯法的学习与分类"><span class="nav-number">5.1.</span> <span class="nav-text">朴素贝叶斯法的学习与分类</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#朴素贝叶斯法的参数估计"><span class="nav-number">5.2.</span> <span class="nav-text">朴素贝叶斯法的参数估计</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-决策树"><span class="nav-number">6.</span> <span class="nav-text">5.决策树</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树模型与学习"><span class="nav-number">6.1.</span> <span class="nav-text">决策树模型与学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特征选择"><span class="nav-number">6.2.</span> <span class="nav-text">特征选择</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树的生成"><span class="nav-number">6.3.</span> <span class="nav-text">决策树的生成</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#ID3算法"><span class="nav-number">6.3.1.</span> <span class="nav-text">ID3算法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#C4-5算法"><span class="nav-number">6.3.2.</span> <span class="nav-text">C4.5算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树的剪枝"><span class="nav-number">6.4.</span> <span class="nav-text">决策树的剪枝</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CART算法"><span class="nav-number">6.5.</span> <span class="nav-text">CART算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#CART生成"><span class="nav-number">6.5.1.</span> <span class="nav-text">CART生成</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CART剪枝"><span class="nav-number">6.5.2.</span> <span class="nav-text">CART剪枝</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-逻辑斯蒂回归与最大熵模型"><span class="nav-number">7.</span> <span class="nav-text">6.逻辑斯蒂回归与最大熵模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑斯蒂回归"><span class="nav-number">7.1.</span> <span class="nav-text">逻辑斯蒂回归</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-支持向量机"><span class="nav-number">8.</span> <span class="nav-text">7.支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#线性可分支持向量机与硬间隔最大化"><span class="nav-number">8.1.</span> <span class="nav-text">线性可分支持向量机与硬间隔最大化</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zofvbeaf</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>
  <div class="powered-by">
  <i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
    Visitors:<span id="busuanzi_value_site_uv"></span>
  </span>
  </div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>



  <div class="footer-custom">Hosted by <a target="_blank" href="https://pages.github.com">GitHub Pages</a></div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

  <script type="text/javascript" src="/js/src/love.js"></script>
  
  <script type="text/javascript" src="//cdn.bootcss.com/canvas-nest.js/1.0.0/canvas-nest.min.js"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  

</body>
</html>
