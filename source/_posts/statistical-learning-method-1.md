---
title: 《统计学习方法》一. 概论
tags:
  - 统计学习方法
  - machine learning
  - book
categories:
  - 统计学习方法
date: 2018-11-07 21:04:54
mathjax: true
---

前言
===========
+ 只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向
+ 学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 --- Herbert A. Simon


统计学习
===========
+ 统计学习的特点，对象，目的，方法，研究
+ 本章主要将监督学习

## 监督学习
+ 从给定有限的训练数据出发, 假定数据是独立同分布的, 而且假设模型属于某个假设空间, 应用某一评价准则, 从假设空间中选取一个最优的模型, 使它对已给训练数据及未知测试数据再给定评价标准意义下有最准确的预测.
+ 基本概念：**input space, output space, feature space**
+ 其它名词：**instance, feature vector, 联合概率分布**
+ 假设空间: $ \mathcal{F} = \\{ f\;|  \mathit{Y} = f(X) \\} $
+ 最终变成求 $\min\limits_{f\in\mathcal{F}}R_{emp}(f)$ 或 $min_{f\in\mathcal{F}}R_{srm}(f)$ 的问题


<!-- more -->

## 统计学习三要素
+ 方法 = 模型 + 策略 + 算法

### 策略
+ 损失函数: 0-1, quadratic, absolute, logarithmic
+ 风险函数(期望损失): $ R_{exp}(f) = E_{p}[L(Y, f(X))] = \int_{x\times y}L(y, f(x))P(x,y)dxdy $
+ 经验风险(经验损失)(empirical loss): $\displaystyle R_{emp}(f) = \frac{1}{N}\sum_{i=1}^{N}L(y_i, f(x_i)) $
+ 根据大数定理, 可用$R_{emp}(f)$估计$R_{exp}(f)$, 但由于现实中样本有限, 甚至很少，所以需要矫正$R_{emp}(f)$
+ 经验风险最小化(ERM)和结构风险最小化(SRM)
  + ERM: 用最优化方法求解$\min\limits_{f\in\mathcal{F}}R_{emp}(f)$
    + 样本容量很小时容易过拟合(over-fitting), 但样本容量大时，学习效果很好
    + 当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计(MLE)([证明](http://datahonor.com/2017/03/03/最大似然估计与经验风险最小化/)). 
  + SRM: 等价于正则化(regularizer), 即求 $\min\limits_{f\in\mathcal{F}}R_{srm}(f)$
    + 结构风险: $\displaystyle R_{srm}(f) = R_{emp}(f) + \lambda J(f)$ 
      + 其中 $\lambda J(f)$ 位正则化项或罚项(penalty term)
      + $J(f)$是模型空间复杂度, 为定义在$\mathcal{F}$上的泛函. $f$越复杂, $J(f)$越大.
      + $\lambda \ge 0$是系数, 用以权衡经验风险和模型复杂度
      + $R_{srm}(f)$小要求$R_{emp}(f)$和$J(f)$同时小, $R_{srm}(f)$小的模型往往对训练数据以及未知的测试数据都有较好的预测
      + 当模型是条件概率分布, 损失函数是对数损失函数, 模型复杂度由模型的先验概率分布表示时，结构风险最小化就等价于最大后验概率估计(MAP)(证明)

## 模型评估与选择
+ 训练误差(**tranning error**): 模型关于训练数据集的平均损失
+ 测试误差(**test error**): 模型关于测试数据集的平均损失, 反映了模型的预测能力(泛化能力 **generalization ability**)
+ 过拟合: 所选模型参数过多, 对训练数据预测的很好, 对测试数据预测的很差
+ 模型选择时要选择复杂度适当的模型, 防止过拟合.

## 正则化与交叉验证
+ 此为常用的两种模型选择方法

### 正则化
+ $\min\limits_{f\in\mathcal{F}}R_{srm}(f)$
+ 正则化项: 一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大
> 如参数向量$w$的$L_1$范数$\parallel w_1 \parallel$或$L_2$范数$\frac{1}{2}\parallel w_1 \parallel^2$
+ 模型越复杂, 先验概率越大

### 交叉验证
+ 样本充足时, 可随机切成训练集(用于训练模型), 验证集(用于模型选择, 选择预测误差最小的模型)和测试集(模型评估)
+ 交叉验证: 重复使用数据, 反复切, 反复训练, 测试及模型选择
+ 简单交叉验证: 随机切成训练集和测试集, 选测试误差最小的模型
+ $S$折交叉验证(S-fold cross validation): 切成$S$份, 每次选$S-1$份训练, $1$份测试, 重复$S$次
+ 留一交叉验证: $S=N$, 数据集为$N$, 数据集较少时用

## 泛化能力
+ 即模型$\hat{f}$的预测能力, 用$R_{exp}(\hat{f})$来表示
+ 泛化误差上界: $R(f) \le \hat{R}(f) + \varepsilon(d, N, \delta)$
> $R(f)$为泛化误差
> $\le$右边为泛化误差上界
> $\hat{R}(f)$为训练误差
> $\varepsilon(d, N, \delta) = \sqrt{\frac{1}{2N}(\log d + \log \frac{1}{\delta})}$
+ 训练误差小的模型, 泛化误差也会小

## 生成模型与判别模型
+ 监督学习的方法可以分为: 生成方法(**generative approach**)和判别方法(**discriminative approach**)
+ 生成方法: 先学习$P(X,Y)$再求出$P(Y|X) = \frac{P(X,Y)}{P(X)}$
> 如:朴素贝叶斯法和隐马尔可夫模型
+ 判别方法: 直接学习$f(X)$或$P(Y|X)$
> 如:$k$近邻法, 感知机, 决策树,  逻辑斯蒂回归模型, 最大熵模型, 支持向量机, 提升方法和条件随机场等
> 存在隐变量时, 判别方法不能用

## 分类问题
+ $P(Y|X)$作为分类器 
+ 分类准确率(**accuracy**): 对于给定的测试数据集, 分类正确的样本数与总样本数之比
+ 精确率(**precision**):$P = \frac{TP}{TP+FP}$ 
> True, False, Positive, Negative
+ 召回率(**recall**): $R = \frac{TP}{TP+FN}$
+ $P$和$R$的调和均值$F_1$: $\frac{1}{F_1} = \frac{1}{P} + \frac{1}{R}$, 即$F_1 = \frac{2TP}{2TP+FP+FN}$
+ 许多统计学习方法可以用于分类
> 如: $k$近邻法, 感知机, 朴素贝叶斯法, 决策树, 决策列表, 逻辑斯蒂回归模型, 支持向量机, 提升方法, 贝叶斯网络, 神经网络, Winnow等

## 标注(tagging)问题
+ 可以认为书分类问题的推广，也是更复杂的结构预测(**structure prediction**)问题的简单形式
+ 输入一个观测序列$x_{N+1} = (x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, ... ,x_{N+1}^{(n)})^T$, 找到使条件概率$$P((y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, ... ,y_{N+1}^{(n)})|(x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, ... ,x_{N+1}^{(n)})$$最大的标记序列$y_{N+1} = (y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, ... ,y_{N+1}^{(n)})^T$
> 常用的标注方法:隐马尔科夫模型`和条件随机场

## 回归问题
+ 等价于函数拟合: 选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据
+ 分类
> 按输入变量的个数: 一元回归和多元回归
> 输入与输出变量的关系模型: 线性回归和非线性回归
> 损失函数是平方损失函数时: 可用最小二乘法(**least squares**)求解


