{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/slides/query_optimzer.slide","path":"slides/query_optimzer.slide","modified":1,"renderable":0},{"_id":"source/slides/test.slide","path":"slides/test.slide","modified":1,"renderable":0},{"_id":"source/images/Self-Driving-Actions.jpg","path":"images/Self-Driving-Actions.jpg","modified":1,"renderable":0},{"_id":"source/images/critical_path_schedule_alg.png","path":"images/critical_path_schedule_alg.png","modified":1,"renderable":0},{"_id":"source/images/taxonomy-of-workflow-scheduling.png","path":"images/taxonomy-of-workflow-scheduling.png","modified":1,"renderable":0},{"_id":"source/images/Self-Driving-Architecture.jpg","path":"images/Self-Driving-Architecture.jpg","modified":1,"renderable":0},{"_id":"source/images/mcp_schedule_alg.png","path":"images/mcp_schedule_alg.png","modified":1,"renderable":0},{"_id":"source/images/workflow-notation.png","path":"images/workflow-notation.png","modified":1,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.jpg","path":"images/avatar.jpg","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/love.js","path":"js/src/love.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/google779793bde483ac90.html","hash":"c8690f83fb207594963840c9344b0ad5453dc2ec","modified":1548639691241},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1548639691241},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1548639691241},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1548639691241},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1548639691241},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1548639691241},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1548639691241},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1548639691241},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1548639691241},{"_id":"themes/next/README.cn.md","hash":"2c766b3369ed477bce134a5450dab45bef161504","modified":1548639691241},{"_id":"themes/next/README.md","hash":"8ce60ce578963eb4e1eb5e33e1efc2fc4779af9c","modified":1548639691241},{"_id":"themes/next/_config.yml","hash":"221b63326398f79a55a249ef8f6babdfbc05a18a","modified":1548639691245},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1548639691245},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1548639691245},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1548639691249},{"_id":"source/_posts/Self-Driving-Database-Management-Systems.md","hash":"52ed8d4e17c2812d7b7995ab9590e9bc93253e73","modified":1548639691241},{"_id":"source/_posts/os.md","hash":"fcb7cf94d75620a970f927050a9dc3f824651578","modified":1548640785382},{"_id":"source/_posts/scheduling-algorithms.md","hash":"1bc4e19bc6bf05a4019475df6e1da20abfa67508","modified":1548640785382},{"_id":"source/_posts/statistical-learning-method-1.md","hash":"9c46759f0b926a589f5065b32f4caa4a208ce9af","modified":1548639691241},{"_id":"source/_posts/statistical-learning-method-2.md","hash":"db010444e1baaa0413d8c6210c27a4df11ea369b","modified":1548639691241},{"_id":"source/_posts/statistical-learning-method-3.md","hash":"cc49965bad05f99cb63895b04137623d190f8f26","modified":1548639691241},{"_id":"source/_posts/statistical-learning-method-4.md","hash":"cfce206c3693bd4aedf4511e0a966d885c2c8eb3","modified":1548639691241},{"_id":"source/_posts/statistical-learning-method-5.md","hash":"9c69d9f3868ac4158bd48a7eb8fec62bde1c78b8","modified":1548640785382},{"_id":"source/_posts/statistical-learning-method-6.md","hash":"a511ecbe6f2ee6c5630e0384fce05b6c7838945e","modified":1548640785382},{"_id":"source/_posts/statistical-learning-method-7.md","hash":"c6adfa73e73b9fbf536bcc2dc96637db32da7170","modified":1548640785382},{"_id":"source/_posts/tpch.md","hash":"4768beaf70bb5a07f6d2c4a0a8fe3c335d348986","modified":1548640785382},{"_id":"source/about/index.md","hash":"5e4bd16e283a836168d9b7f1036c18e5770e1693","modified":1548639691241},{"_id":"source/archives/index.md","hash":"4fad2692f8fe01b2010ca764dd4c2e4c9bb8dc26","modified":1548639691241},{"_id":"source/categories/index.md","hash":"39bf604afb9808d73f0c060ec7d167f85be3d5c2","modified":1548639691241},{"_id":"source/slides/index.md","hash":"46072a48f4a69a8452a866eb2684068f20cb4aa6","modified":1548639691241},{"_id":"source/slides/query_optimzer.html","hash":"56cb6fbd74748123d83132a9d86f8c858dba7142","modified":1548640785386},{"_id":"source/slides/query_optimzer.slide","hash":"369ab6c7792e13831dd0dc52b01a3b754a55d5ad","modified":1548640785386},{"_id":"source/slides/test.html","hash":"683e8d1c8524abf90379caeb0b4c61ef2ac0d0b1","modified":1548639691241},{"_id":"source/slides/test.slide","hash":"085d60d72038fbb9c5b5df53d211a510260ec06b","modified":1548639691241},{"_id":"source/tags/index.md","hash":"9007a1489d64c133a7b1256824b553073e59ec66","modified":1548639691241},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1548639691245},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1548639691245},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1548639691245},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1548639691245},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1548639691245},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1548639691245},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1548639691245},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1548639691245},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1548639691245},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1548639691245},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1548639691245},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1548639691245},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1548639691245},{"_id":"themes/next/languages/zh-Hans.yml","hash":"16ef56d0dea94638de7d200984c90ae56f26b4fe","modified":1548639691245},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1548639691245},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1548639691245},{"_id":"themes/next/layout/_layout.swig","hash":"b6e32544433b8628f4a37235ce75335059cb6c04","modified":1548639691245},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1548639691249},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1548639691249},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1548639691249},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1548639691249},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1548639691249},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1548639691249},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1548639691249},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1548639691249},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1548639691249},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1548639691281},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1548639691281},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1548639691281},{"_id":"source/images/Self-Driving-Actions.jpg","hash":"7525d582cd41c248591ee9782b6c49f178436866","modified":1548639691241},{"_id":"source/images/critical_path_schedule_alg.png","hash":"4c6ef8bb29fe81343b727f5d6cc049840c79b712","modified":1548640785382},{"_id":"source/images/taxonomy-of-workflow-scheduling.png","hash":"ac59b535020dcfae33506e8765a818d849f21f78","modified":1548640785386},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548639691253},{"_id":"source/images/Self-Driving-Architecture.jpg","hash":"f33c6f5a196187e0c364fc316e654d51795a5a5d","modified":1548639691241},{"_id":"source/images/mcp_schedule_alg.png","hash":"9846d22ec050297d7c83392152b1b9f1b0170edb","modified":1548640785386},{"_id":"source/images/workflow-notation.png","hash":"edd80650e3660c9b18d635863c87ef5e10fa72a5","modified":1548640785386},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1548639691245},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1548639691245},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1548639691245},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1548639691245},{"_id":"themes/next/layout/_macro/post.swig","hash":"00ca04166bf1d867c0df9e87f47a29faf916eac8","modified":1548639691245},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1548639691245},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1548639691245},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1548639691245},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1548639691245},{"_id":"themes/next/layout/_partials/footer.swig","hash":"6fde38cdb7062faf5ac31c82d79320c12685332e","modified":1548639691245},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1548639691245},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1548639691245},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1548639691245},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1548639691245},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1548639691245},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1548639691245},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1548639691245},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1548639691245},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1548639691245},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1548639691245},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1548639691245},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1548639691245},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1548639691245},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1548639691245},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1548639691245},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1548639691249},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1548639691249},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1548639691249},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1548639691249},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1548639691249},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1548639691249},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1548639691249},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1548639691249},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1548639691249},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1548639691253},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1548639691253},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1548639691253},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1548639691253},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1548639691253},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1548639691253},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1548639691253},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1548639691253},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1548639691253},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1548639691253},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1548639691253},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1548639691253},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1548639691253},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1548639691253},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1548639691253},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1548639691253},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1548639691253},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1548639691253},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1548639691253},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548639691245},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548639691245},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548639691253},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548639691253},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548639691253},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548639691253},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1548639691253},{"_id":"themes/next/source/images/avatar.jpg","hash":"a79b03cd23dbb6aea58252ec75cf712e9d4b06c6","modified":1548639691253},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1548639691245},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1548639691245},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1548639691245},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1548639691245},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1548639691245},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1548639691245},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1548639691245},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1548639691245},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1548639691245},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1548639691245},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1548639691245},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1548639691245},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1548639691245},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1548639691245},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1548639691245},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1548639691245},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1548639691245},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1548639691245},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1548639691245},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1548639691245},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1548639691245},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1548639691245},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1548639691245},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1548639691245},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1548639691245},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1548639691245},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1548639691253},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1548639691253},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1548639691253},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1548639691253},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1548639691253},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1548639691253},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1548639691253},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1548639691253},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1548639691253},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1548639691253},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1548639691253},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1548639691253},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1548639691253},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1548639691257},{"_id":"themes/next/source/js/src/love.js","hash":"bf5b51107686df350736ba49160a335a86acd9a9","modified":1548639691257},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1548639691257},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1548639691257},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1548639691257},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1548639691257},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1548639691257},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1548639691257},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1548639691261},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1548639691261},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1548639691261},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1548639691261},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1548639691261},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1548639691261},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1548639691261},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1548639691261},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1548639691261},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1548639691261},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1548639691261},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1548639691273},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1548639691273},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1548639691273},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1548639691273},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1548639691273},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1548639691273},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1548639691273},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1548639691273},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1548639691273},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1548639691273},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1548639691273},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1548639691277},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1548639691277},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1548639691277},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1548639691277},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1548639691277},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1548639691281},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1548639691281},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1548639691281},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1548639691273},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1548639691245},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1548639691245},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1548639691249},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1548639691249},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1548639691249},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1548639691249},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1548639691249},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1548639691249},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1548639691249},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1548639691253},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1548639691257},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1548639691257},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1548639691257},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1548639691257},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1548639691261},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1548639691261},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1548639691261},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1548639691265},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1548639691265},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1548639691265},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1548639691277},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1548639691277},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1548639691257},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1548639691273},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1548639691273},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1548639691281},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1548639691249},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1548639691249},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1548639691253},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1548639691253},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1548639691257},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1548639691257},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1548639691257},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1548639691257},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1548639691257},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1548639691261},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1548639691261},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1548639691265},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1548639691265},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1548639691273},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1548639691261},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1548639691277},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1548639691269},{"_id":"public/google779793bde483ac90.html","hash":"e2934975406485d061972795bb90195eef6f1c0d","modified":1548642195859},{"_id":"public/slides/query_optimzer.html","hash":"6bde3ad9045dfcb289a0fb68be50dd3ec25dc3d8","modified":1548642195962},{"_id":"public/slides/test.html","hash":"d573ae11de005c1e516265ea2790ead5a04fc2d1","modified":1548642195967},{"_id":"public/baidusitemap.xml","hash":"da77f86fffb70e18206e5b8e8d6fa92d6bc84ad2","modified":1548642195968},{"_id":"public/search.xml","hash":"6c5de62842bcb0fffe6f3d3fbbd4972dc0f9d916","modified":1548642195977},{"_id":"public/sitemap.xml","hash":"00f9532a5c8da4db5168d303d58c37c7281c12de","modified":1548642195978},{"_id":"public/about/index.html","hash":"efc2fb1719598341b8ec5644febf3edb292f86c2","modified":1548642195993},{"_id":"public/archives/index.html","hash":"a071b19687fd118e64438d907109c83c4970c689","modified":1548642195993},{"_id":"public/categories/index.html","hash":"83252b55951f8edd5edefd115d518f5d3dbf4bb3","modified":1548642195993},{"_id":"public/slides/index.html","hash":"887979c1189d955ebca66b6a5a9b55bcb9b6c581","modified":1548642195993},{"_id":"public/tags/index.html","hash":"956005648219e4a2f4d752b6e9a0a0ccddb30434","modified":1548642195993},{"_id":"public/operating-system/os.html","hash":"fa0db7f9645e5f78a9d46427f0bc9d888bb4db18","modified":1548642195993},{"_id":"public/database/tpch.html","hash":"82d53accda8e95539f33e15ce570db0656292c20","modified":1548642195993},{"_id":"public/scheduling-algorithm/scheduling-algorithms.html","hash":"856474cda342f7e43092b5833423cce3d615b9c8","modified":1548642195994},{"_id":"public/统计学习方法/statistical-learning-method-7.html","hash":"d30fca5fef264633f508ef614bb1b22b154858f8","modified":1548642195994},{"_id":"public/统计学习方法/statistical-learning-method-6.html","hash":"7a1db407817fa3a447f77911c472188beab0dcb9","modified":1548642195994},{"_id":"public/统计学习方法/statistical-learning-method-5.html","hash":"80e0b2d5b5df0342dc13cc80152e341228e12827","modified":1548642195994},{"_id":"public/统计学习方法/statistical-learning-method-4.html","hash":"26ed9c588902f36e915dc337ec805972df08ca4f","modified":1548642195994},{"_id":"public/统计学习方法/statistical-learning-method-3.html","hash":"45e116de6b1f1fd9f4a30f2bbe6ec280f4366b11","modified":1548642195994},{"_id":"public/统计学习方法/statistical-learning-method-2.html","hash":"e6b335c8b651c363c8963d35e60088dd45fc8220","modified":1548642195994},{"_id":"public/统计学习方法/statistical-learning-method-1.html","hash":"b911ec89d04219ecc0364d96dffdc39d6236ffd9","modified":1548642195994},{"_id":"public/paper-reading/Self-Driving-Database-Management-Systems.html","hash":"1b6e5ffe2ca230d9f2d1eafef435473653c491a6","modified":1548642195994},{"_id":"public/archives/page/2/index.html","hash":"59735f3d47ba5ef4bdeb78b4461e6162d70c4362","modified":1548642195995},{"_id":"public/archives/2018/index.html","hash":"b8d6e75a0840cd427e157e1daf15155f230c1144","modified":1548642195995},{"_id":"public/archives/2018/11/index.html","hash":"12d62eca5f98eccebb860ef926570805dcdcf664","modified":1548642195995},{"_id":"public/archives/2019/index.html","hash":"b0f9249bdc1665c1cff75cfd5f4e45973eaf3e65","modified":1548642195995},{"_id":"public/archives/2019/01/index.html","hash":"8c47f687e9b1f2c91b6e20f0fd164c5e77537c29","modified":1548642195995},{"_id":"public/categories/paper-reading/index.html","hash":"5aca25b736e9e03baeca4dda56fb97f3f995e4f3","modified":1548642195995},{"_id":"public/categories/operating-system/index.html","hash":"91436695fa22b0647bb55eb65c99265d4f46a0d9","modified":1548642195995},{"_id":"public/categories/scheduling-algorithm/index.html","hash":"2590795b4aad8fc115117d8367d726dc2e0a480c","modified":1548642195995},{"_id":"public/categories/统计学习方法/index.html","hash":"48bd3d9e0d43ec671726ddafbdfa632ad45c109a","modified":1548642195995},{"_id":"public/categories/database/index.html","hash":"0060b0b0a8768e37fcffc987679b9c695b7ad9ad","modified":1548642195996},{"_id":"public/index.html","hash":"accf9f34acca44bf3189577f3dc1c0c5e6c26be5","modified":1548642195996},{"_id":"public/page/2/index.html","hash":"634e21e1d124a46a7dc8ca3e88807aef83ee60fd","modified":1548642195996},{"_id":"public/tags/paper-reading/index.html","hash":"f5a05416244b67175a8a7664abca5bfb22665e11","modified":1548642195996},{"_id":"public/tags/database/index.html","hash":"9307cb1e8ce1f0db1174b63161f52b499c1106b6","modified":1548642195996},{"_id":"public/tags/operating-system/index.html","hash":"8f473569d9734f374a8c3a7e2d2e330dfbe72d4d","modified":1548642195996},{"_id":"public/tags/scheduling-algorithm/index.html","hash":"09727efa8540891b3e131312fa4d7f08f2e2468a","modified":1548642195996},{"_id":"public/tags/统计学习方法/index.html","hash":"05759867444287ff602ae37492448ca347c56616","modified":1548642195996},{"_id":"public/tags/machine-learning/index.html","hash":"b0f9d973cd19fc23975f1d13cec97568f747ee91","modified":1548642195997},{"_id":"public/tags/book/index.html","hash":"9fe6808fc5d5bdc80988e3f11e57e232cb5894cd","modified":1548642195997},{"_id":"public/tags/tpch/index.html","hash":"c40dc0e6812a878bc27caed22b42538d91122477","modified":1548642195997},{"_id":"public/slides/query_optimzer.slide","hash":"369ab6c7792e13831dd0dc52b01a3b754a55d5ad","modified":1548642196008},{"_id":"public/slides/test.slide","hash":"085d60d72038fbb9c5b5df53d211a510260ec06b","modified":1548642196008},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1548642196008},{"_id":"public/images/apple-touch-icon-next.png","hash":"2959dbc97f31c80283e67104fe0854e2369e40aa","modified":1548642196008},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1548642196008},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1548642196008},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1548642196008},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1548642196008},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1548642196009},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1548642196009},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1548642196009},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1548642196009},{"_id":"public/images/favicon-16x16-next.png","hash":"943a0d67a9cdf8c198109b28f9dbd42f761d11c3","modified":1548642196009},{"_id":"public/images/favicon-32x32-next.png","hash":"0749d7b24b0d2fae1c8eb7f671ad4646ee1894b1","modified":1548642196009},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1548642196009},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1548642196009},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1548642196009},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1548642196009},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1548642196009},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1548642196010},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1548642196010},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1548642196010},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1548642196010},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1548642196010},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1548642196010},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1548642196010},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1548642196010},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1548642196010},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1548642196010},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1548642196010},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1548642196010},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1548642196011},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1548642196011},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1548642196011},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1548642196011},{"_id":"public/images/Self-Driving-Actions.jpg","hash":"7525d582cd41c248591ee9782b6c49f178436866","modified":1548642196713},{"_id":"public/images/critical_path_schedule_alg.png","hash":"4c6ef8bb29fe81343b727f5d6cc049840c79b712","modified":1548642196719},{"_id":"public/images/taxonomy-of-workflow-scheduling.png","hash":"ac59b535020dcfae33506e8765a818d849f21f78","modified":1548642196732},{"_id":"public/images/avatar.jpg","hash":"a79b03cd23dbb6aea58252ec75cf712e9d4b06c6","modified":1548642196732},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1548642196733},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1548642196733},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1548642196765},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1548642196765},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1548642196765},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1548642196765},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1548642196765},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1548642196765},{"_id":"public/js/src/love.js","hash":"bf5b51107686df350736ba49160a335a86acd9a9","modified":1548642196765},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1548642196766},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1548642196766},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1548642196766},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1548642196766},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1548642196766},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1548642196766},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1548642196766},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1548642196766},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1548642196766},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1548642196766},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1548642196766},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1548642196766},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1548642196767},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1548642196767},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1548642196768},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1548642196768},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1548642196768},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1548642196768},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1548642196768},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1548642196768},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1548642196768},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1548642196768},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1548642196768},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1548642196768},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1548642196768},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1548642196768},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1548642196769},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1548642196769},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1548642196769},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1548642196769},{"_id":"public/lib/fastclick/README.html","hash":"c52d599f3a276053019fc41af2759ce6491ef581","modified":1548642196769},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1548642196769},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1548642196769},{"_id":"public/css/main.css","hash":"7150ae0d5587cc3dc7d9fe3a6e809f68b8400c25","modified":1548642196769},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1548642196769},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1548642196769},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1548642196769},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1548642196770},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1548642196770},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1548642196770},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1548642196770},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1548642196770},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1548642196770},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1548642196770},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1548642196770},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1548642196770},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1548642196770},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1548642196771},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1548642196771},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1548642196771},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1548642196771},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1548642196771},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1548642196771},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1548642196771},{"_id":"public/images/Self-Driving-Architecture.jpg","hash":"f33c6f5a196187e0c364fc316e654d51795a5a5d","modified":1548642196772},{"_id":"public/images/mcp_schedule_alg.png","hash":"9846d22ec050297d7c83392152b1b9f1b0170edb","modified":1548642196772},{"_id":"public/images/workflow-notation.png","hash":"edd80650e3660c9b18d635863c87ef5e10fa72a5","modified":1548642196772},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1548642196772},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1548642196773},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1548642196773},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1548642196811}],"Category":[{"name":"paper reading","_id":"cjrfpkr780005ap3noej2c7sh"},{"name":"operating system","_id":"cjrfpkr7o000cap3nxe35v7mh"},{"name":"scheduling algorithm","_id":"cjrfpkr7u000kap3nbouaqd0s"},{"name":"统计学习方法","_id":"cjrfpkr7y000rap3nie0djtyd"},{"name":"database","_id":"cjrfpkr8c001gap3nw22c7epr"}],"Data":[],"Page":[{"layout":"false","_content":"google-site-verification: google779793bde483ac90.html\n\n","source":"google779793bde483ac90.html","raw":"layout: false\n---\ngoogle-site-verification: google779793bde483ac90.html\n\n","date":"2019-01-28T01:41:31.241Z","updated":"2019-01-28T01:41:31.241Z","path":"google779793bde483ac90.html","title":"","comments":1,"_id":"cjrfpkqxr0000ap3n3k532sns","content":"google-site-verification: google779793bde483ac90.html\n\n","site":{"data":{}},"excerpt":"","more":"google-site-verification: google779793bde483ac90.html\n\n"},{"title":"about","date":"2018-11-07T07:44:45.000Z","type":"about","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2018-11-07 15:44:45\ntype: \"about\"\n---\n","updated":"2019-01-28T01:41:31.241Z","path":"about/index.html","comments":1,"layout":"page","_id":"cjrfpkr6l0002ap3n4yxu04m4","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"archives","date":"2018-11-07T07:48:23.000Z","type":"archives","_content":"","source":"archives/index.md","raw":"---\ntitle: archives\ndate: 2018-11-07 15:48:23\ntype: \"archives\"\n---\n","updated":"2019-01-28T01:41:31.241Z","path":"archives/index.html","comments":1,"layout":"page","_id":"cjrfpkr730004ap3njnl4yus4","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2018-11-07T07:47:25.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2018-11-07 15:47:25\ntype: \"categories\"\n---\n","updated":"2019-01-28T01:41:31.241Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjrfpkr7c0008ap3nmfv0d0f8","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"slides","date":"2018-11-08T06:22:27.000Z","_content":"","source":"slides/index.md","raw":"---\ntitle: slides\ndate: 2018-11-08 14:22:27\n---\n","updated":"2019-01-28T01:41:31.241Z","path":"slides/index.html","comments":1,"layout":"page","_id":"cjrfpkr7f000aap3n6e1s45lp","content":"","site":{"data":{}},"excerpt":"","more":""},{"layout":"false","_content":"<!DOCTYPE html>\n<html>\n  <head>\n    <title>Title</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n    <style type=\"text/css\">\n      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);\n      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);\n      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);\n\n      body { font-family: 'Droid Serif'; }\n      h1, h2, h3 {\n        font-family: 'Yanone Kaffeesatz';\n        font-weight: normal;\n      }\n      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }\n    </style>\n    <script src=\"http://gnab.github.io/remark/downloads/remark-latest.min.js\" type=\"text/javascript\"></script>\n\n  </head>\n\n\n  <body>\n    <script type=\"text/javascript\">\n      var slideshow = remark.create({\n        highlightStyle: 'monokai',\n        sourceUrl: '/slides/query_optimzer.slide'\n      })\n    </script>\n  </body>\n</html>\n","source":"slides/query_optimzer.html","raw":"layout: false\n--------\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>Title</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n    <style type=\"text/css\">\n      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);\n      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);\n      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);\n\n      body { font-family: 'Droid Serif'; }\n      h1, h2, h3 {\n        font-family: 'Yanone Kaffeesatz';\n        font-weight: normal;\n      }\n      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }\n    </style>\n    <script src=\"http://gnab.github.io/remark/downloads/remark-latest.min.js\" type=\"text/javascript\"></script>\n\n  </head>\n\n\n  <body>\n    <script type=\"text/javascript\">\n      var slideshow = remark.create({\n        highlightStyle: 'monokai',\n        sourceUrl: '/slides/query_optimzer.slide'\n      })\n    </script>\n  </body>\n</html>\n","date":"2019-01-28T01:59:45.386Z","updated":"2019-01-28T01:59:45.386Z","path":"slides/query_optimzer.html","title":"","comments":1,"_id":"cjrfpkr7p000eap3ntonmbd04","content":"<!DOCTYPE html>\n<html>\n  <head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n    <!-- hexo-inject:begin --><!-- hexo-inject:end --><title>Title</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n    <style type=\"text/css\">\n      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);\n      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);\n      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);\n\n      body { font-family: 'Droid Serif'; }\n      h1, h2, h3 {\n        font-family: 'Yanone Kaffeesatz';\n        font-weight: normal;\n      }\n      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }\n    </style>\n    <script src=\"http://gnab.github.io/remark/downloads/remark-latest.min.js\" type=\"text/javascript\"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n\n  </head>\n\n\n  <body>\n    <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type=\"text/javascript\">\n      var slideshow = remark.create({\n        highlightStyle: 'monokai',\n        sourceUrl: '/slides/query_optimzer.slide'\n      })\n    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n  </body>\n</html>\n","site":{"data":{}},"excerpt":"","more":"<!DOCTYPE html>\n<html>\n  <head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n    <!-- hexo-inject:begin --><!-- hexo-inject:end --><title>Title</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n    <style type=\"text/css\">\n      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);\n      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);\n      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);\n\n      body { font-family: 'Droid Serif'; }\n      h1, h2, h3 {\n        font-family: 'Yanone Kaffeesatz';\n        font-weight: normal;\n      }\n      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }\n    </style>\n    <script src=\"http://gnab.github.io/remark/downloads/remark-latest.min.js\" type=\"text/javascript\"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n\n  </head>\n\n\n  <body>\n    <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type=\"text/javascript\">\n      var slideshow = remark.create({\n        highlightStyle: 'monokai',\n        sourceUrl: '/slides/query_optimzer.slide'\n      })\n    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n  </body>\n</html>\n"},{"layout":"false","_content":"<!DOCTYPE html>\n<html>\n  <head>\n    <title>Title</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n    <style type=\"text/css\">\n      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);\n      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);\n      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);\n\n      body { font-family: 'Droid Serif'; }\n      h1, h2, h3 {\n        font-family: 'Yanone Kaffeesatz';\n        font-weight: normal;\n      }\n      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }\n    </style>\n    <script src=\"http://gnab.github.io/remark/downloads/remark-latest.min.js\" type=\"text/javascript\"></script>\n\n  </head>\n\n\n  <body>\n    <script type=\"text/javascript\">\n      var slideshow = remark.create({\n        highlightStyle: 'monokai',\n        sourceUrl: '/slides/test.slide'\n      })\n    </script>\n  </body>\n</html>\n","source":"slides/test.html","raw":"layout: false\n--------\n<!DOCTYPE html>\n<html>\n  <head>\n    <title>Title</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\"/>\n    <style type=\"text/css\">\n      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);\n      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);\n      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);\n\n      body { font-family: 'Droid Serif'; }\n      h1, h2, h3 {\n        font-family: 'Yanone Kaffeesatz';\n        font-weight: normal;\n      }\n      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }\n    </style>\n    <script src=\"http://gnab.github.io/remark/downloads/remark-latest.min.js\" type=\"text/javascript\"></script>\n\n  </head>\n\n\n  <body>\n    <script type=\"text/javascript\">\n      var slideshow = remark.create({\n        highlightStyle: 'monokai',\n        sourceUrl: '/slides/test.slide'\n      })\n    </script>\n  </body>\n</html>\n","date":"2019-01-28T01:41:31.241Z","updated":"2019-01-28T01:41:31.241Z","path":"slides/test.html","title":"","comments":1,"_id":"cjrfpkr7r000gap3nce7xfc66","content":"<!DOCTYPE html>\n<html>\n  <head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n    <!-- hexo-inject:begin --><!-- hexo-inject:end --><title>Title</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n    <style type=\"text/css\">\n      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);\n      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);\n      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);\n\n      body { font-family: 'Droid Serif'; }\n      h1, h2, h3 {\n        font-family: 'Yanone Kaffeesatz';\n        font-weight: normal;\n      }\n      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }\n    </style>\n    <script src=\"http://gnab.github.io/remark/downloads/remark-latest.min.js\" type=\"text/javascript\"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n\n  </head>\n\n\n  <body>\n    <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type=\"text/javascript\">\n      var slideshow = remark.create({\n        highlightStyle: 'monokai',\n        sourceUrl: '/slides/test.slide'\n      })\n    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n  </body>\n</html>\n","site":{"data":{}},"excerpt":"","more":"<!DOCTYPE html>\n<html>\n  <head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n    <!-- hexo-inject:begin --><!-- hexo-inject:end --><title>Title</title>\n    <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n    <style type=\"text/css\">\n      @import url(http://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);\n      @import url(http://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);\n      @import url(http://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);\n\n      body { font-family: 'Droid Serif'; }\n      h1, h2, h3 {\n        font-family: 'Yanone Kaffeesatz';\n        font-weight: normal;\n      }\n      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }\n    </style>\n    <script src=\"http://gnab.github.io/remark/downloads/remark-latest.min.js\" type=\"text/javascript\"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n\n  </head>\n\n\n  <body>\n    <!-- hexo-inject:begin --><!-- hexo-inject:end --><script type=\"text/javascript\">\n      var slideshow = remark.create({\n        highlightStyle: 'monokai',\n        sourceUrl: '/slides/test.slide'\n      })\n    </script><!-- hexo-inject:begin --><!-- hexo-inject:end -->\n  </body>\n</html>\n"},{"title":"tags","date":"2018-11-07T07:48:09.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2018-11-07 15:48:09\ntype: \"tags\"\n---\n","updated":"2019-01-28T01:41:31.241Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjrfpkr7t000jap3n9b332lgy","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Self-Driving Database Management Systems (CIDR’17)","date":"2018-11-07T09:42:42.000Z","_content":"\n# 介绍\n+ 以往数据库调优是 DBA 在问题发生后进行调整，self-driving （自治）数据库不仅优化当前工作负载，还可以预测以后的负载情况，从而事先做好准备，并且可以为现代高性能数据库提供更多复杂的新的优化方案。Peloton 通过深度学习实现了self-driving。\n+ 现存的自动调优技术例如：Self-Tuning 物理数据库技术，自动选择索引、自动对表分区存储、自动创建和更新物化视图。自动选择底层存储方式（H2O， 2014），自动设置数据库配置参数，拷贝并及时更新所需索引的DataBase Cracking 技术，云数据库动态资源配置等等。但以上都只用于解决单一的问题，没有从全局考虑，而且 DBA 不一定能了解那么多方面去修复或优化一个系统，而且无法预测未来的负载从而提前做出决策。\n\n# 问题概述\n+ 了解应用的工作负载，HTAP（hybrid transaction analytical processing）可能执行事务和查询的时间几乎是同时的，所以不能用为 OLAP 和 OLTP 分别创建一个数据库的方法。HTAP 可自动的选择是使用 OLAP 还是 OLTP 的方式来优化。\n+ 需要预测资源使用率的趋势。如错开高峰时段进行更新，对即将可能出现的问题提前告警。\n+ 有了预测能力之后，DBMS 需要为预计的负载情况选择合适的优化方式。Self-driving 不支持需要数据库外部信息（如权限，数据清理和版本控制）的 DBA 任务，支持以下这些操作。对于每一个优化动作，DBMS 不仅需要估计其部署后的开销，还要估计部署它所需要的开销。\n![Self-Driving Actions](/images/Self-Driving-Actions.jpg)\n+ 需要确定何时生成及采用相应的优化动作。即需要动态学习和改变，以适应负载的改变。\n+ 两个额外的限制：代码不能因为上层需求改变而需要重构；它不能依赖于仅支持某些编程环境的程序分析工具。\n\n<!-- more -->\n\n# Self-Driving 架构\n+ 现存的数据库在修改表1 中的Actions时常常需要重启，并且速度也比较慢。自研一个新的DBMS架构能很好的嵌入self-driving组件，并且提供更细粒度的控制。使用多版本并发控制（MVCC）来使得 OLTP 事务不会阻塞 OLAP 查询。使用内存管理、lock-free数据结构和flexible layout使得HTAP工作负载可以快速执行(即 Peloton 的实现)。\n![Self-Driving-Architecture](/images/Self-Driving-Architecture.jpg)\n+ Peloton架构如Figure 1，系统在不需要任何除环境（例如内存上限，目录路径等）外的其它信息就可以实现自动学习如何降低延迟（数据库最重要的性能指标），目前主要考虑延迟，其它的指标（分布式环境服务开销和能耗）可通过增加限制来优化。\n+ Peloton中有一个Workload Monitor来监控事件流的资源使用情况和DBMS /OS遥测数据、优化动作的问题出现和结束时机。之后通过这些数据预测负载情况，找出系统瓶颈和其它问题（如索引丢失，节点过载）然后选择最佳执行动作，并且执行的同时进行检测和学习。\n\n## 负载分类\n+ 第一个功能组件是通过无监督学习的方式将具有相似特性的应用查询进行聚合，即对负载进行聚类，可以减少模型数量，更容易预测应用行为。Peloton最初的实现是DBSCAN算法（原本用于聚合OLTP负载）。\n+ 一个很大的问题就是用什么查询特性来进行聚类，有两种：一是查询runtime metrics，虽然这对可以在不需要理解其意义的情况下进行聚类，但是其对数据库内容和底层物理设计的变化更敏感，对高并发的负载也会出现类似的问题；二是查询逻辑语义，基于逻辑执行计划（如表和谓词）来分类，其独立于数据库内容和底层物理设计，但是需要考虑其是否能生成好的模型，并且为了runtime metrics的精度所付出的训练代价是值得的。不过，有可能模型变化不大，收敛快，且由于硬件加速使得开销小。\n+ 还有一个问题就是如何确定类簇已经不再正确了。Peloton采用交叉验证（留一小部分数据集作为验证集）来确定何时类簇的错误率超过阈值，并且可以探索执行动作是如何影响查询的，从而决定何时重新训练模型。\n\n## 负载预测\n+ 为每一种负载的查询的出现率做预测，除了异常的热点之外，这种预测使系统能够识别负载周期性和数据增长趋势，从而为负载波动做准备。在DBMS执行查询之后，它用其簇标识符标记每个查询，然后填充一个直方图，该直方图跟踪在一个时间段内到达每个群集的查询的数量。Peloton使用这些数据来训练预测模型，这些模型估计了应用程序在将来执行的每个簇的查询数量。DBMS还在事件流中为其他DBMS/OS指标构建了类似的模型。\n+ ARM被用来做时序数据的线性关系分析，但是数据库可能被多个因素影响，并不符合线性假说。\n+ RNN对预测时序数据的非线性模型很有效。LSTM是RNN的一个变种，可以学习时序数据的周期性规律。\n+ RNN的准确性依赖于其训练数据集的大小，Peloton为每个Group维护多个RNN（不同的时间范围和间隔）来预测负载。尽管这种粗粒度的RNN不太准确，但是减少了DBMS必须在运行时维护的训练数据的大小和预测所需的开销。\n\n## Action Planning & Execution\n+ 将自动化部件与DBMS进行紧耦合可以使得各部分之间提供反馈。还可以将增强学习应用于并发控制和查询优化\n+ **Action Generation：Peloton**会搜索可能提升性能的Action，并且将action及其调用后对系统的影响记录在catalog中。这种搜索是由预测模型引导的，这样系统就会寻找能够提供最大收益的操作。它还可以删除冗余操作，以减少搜索的复杂性。可以根据资源需求及使用情况决定分配多少个CPU核来执行action。Action资源分配的knob为增量更改而非绝对值。某些action还有相应的reverse action，如 add/drop index。\n+ **Action Generation:** Peloton会搜索可能提升性能的Action，并且将action及其调用后对系统的影响记录在catalog中。这种搜索是由预测模型引导的，这样系统就会寻找能够提供最大收益的操作。它还可以删除冗余操作，以减少搜索的复杂性。可以根据资源需求及使用情况决定分配多少个CPU核来执行action。Action资源分配的knob为增量更改而非绝对值。某些action还有相应的reverse action，如 add/drop index。\n+ 在RHCM之下，计划流程（planning process）被组织为树状，每一层包含某个时刻数据库可调用的action，系统根据这些action的成本效益（cost-benefit）来决定调用哪一个action，也有可能一个action都不调用。一种搜索方式是随机选择树上层次更深的action而非评估所有的action（参考alpha go的论文）。对当前数据库状态和预期负载效益更好的action更可能被考虑（加权），同时最近被reverse的action会被避免调用。\n+ 一个action的开销(cost)是对部署（deploy）这个action的时间和数据库因此性能下降情况的估计。对于没有调用过的action的分析，通过回馈机制分析某一类型的action来改善。一个action的效益(benefit)是在执行（intsall）这个action后在查询延迟上带来的改变，即查询样例的开销加权总和，权重为预测出来的相应查询的到达率。而且时域（time horizon）也会作为权重考虑，这使得直接模型（immediate model）会对最终的成本效益分析有更大的影响。\n+ 此外，action对Peloton的内存使用率的影响也会在cost-benefit分析的时候考虑，任何导致DBMS内存超限的action都会被忽略。\n+ RHCM的horizon的值比较微妙，太短的话，在即将到来的负载峰值时DBMS来不及进行准备；太长的话，突然出现的问题无法及时得到优化解决，因为模型太慢了。除此之外，由于计算每个time epoch的cost-benefit是昂贵的，所以可以创建另一个深度神经网络从而用一个值函数来近似它们。\n+ **Deployment：**Peloton支持非阻塞地deploying actions。例如，对表进行迁移或重组并不影响其它查询的访问。一些操作，比如添加索引，需要特别考虑，以防在action执行过程中因为因为数据被修改而产生影响。\n+ DBMS还处理来自集成机器学习组件的资源调度和争用问题。使用单独的联合处理器或GPU来处理繁重的计算任务将避免减慢DBMS的速度。否则，DBMS将不得不使用单独的机器，专门用于所有的预测和计划组件。这将使系统的设计复杂化，并由于协调而增加额外的开销。\n\n## Additional Considerations\n+ DBA对于self-driving的不信任，可以将决策写成人类可读的形式，比如为什么添加索引，它的负载跟之前哪一个很相似，为何添加索引可以带来优化。另外，还需要提示DBA是否需要进行OLTP或者OLAP的优化，以及数据库的重要性优先级。Peloton也会像其它action一样记录DBA的手动操作，并且记录其效益，同时也允许DBA决定此记录何时过时，以防止消除误操作带来长期的影响。\n\n","source":"_posts/Self-Driving-Database-Management-Systems.md","raw":"---\ntitle: Self-Driving Database Management Systems (CIDR’17)\ndate: 2018-11-07 17:42:42\ntags: \n  - paper reading\n  - database\ncategories: paper reading\n---\n\n# 介绍\n+ 以往数据库调优是 DBA 在问题发生后进行调整，self-driving （自治）数据库不仅优化当前工作负载，还可以预测以后的负载情况，从而事先做好准备，并且可以为现代高性能数据库提供更多复杂的新的优化方案。Peloton 通过深度学习实现了self-driving。\n+ 现存的自动调优技术例如：Self-Tuning 物理数据库技术，自动选择索引、自动对表分区存储、自动创建和更新物化视图。自动选择底层存储方式（H2O， 2014），自动设置数据库配置参数，拷贝并及时更新所需索引的DataBase Cracking 技术，云数据库动态资源配置等等。但以上都只用于解决单一的问题，没有从全局考虑，而且 DBA 不一定能了解那么多方面去修复或优化一个系统，而且无法预测未来的负载从而提前做出决策。\n\n# 问题概述\n+ 了解应用的工作负载，HTAP（hybrid transaction analytical processing）可能执行事务和查询的时间几乎是同时的，所以不能用为 OLAP 和 OLTP 分别创建一个数据库的方法。HTAP 可自动的选择是使用 OLAP 还是 OLTP 的方式来优化。\n+ 需要预测资源使用率的趋势。如错开高峰时段进行更新，对即将可能出现的问题提前告警。\n+ 有了预测能力之后，DBMS 需要为预计的负载情况选择合适的优化方式。Self-driving 不支持需要数据库外部信息（如权限，数据清理和版本控制）的 DBA 任务，支持以下这些操作。对于每一个优化动作，DBMS 不仅需要估计其部署后的开销，还要估计部署它所需要的开销。\n![Self-Driving Actions](/images/Self-Driving-Actions.jpg)\n+ 需要确定何时生成及采用相应的优化动作。即需要动态学习和改变，以适应负载的改变。\n+ 两个额外的限制：代码不能因为上层需求改变而需要重构；它不能依赖于仅支持某些编程环境的程序分析工具。\n\n<!-- more -->\n\n# Self-Driving 架构\n+ 现存的数据库在修改表1 中的Actions时常常需要重启，并且速度也比较慢。自研一个新的DBMS架构能很好的嵌入self-driving组件，并且提供更细粒度的控制。使用多版本并发控制（MVCC）来使得 OLTP 事务不会阻塞 OLAP 查询。使用内存管理、lock-free数据结构和flexible layout使得HTAP工作负载可以快速执行(即 Peloton 的实现)。\n![Self-Driving-Architecture](/images/Self-Driving-Architecture.jpg)\n+ Peloton架构如Figure 1，系统在不需要任何除环境（例如内存上限，目录路径等）外的其它信息就可以实现自动学习如何降低延迟（数据库最重要的性能指标），目前主要考虑延迟，其它的指标（分布式环境服务开销和能耗）可通过增加限制来优化。\n+ Peloton中有一个Workload Monitor来监控事件流的资源使用情况和DBMS /OS遥测数据、优化动作的问题出现和结束时机。之后通过这些数据预测负载情况，找出系统瓶颈和其它问题（如索引丢失，节点过载）然后选择最佳执行动作，并且执行的同时进行检测和学习。\n\n## 负载分类\n+ 第一个功能组件是通过无监督学习的方式将具有相似特性的应用查询进行聚合，即对负载进行聚类，可以减少模型数量，更容易预测应用行为。Peloton最初的实现是DBSCAN算法（原本用于聚合OLTP负载）。\n+ 一个很大的问题就是用什么查询特性来进行聚类，有两种：一是查询runtime metrics，虽然这对可以在不需要理解其意义的情况下进行聚类，但是其对数据库内容和底层物理设计的变化更敏感，对高并发的负载也会出现类似的问题；二是查询逻辑语义，基于逻辑执行计划（如表和谓词）来分类，其独立于数据库内容和底层物理设计，但是需要考虑其是否能生成好的模型，并且为了runtime metrics的精度所付出的训练代价是值得的。不过，有可能模型变化不大，收敛快，且由于硬件加速使得开销小。\n+ 还有一个问题就是如何确定类簇已经不再正确了。Peloton采用交叉验证（留一小部分数据集作为验证集）来确定何时类簇的错误率超过阈值，并且可以探索执行动作是如何影响查询的，从而决定何时重新训练模型。\n\n## 负载预测\n+ 为每一种负载的查询的出现率做预测，除了异常的热点之外，这种预测使系统能够识别负载周期性和数据增长趋势，从而为负载波动做准备。在DBMS执行查询之后，它用其簇标识符标记每个查询，然后填充一个直方图，该直方图跟踪在一个时间段内到达每个群集的查询的数量。Peloton使用这些数据来训练预测模型，这些模型估计了应用程序在将来执行的每个簇的查询数量。DBMS还在事件流中为其他DBMS/OS指标构建了类似的模型。\n+ ARM被用来做时序数据的线性关系分析，但是数据库可能被多个因素影响，并不符合线性假说。\n+ RNN对预测时序数据的非线性模型很有效。LSTM是RNN的一个变种，可以学习时序数据的周期性规律。\n+ RNN的准确性依赖于其训练数据集的大小，Peloton为每个Group维护多个RNN（不同的时间范围和间隔）来预测负载。尽管这种粗粒度的RNN不太准确，但是减少了DBMS必须在运行时维护的训练数据的大小和预测所需的开销。\n\n## Action Planning & Execution\n+ 将自动化部件与DBMS进行紧耦合可以使得各部分之间提供反馈。还可以将增强学习应用于并发控制和查询优化\n+ **Action Generation：Peloton**会搜索可能提升性能的Action，并且将action及其调用后对系统的影响记录在catalog中。这种搜索是由预测模型引导的，这样系统就会寻找能够提供最大收益的操作。它还可以删除冗余操作，以减少搜索的复杂性。可以根据资源需求及使用情况决定分配多少个CPU核来执行action。Action资源分配的knob为增量更改而非绝对值。某些action还有相应的reverse action，如 add/drop index。\n+ **Action Generation:** Peloton会搜索可能提升性能的Action，并且将action及其调用后对系统的影响记录在catalog中。这种搜索是由预测模型引导的，这样系统就会寻找能够提供最大收益的操作。它还可以删除冗余操作，以减少搜索的复杂性。可以根据资源需求及使用情况决定分配多少个CPU核来执行action。Action资源分配的knob为增量更改而非绝对值。某些action还有相应的reverse action，如 add/drop index。\n+ 在RHCM之下，计划流程（planning process）被组织为树状，每一层包含某个时刻数据库可调用的action，系统根据这些action的成本效益（cost-benefit）来决定调用哪一个action，也有可能一个action都不调用。一种搜索方式是随机选择树上层次更深的action而非评估所有的action（参考alpha go的论文）。对当前数据库状态和预期负载效益更好的action更可能被考虑（加权），同时最近被reverse的action会被避免调用。\n+ 一个action的开销(cost)是对部署（deploy）这个action的时间和数据库因此性能下降情况的估计。对于没有调用过的action的分析，通过回馈机制分析某一类型的action来改善。一个action的效益(benefit)是在执行（intsall）这个action后在查询延迟上带来的改变，即查询样例的开销加权总和，权重为预测出来的相应查询的到达率。而且时域（time horizon）也会作为权重考虑，这使得直接模型（immediate model）会对最终的成本效益分析有更大的影响。\n+ 此外，action对Peloton的内存使用率的影响也会在cost-benefit分析的时候考虑，任何导致DBMS内存超限的action都会被忽略。\n+ RHCM的horizon的值比较微妙，太短的话，在即将到来的负载峰值时DBMS来不及进行准备；太长的话，突然出现的问题无法及时得到优化解决，因为模型太慢了。除此之外，由于计算每个time epoch的cost-benefit是昂贵的，所以可以创建另一个深度神经网络从而用一个值函数来近似它们。\n+ **Deployment：**Peloton支持非阻塞地deploying actions。例如，对表进行迁移或重组并不影响其它查询的访问。一些操作，比如添加索引，需要特别考虑，以防在action执行过程中因为因为数据被修改而产生影响。\n+ DBMS还处理来自集成机器学习组件的资源调度和争用问题。使用单独的联合处理器或GPU来处理繁重的计算任务将避免减慢DBMS的速度。否则，DBMS将不得不使用单独的机器，专门用于所有的预测和计划组件。这将使系统的设计复杂化，并由于协调而增加额外的开销。\n\n## Additional Considerations\n+ DBA对于self-driving的不信任，可以将决策写成人类可读的形式，比如为什么添加索引，它的负载跟之前哪一个很相似，为何添加索引可以带来优化。另外，还需要提示DBA是否需要进行OLTP或者OLAP的优化，以及数据库的重要性优先级。Peloton也会像其它action一样记录DBA的手动操作，并且记录其效益，同时也允许DBA决定此记录何时过时，以防止消除误操作带来长期的影响。\n\n","slug":"Self-Driving-Database-Management-Systems","published":1,"updated":"2019-01-28T01:41:31.241Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr6f0001ap3nr5sz4u7x","content":"<h1 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h1><ul>\n<li>以往数据库调优是 DBA 在问题发生后进行调整，self-driving （自治）数据库不仅优化当前工作负载，还可以预测以后的负载情况，从而事先做好准备，并且可以为现代高性能数据库提供更多复杂的新的优化方案。Peloton 通过深度学习实现了self-driving。</li>\n<li>现存的自动调优技术例如：Self-Tuning 物理数据库技术，自动选择索引、自动对表分区存储、自动创建和更新物化视图。自动选择底层存储方式（H2O， 2014），自动设置数据库配置参数，拷贝并及时更新所需索引的DataBase Cracking 技术，云数据库动态资源配置等等。但以上都只用于解决单一的问题，没有从全局考虑，而且 DBA 不一定能了解那么多方面去修复或优化一个系统，而且无法预测未来的负载从而提前做出决策。</li>\n</ul>\n<h1 id=\"问题概述\"><a href=\"#问题概述\" class=\"headerlink\" title=\"问题概述\"></a>问题概述</h1><ul>\n<li>了解应用的工作负载，HTAP（hybrid transaction analytical processing）可能执行事务和查询的时间几乎是同时的，所以不能用为 OLAP 和 OLTP 分别创建一个数据库的方法。HTAP 可自动的选择是使用 OLAP 还是 OLTP 的方式来优化。</li>\n<li>需要预测资源使用率的趋势。如错开高峰时段进行更新，对即将可能出现的问题提前告警。</li>\n<li>有了预测能力之后，DBMS 需要为预计的负载情况选择合适的优化方式。Self-driving 不支持需要数据库外部信息（如权限，数据清理和版本控制）的 DBA 任务，支持以下这些操作。对于每一个优化动作，DBMS 不仅需要估计其部署后的开销，还要估计部署它所需要的开销。<br><img src=\"/images/Self-Driving-Actions.jpg\" alt=\"Self-Driving Actions\"></li>\n<li>需要确定何时生成及采用相应的优化动作。即需要动态学习和改变，以适应负载的改变。</li>\n<li>两个额外的限制：代码不能因为上层需求改变而需要重构；它不能依赖于仅支持某些编程环境的程序分析工具。</li>\n</ul>\n<a id=\"more\"></a>\n<h1 id=\"Self-Driving-架构\"><a href=\"#Self-Driving-架构\" class=\"headerlink\" title=\"Self-Driving 架构\"></a>Self-Driving 架构</h1><ul>\n<li>现存的数据库在修改表1 中的Actions时常常需要重启，并且速度也比较慢。自研一个新的DBMS架构能很好的嵌入self-driving组件，并且提供更细粒度的控制。使用多版本并发控制（MVCC）来使得 OLTP 事务不会阻塞 OLAP 查询。使用内存管理、lock-free数据结构和flexible layout使得HTAP工作负载可以快速执行(即 Peloton 的实现)。<br><img src=\"/images/Self-Driving-Architecture.jpg\" alt=\"Self-Driving-Architecture\"></li>\n<li>Peloton架构如Figure 1，系统在不需要任何除环境（例如内存上限，目录路径等）外的其它信息就可以实现自动学习如何降低延迟（数据库最重要的性能指标），目前主要考虑延迟，其它的指标（分布式环境服务开销和能耗）可通过增加限制来优化。</li>\n<li>Peloton中有一个Workload Monitor来监控事件流的资源使用情况和DBMS /OS遥测数据、优化动作的问题出现和结束时机。之后通过这些数据预测负载情况，找出系统瓶颈和其它问题（如索引丢失，节点过载）然后选择最佳执行动作，并且执行的同时进行检测和学习。</li>\n</ul>\n<h2 id=\"负载分类\"><a href=\"#负载分类\" class=\"headerlink\" title=\"负载分类\"></a>负载分类</h2><ul>\n<li>第一个功能组件是通过无监督学习的方式将具有相似特性的应用查询进行聚合，即对负载进行聚类，可以减少模型数量，更容易预测应用行为。Peloton最初的实现是DBSCAN算法（原本用于聚合OLTP负载）。</li>\n<li>一个很大的问题就是用什么查询特性来进行聚类，有两种：一是查询runtime metrics，虽然这对可以在不需要理解其意义的情况下进行聚类，但是其对数据库内容和底层物理设计的变化更敏感，对高并发的负载也会出现类似的问题；二是查询逻辑语义，基于逻辑执行计划（如表和谓词）来分类，其独立于数据库内容和底层物理设计，但是需要考虑其是否能生成好的模型，并且为了runtime metrics的精度所付出的训练代价是值得的。不过，有可能模型变化不大，收敛快，且由于硬件加速使得开销小。</li>\n<li>还有一个问题就是如何确定类簇已经不再正确了。Peloton采用交叉验证（留一小部分数据集作为验证集）来确定何时类簇的错误率超过阈值，并且可以探索执行动作是如何影响查询的，从而决定何时重新训练模型。</li>\n</ul>\n<h2 id=\"负载预测\"><a href=\"#负载预测\" class=\"headerlink\" title=\"负载预测\"></a>负载预测</h2><ul>\n<li>为每一种负载的查询的出现率做预测，除了异常的热点之外，这种预测使系统能够识别负载周期性和数据增长趋势，从而为负载波动做准备。在DBMS执行查询之后，它用其簇标识符标记每个查询，然后填充一个直方图，该直方图跟踪在一个时间段内到达每个群集的查询的数量。Peloton使用这些数据来训练预测模型，这些模型估计了应用程序在将来执行的每个簇的查询数量。DBMS还在事件流中为其他DBMS/OS指标构建了类似的模型。</li>\n<li>ARM被用来做时序数据的线性关系分析，但是数据库可能被多个因素影响，并不符合线性假说。</li>\n<li>RNN对预测时序数据的非线性模型很有效。LSTM是RNN的一个变种，可以学习时序数据的周期性规律。</li>\n<li>RNN的准确性依赖于其训练数据集的大小，Peloton为每个Group维护多个RNN（不同的时间范围和间隔）来预测负载。尽管这种粗粒度的RNN不太准确，但是减少了DBMS必须在运行时维护的训练数据的大小和预测所需的开销。</li>\n</ul>\n<h2 id=\"Action-Planning-amp-Execution\"><a href=\"#Action-Planning-amp-Execution\" class=\"headerlink\" title=\"Action Planning &amp; Execution\"></a>Action Planning &amp; Execution</h2><ul>\n<li>将自动化部件与DBMS进行紧耦合可以使得各部分之间提供反馈。还可以将增强学习应用于并发控制和查询优化</li>\n<li><strong>Action Generation：Peloton</strong>会搜索可能提升性能的Action，并且将action及其调用后对系统的影响记录在catalog中。这种搜索是由预测模型引导的，这样系统就会寻找能够提供最大收益的操作。它还可以删除冗余操作，以减少搜索的复杂性。可以根据资源需求及使用情况决定分配多少个CPU核来执行action。Action资源分配的knob为增量更改而非绝对值。某些action还有相应的reverse action，如 add/drop index。</li>\n<li><strong>Action Generation:</strong> Peloton会搜索可能提升性能的Action，并且将action及其调用后对系统的影响记录在catalog中。这种搜索是由预测模型引导的，这样系统就会寻找能够提供最大收益的操作。它还可以删除冗余操作，以减少搜索的复杂性。可以根据资源需求及使用情况决定分配多少个CPU核来执行action。Action资源分配的knob为增量更改而非绝对值。某些action还有相应的reverse action，如 add/drop index。</li>\n<li>在RHCM之下，计划流程（planning process）被组织为树状，每一层包含某个时刻数据库可调用的action，系统根据这些action的成本效益（cost-benefit）来决定调用哪一个action，也有可能一个action都不调用。一种搜索方式是随机选择树上层次更深的action而非评估所有的action（参考alpha go的论文）。对当前数据库状态和预期负载效益更好的action更可能被考虑（加权），同时最近被reverse的action会被避免调用。</li>\n<li>一个action的开销(cost)是对部署（deploy）这个action的时间和数据库因此性能下降情况的估计。对于没有调用过的action的分析，通过回馈机制分析某一类型的action来改善。一个action的效益(benefit)是在执行（intsall）这个action后在查询延迟上带来的改变，即查询样例的开销加权总和，权重为预测出来的相应查询的到达率。而且时域（time horizon）也会作为权重考虑，这使得直接模型（immediate model）会对最终的成本效益分析有更大的影响。</li>\n<li>此外，action对Peloton的内存使用率的影响也会在cost-benefit分析的时候考虑，任何导致DBMS内存超限的action都会被忽略。</li>\n<li>RHCM的horizon的值比较微妙，太短的话，在即将到来的负载峰值时DBMS来不及进行准备；太长的话，突然出现的问题无法及时得到优化解决，因为模型太慢了。除此之外，由于计算每个time epoch的cost-benefit是昂贵的，所以可以创建另一个深度神经网络从而用一个值函数来近似它们。</li>\n<li><strong>Deployment：</strong>Peloton支持非阻塞地deploying actions。例如，对表进行迁移或重组并不影响其它查询的访问。一些操作，比如添加索引，需要特别考虑，以防在action执行过程中因为因为数据被修改而产生影响。</li>\n<li>DBMS还处理来自集成机器学习组件的资源调度和争用问题。使用单独的联合处理器或GPU来处理繁重的计算任务将避免减慢DBMS的速度。否则，DBMS将不得不使用单独的机器，专门用于所有的预测和计划组件。这将使系统的设计复杂化，并由于协调而增加额外的开销。</li>\n</ul>\n<h2 id=\"Additional-Considerations\"><a href=\"#Additional-Considerations\" class=\"headerlink\" title=\"Additional Considerations\"></a>Additional Considerations</h2><ul>\n<li>DBA对于self-driving的不信任，可以将决策写成人类可读的形式，比如为什么添加索引，它的负载跟之前哪一个很相似，为何添加索引可以带来优化。另外，还需要提示DBA是否需要进行OLTP或者OLAP的优化，以及数据库的重要性优先级。Peloton也会像其它action一样记录DBA的手动操作，并且记录其效益，同时也允许DBA决定此记录何时过时，以防止消除误操作带来长期的影响。</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"介绍\"><a href=\"#介绍\" class=\"headerlink\" title=\"介绍\"></a>介绍</h1><ul>\n<li>以往数据库调优是 DBA 在问题发生后进行调整，self-driving （自治）数据库不仅优化当前工作负载，还可以预测以后的负载情况，从而事先做好准备，并且可以为现代高性能数据库提供更多复杂的新的优化方案。Peloton 通过深度学习实现了self-driving。</li>\n<li>现存的自动调优技术例如：Self-Tuning 物理数据库技术，自动选择索引、自动对表分区存储、自动创建和更新物化视图。自动选择底层存储方式（H2O， 2014），自动设置数据库配置参数，拷贝并及时更新所需索引的DataBase Cracking 技术，云数据库动态资源配置等等。但以上都只用于解决单一的问题，没有从全局考虑，而且 DBA 不一定能了解那么多方面去修复或优化一个系统，而且无法预测未来的负载从而提前做出决策。</li>\n</ul>\n<h1 id=\"问题概述\"><a href=\"#问题概述\" class=\"headerlink\" title=\"问题概述\"></a>问题概述</h1><ul>\n<li>了解应用的工作负载，HTAP（hybrid transaction analytical processing）可能执行事务和查询的时间几乎是同时的，所以不能用为 OLAP 和 OLTP 分别创建一个数据库的方法。HTAP 可自动的选择是使用 OLAP 还是 OLTP 的方式来优化。</li>\n<li>需要预测资源使用率的趋势。如错开高峰时段进行更新，对即将可能出现的问题提前告警。</li>\n<li>有了预测能力之后，DBMS 需要为预计的负载情况选择合适的优化方式。Self-driving 不支持需要数据库外部信息（如权限，数据清理和版本控制）的 DBA 任务，支持以下这些操作。对于每一个优化动作，DBMS 不仅需要估计其部署后的开销，还要估计部署它所需要的开销。<br><img src=\"/images/Self-Driving-Actions.jpg\" alt=\"Self-Driving Actions\"></li>\n<li>需要确定何时生成及采用相应的优化动作。即需要动态学习和改变，以适应负载的改变。</li>\n<li>两个额外的限制：代码不能因为上层需求改变而需要重构；它不能依赖于仅支持某些编程环境的程序分析工具。</li>\n</ul>","more":"<h1 id=\"Self-Driving-架构\"><a href=\"#Self-Driving-架构\" class=\"headerlink\" title=\"Self-Driving 架构\"></a>Self-Driving 架构</h1><ul>\n<li>现存的数据库在修改表1 中的Actions时常常需要重启，并且速度也比较慢。自研一个新的DBMS架构能很好的嵌入self-driving组件，并且提供更细粒度的控制。使用多版本并发控制（MVCC）来使得 OLTP 事务不会阻塞 OLAP 查询。使用内存管理、lock-free数据结构和flexible layout使得HTAP工作负载可以快速执行(即 Peloton 的实现)。<br><img src=\"/images/Self-Driving-Architecture.jpg\" alt=\"Self-Driving-Architecture\"></li>\n<li>Peloton架构如Figure 1，系统在不需要任何除环境（例如内存上限，目录路径等）外的其它信息就可以实现自动学习如何降低延迟（数据库最重要的性能指标），目前主要考虑延迟，其它的指标（分布式环境服务开销和能耗）可通过增加限制来优化。</li>\n<li>Peloton中有一个Workload Monitor来监控事件流的资源使用情况和DBMS /OS遥测数据、优化动作的问题出现和结束时机。之后通过这些数据预测负载情况，找出系统瓶颈和其它问题（如索引丢失，节点过载）然后选择最佳执行动作，并且执行的同时进行检测和学习。</li>\n</ul>\n<h2 id=\"负载分类\"><a href=\"#负载分类\" class=\"headerlink\" title=\"负载分类\"></a>负载分类</h2><ul>\n<li>第一个功能组件是通过无监督学习的方式将具有相似特性的应用查询进行聚合，即对负载进行聚类，可以减少模型数量，更容易预测应用行为。Peloton最初的实现是DBSCAN算法（原本用于聚合OLTP负载）。</li>\n<li>一个很大的问题就是用什么查询特性来进行聚类，有两种：一是查询runtime metrics，虽然这对可以在不需要理解其意义的情况下进行聚类，但是其对数据库内容和底层物理设计的变化更敏感，对高并发的负载也会出现类似的问题；二是查询逻辑语义，基于逻辑执行计划（如表和谓词）来分类，其独立于数据库内容和底层物理设计，但是需要考虑其是否能生成好的模型，并且为了runtime metrics的精度所付出的训练代价是值得的。不过，有可能模型变化不大，收敛快，且由于硬件加速使得开销小。</li>\n<li>还有一个问题就是如何确定类簇已经不再正确了。Peloton采用交叉验证（留一小部分数据集作为验证集）来确定何时类簇的错误率超过阈值，并且可以探索执行动作是如何影响查询的，从而决定何时重新训练模型。</li>\n</ul>\n<h2 id=\"负载预测\"><a href=\"#负载预测\" class=\"headerlink\" title=\"负载预测\"></a>负载预测</h2><ul>\n<li>为每一种负载的查询的出现率做预测，除了异常的热点之外，这种预测使系统能够识别负载周期性和数据增长趋势，从而为负载波动做准备。在DBMS执行查询之后，它用其簇标识符标记每个查询，然后填充一个直方图，该直方图跟踪在一个时间段内到达每个群集的查询的数量。Peloton使用这些数据来训练预测模型，这些模型估计了应用程序在将来执行的每个簇的查询数量。DBMS还在事件流中为其他DBMS/OS指标构建了类似的模型。</li>\n<li>ARM被用来做时序数据的线性关系分析，但是数据库可能被多个因素影响，并不符合线性假说。</li>\n<li>RNN对预测时序数据的非线性模型很有效。LSTM是RNN的一个变种，可以学习时序数据的周期性规律。</li>\n<li>RNN的准确性依赖于其训练数据集的大小，Peloton为每个Group维护多个RNN（不同的时间范围和间隔）来预测负载。尽管这种粗粒度的RNN不太准确，但是减少了DBMS必须在运行时维护的训练数据的大小和预测所需的开销。</li>\n</ul>\n<h2 id=\"Action-Planning-amp-Execution\"><a href=\"#Action-Planning-amp-Execution\" class=\"headerlink\" title=\"Action Planning &amp; Execution\"></a>Action Planning &amp; Execution</h2><ul>\n<li>将自动化部件与DBMS进行紧耦合可以使得各部分之间提供反馈。还可以将增强学习应用于并发控制和查询优化</li>\n<li><strong>Action Generation：Peloton</strong>会搜索可能提升性能的Action，并且将action及其调用后对系统的影响记录在catalog中。这种搜索是由预测模型引导的，这样系统就会寻找能够提供最大收益的操作。它还可以删除冗余操作，以减少搜索的复杂性。可以根据资源需求及使用情况决定分配多少个CPU核来执行action。Action资源分配的knob为增量更改而非绝对值。某些action还有相应的reverse action，如 add/drop index。</li>\n<li><strong>Action Generation:</strong> Peloton会搜索可能提升性能的Action，并且将action及其调用后对系统的影响记录在catalog中。这种搜索是由预测模型引导的，这样系统就会寻找能够提供最大收益的操作。它还可以删除冗余操作，以减少搜索的复杂性。可以根据资源需求及使用情况决定分配多少个CPU核来执行action。Action资源分配的knob为增量更改而非绝对值。某些action还有相应的reverse action，如 add/drop index。</li>\n<li>在RHCM之下，计划流程（planning process）被组织为树状，每一层包含某个时刻数据库可调用的action，系统根据这些action的成本效益（cost-benefit）来决定调用哪一个action，也有可能一个action都不调用。一种搜索方式是随机选择树上层次更深的action而非评估所有的action（参考alpha go的论文）。对当前数据库状态和预期负载效益更好的action更可能被考虑（加权），同时最近被reverse的action会被避免调用。</li>\n<li>一个action的开销(cost)是对部署（deploy）这个action的时间和数据库因此性能下降情况的估计。对于没有调用过的action的分析，通过回馈机制分析某一类型的action来改善。一个action的效益(benefit)是在执行（intsall）这个action后在查询延迟上带来的改变，即查询样例的开销加权总和，权重为预测出来的相应查询的到达率。而且时域（time horizon）也会作为权重考虑，这使得直接模型（immediate model）会对最终的成本效益分析有更大的影响。</li>\n<li>此外，action对Peloton的内存使用率的影响也会在cost-benefit分析的时候考虑，任何导致DBMS内存超限的action都会被忽略。</li>\n<li>RHCM的horizon的值比较微妙，太短的话，在即将到来的负载峰值时DBMS来不及进行准备；太长的话，突然出现的问题无法及时得到优化解决，因为模型太慢了。除此之外，由于计算每个time epoch的cost-benefit是昂贵的，所以可以创建另一个深度神经网络从而用一个值函数来近似它们。</li>\n<li><strong>Deployment：</strong>Peloton支持非阻塞地deploying actions。例如，对表进行迁移或重组并不影响其它查询的访问。一些操作，比如添加索引，需要特别考虑，以防在action执行过程中因为因为数据被修改而产生影响。</li>\n<li>DBMS还处理来自集成机器学习组件的资源调度和争用问题。使用单独的联合处理器或GPU来处理繁重的计算任务将避免减慢DBMS的速度。否则，DBMS将不得不使用单独的机器，专门用于所有的预测和计划组件。这将使系统的设计复杂化，并由于协调而增加额外的开销。</li>\n</ul>\n<h2 id=\"Additional-Considerations\"><a href=\"#Additional-Considerations\" class=\"headerlink\" title=\"Additional Considerations\"></a>Additional Considerations</h2><ul>\n<li>DBA对于self-driving的不信任，可以将决策写成人类可读的形式，比如为什么添加索引，它的负载跟之前哪一个很相似，为何添加索引可以带来优化。另外，还需要提示DBA是否需要进行OLTP或者OLAP的优化，以及数据库的重要性优先级。Peloton也会像其它action一样记录DBA的手动操作，并且记录其效益，同时也允许DBA决定此记录何时过时，以防止消除误操作带来长期的影响。</li>\n</ul>"},{"title":"os","date":"2019-01-16T03:08:00.000Z","_content":"\n\n6.828 operating system engneering\n==============================================\n\n\ngoals\n---------------------------------\n> Understand operating system design and implementation\n> Hands-on experience by building small O/S\n","source":"_posts/os.md","raw":"---\ntitle: os\ntags: operating system\ncategories: operating system \ndate: 2019-01-16 11:08:00\n---\n\n\n6.828 operating system engneering\n==============================================\n\n\ngoals\n---------------------------------\n> Understand operating system design and implementation\n> Hands-on experience by building small O/S\n","slug":"os","published":1,"updated":"2019-01-28T01:59:45.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr700003ap3nr16do0jg","content":"<h1 id=\"6-828-operating-system-engneering\"><a href=\"#6-828-operating-system-engneering\" class=\"headerlink\" title=\"6.828 operating system engneering\"></a>6.828 operating system engneering</h1><h2 id=\"goals\"><a href=\"#goals\" class=\"headerlink\" title=\"goals\"></a>goals</h2><blockquote>\n<p>Understand operating system design and implementation<br>Hands-on experience by building small O/S</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"6-828-operating-system-engneering\"><a href=\"#6-828-operating-system-engneering\" class=\"headerlink\" title=\"6.828 operating system engneering\"></a>6.828 operating system engneering</h1><h2 id=\"goals\"><a href=\"#goals\" class=\"headerlink\" title=\"goals\"></a>goals</h2><blockquote>\n<p>Understand operating system design and implementation<br>Hands-on experience by building small O/S</p>\n</blockquote>\n"},{"title":"scheduling algorithms","date":"2018-11-19T03:10:07.000Z","mathjax":true,"_content":"\n\nWorkflow scheduling in cloud: a survey\n=============================================\n\nModeling and definition\n--------------------------------\n\n![](/images/workflow-notation.png)\n\n![](/images/taxonomy-of-workflow-scheduling.png)\n\n\n### static workflow scheduling\n> 1. *Task selection* Select the first task from the scheduling list;\n> 2. *Resource selection* Allocate the task to selected resource.\n#### List scheduling heuristic\n> *static*: priorities are constructed before any task allocation\n> *dynamic*: the priorities of unscheduled tasks are recomputed after each task scheduling step\n\n\n\n\n\n\nList Scheduling Algorithm\n===========================================================\n\nCritical-Path algorithm\n------------------------------------------------------------\n> *Parallel sequencing and assembly line problems (1961)*\n> 自底向上，每次选择已经准备好的节点分配到准备好的机器上, 离 $exit$ 节点路径长的优先调度\n> 忽略消息传输时间\n\n![](/images/critical_path_schedule_alg.png)\n\n\n\nModified Critical-Path (MCP) algorithm\n------------------------------------------------------------\n> *Hypertool A Programming Aid for Message-Passing Systems (1990)*\n> *MCP Revisited (2000)*\n> 每次选择 $ALAP$ 时间最小的节点进行调度, 当有多台机器可用时, 选择调度后整体通信开销最小的\n\n![](/images/mcp_schedule_alg.png)\n\n\nDynamic-Level Scheduling (DLS) algorithm\n------------------------------------------------------------\n> *A Compile-Time Scheduling Heuristic for Interconnection-Constrained Heterogeneous Processor Architectures (1993)* \n> *Highest Levels First with Estimated Times (HLEFT) algorithm* : Just like *Critical-Path algorithm*\n> *Highest Dynamic Levels First with Estimated Times (HDLEFT) algorithm* \n> 先选就绪*P*, 再选合适的*task*, 或者两个同时考虑一起选的方式较优\n> *HDLEFT's inherent flaw*: 限制了一个可执行的任务只能从当前就绪的处理器中选择一个执行. 因为有 *global clock* 的存在 \n> *Dynamic Level Scheduling (DLS) algorithm*\n> *Static Level*: 当前节点到 *exit* 节点的所有执行时间之和, 不包括通信时间\n> *Dynamic Level*: $DL(N_i, P_j, \\sum) = SL(N_i) - \\max [DA(N_i, P_j, \\sum), TF(P_j, \\sum)]$\n\n\n\n\n\n","source":"_posts/scheduling-algorithms.md","raw":"---\ntitle: scheduling algorithms\ntags: \n  - scheduling algorithm\ncategories:\n  - scheduling algorithm\ndate: 2018-11-19 11:10:07\nmathjax: true\n---\n\n\nWorkflow scheduling in cloud: a survey\n=============================================\n\nModeling and definition\n--------------------------------\n\n![](/images/workflow-notation.png)\n\n![](/images/taxonomy-of-workflow-scheduling.png)\n\n\n### static workflow scheduling\n> 1. *Task selection* Select the first task from the scheduling list;\n> 2. *Resource selection* Allocate the task to selected resource.\n#### List scheduling heuristic\n> *static*: priorities are constructed before any task allocation\n> *dynamic*: the priorities of unscheduled tasks are recomputed after each task scheduling step\n\n\n\n\n\n\nList Scheduling Algorithm\n===========================================================\n\nCritical-Path algorithm\n------------------------------------------------------------\n> *Parallel sequencing and assembly line problems (1961)*\n> 自底向上，每次选择已经准备好的节点分配到准备好的机器上, 离 $exit$ 节点路径长的优先调度\n> 忽略消息传输时间\n\n![](/images/critical_path_schedule_alg.png)\n\n\n\nModified Critical-Path (MCP) algorithm\n------------------------------------------------------------\n> *Hypertool A Programming Aid for Message-Passing Systems (1990)*\n> *MCP Revisited (2000)*\n> 每次选择 $ALAP$ 时间最小的节点进行调度, 当有多台机器可用时, 选择调度后整体通信开销最小的\n\n![](/images/mcp_schedule_alg.png)\n\n\nDynamic-Level Scheduling (DLS) algorithm\n------------------------------------------------------------\n> *A Compile-Time Scheduling Heuristic for Interconnection-Constrained Heterogeneous Processor Architectures (1993)* \n> *Highest Levels First with Estimated Times (HLEFT) algorithm* : Just like *Critical-Path algorithm*\n> *Highest Dynamic Levels First with Estimated Times (HDLEFT) algorithm* \n> 先选就绪*P*, 再选合适的*task*, 或者两个同时考虑一起选的方式较优\n> *HDLEFT's inherent flaw*: 限制了一个可执行的任务只能从当前就绪的处理器中选择一个执行. 因为有 *global clock* 的存在 \n> *Dynamic Level Scheduling (DLS) algorithm*\n> *Static Level*: 当前节点到 *exit* 节点的所有执行时间之和, 不包括通信时间\n> *Dynamic Level*: $DL(N_i, P_j, \\sum) = SL(N_i) - \\max [DA(N_i, P_j, \\sum), TF(P_j, \\sum)]$\n\n\n\n\n\n","slug":"scheduling-algorithms","published":1,"updated":"2019-01-28T01:59:45.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr7b0007ap3n28kht67z","content":"<h1 id=\"Workflow-scheduling-in-cloud-a-survey\"><a href=\"#Workflow-scheduling-in-cloud-a-survey\" class=\"headerlink\" title=\"Workflow scheduling in cloud: a survey\"></a>Workflow scheduling in cloud: a survey</h1><h2 id=\"Modeling-and-definition\"><a href=\"#Modeling-and-definition\" class=\"headerlink\" title=\"Modeling and definition\"></a>Modeling and definition</h2><p><img src=\"/images/workflow-notation.png\" alt=\"\"></p>\n<p><img src=\"/images/taxonomy-of-workflow-scheduling.png\" alt=\"\"></p>\n<h3 id=\"static-workflow-scheduling\"><a href=\"#static-workflow-scheduling\" class=\"headerlink\" title=\"static workflow scheduling\"></a>static workflow scheduling</h3><blockquote>\n<ol>\n<li><em>Task selection</em> Select the first task from the scheduling list;</li>\n<li><em>Resource selection</em> Allocate the task to selected resource.</li>\n</ol>\n</blockquote>\n<h4 id=\"List-scheduling-heuristic\"><a href=\"#List-scheduling-heuristic\" class=\"headerlink\" title=\"List scheduling heuristic\"></a>List scheduling heuristic</h4><blockquote>\n<p><em>static</em>: priorities are constructed before any task allocation<br><em>dynamic</em>: the priorities of unscheduled tasks are recomputed after each task scheduling step</p>\n</blockquote>\n<h1 id=\"List-Scheduling-Algorithm\"><a href=\"#List-Scheduling-Algorithm\" class=\"headerlink\" title=\"List Scheduling Algorithm\"></a>List Scheduling Algorithm</h1><h2 id=\"Critical-Path-algorithm\"><a href=\"#Critical-Path-algorithm\" class=\"headerlink\" title=\"Critical-Path algorithm\"></a>Critical-Path algorithm</h2><blockquote>\n<p><em>Parallel sequencing and assembly line problems (1961)</em><br>自底向上，每次选择已经准备好的节点分配到准备好的机器上, 离 $exit$ 节点路径长的优先调度<br>忽略消息传输时间</p>\n</blockquote>\n<p><img src=\"/images/critical_path_schedule_alg.png\" alt=\"\"></p>\n<h2 id=\"Modified-Critical-Path-MCP-algorithm\"><a href=\"#Modified-Critical-Path-MCP-algorithm\" class=\"headerlink\" title=\"Modified Critical-Path (MCP) algorithm\"></a>Modified Critical-Path (MCP) algorithm</h2><blockquote>\n<p><em>Hypertool A Programming Aid for Message-Passing Systems (1990)</em><br><em>MCP Revisited (2000)</em><br>每次选择 $ALAP$ 时间最小的节点进行调度, 当有多台机器可用时, 选择调度后整体通信开销最小的</p>\n</blockquote>\n<p><img src=\"/images/mcp_schedule_alg.png\" alt=\"\"></p>\n<h2 id=\"Dynamic-Level-Scheduling-DLS-algorithm\"><a href=\"#Dynamic-Level-Scheduling-DLS-algorithm\" class=\"headerlink\" title=\"Dynamic-Level Scheduling (DLS) algorithm\"></a>Dynamic-Level Scheduling (DLS) algorithm</h2><blockquote>\n<p><em>A Compile-Time Scheduling Heuristic for Interconnection-Constrained Heterogeneous Processor Architectures (1993)</em><br><em>Highest Levels First with Estimated Times (HLEFT) algorithm</em> : Just like <em>Critical-Path algorithm</em><br><em>Highest Dynamic Levels First with Estimated Times (HDLEFT) algorithm</em><br>先选就绪<em>P</em>, 再选合适的<em>task</em>, 或者两个同时考虑一起选的方式较优<br><em>HDLEFT’s inherent flaw</em>: 限制了一个可执行的任务只能从当前就绪的处理器中选择一个执行. 因为有 <em>global clock</em> 的存在<br><em>Dynamic Level Scheduling (DLS) algorithm</em><br><em>Static Level</em>: 当前节点到 <em>exit</em> 节点的所有执行时间之和, 不包括通信时间<br><em>Dynamic Level</em>: $DL(N_i, P_j, \\sum) = SL(N_i) - \\max [DA(N_i, P_j, \\sum), TF(P_j, \\sum)]$</p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Workflow-scheduling-in-cloud-a-survey\"><a href=\"#Workflow-scheduling-in-cloud-a-survey\" class=\"headerlink\" title=\"Workflow scheduling in cloud: a survey\"></a>Workflow scheduling in cloud: a survey</h1><h2 id=\"Modeling-and-definition\"><a href=\"#Modeling-and-definition\" class=\"headerlink\" title=\"Modeling and definition\"></a>Modeling and definition</h2><p><img src=\"/images/workflow-notation.png\" alt=\"\"></p>\n<p><img src=\"/images/taxonomy-of-workflow-scheduling.png\" alt=\"\"></p>\n<h3 id=\"static-workflow-scheduling\"><a href=\"#static-workflow-scheduling\" class=\"headerlink\" title=\"static workflow scheduling\"></a>static workflow scheduling</h3><blockquote>\n<ol>\n<li><em>Task selection</em> Select the first task from the scheduling list;</li>\n<li><em>Resource selection</em> Allocate the task to selected resource.</li>\n</ol>\n</blockquote>\n<h4 id=\"List-scheduling-heuristic\"><a href=\"#List-scheduling-heuristic\" class=\"headerlink\" title=\"List scheduling heuristic\"></a>List scheduling heuristic</h4><blockquote>\n<p><em>static</em>: priorities are constructed before any task allocation<br><em>dynamic</em>: the priorities of unscheduled tasks are recomputed after each task scheduling step</p>\n</blockquote>\n<h1 id=\"List-Scheduling-Algorithm\"><a href=\"#List-Scheduling-Algorithm\" class=\"headerlink\" title=\"List Scheduling Algorithm\"></a>List Scheduling Algorithm</h1><h2 id=\"Critical-Path-algorithm\"><a href=\"#Critical-Path-algorithm\" class=\"headerlink\" title=\"Critical-Path algorithm\"></a>Critical-Path algorithm</h2><blockquote>\n<p><em>Parallel sequencing and assembly line problems (1961)</em><br>自底向上，每次选择已经准备好的节点分配到准备好的机器上, 离 $exit$ 节点路径长的优先调度<br>忽略消息传输时间</p>\n</blockquote>\n<p><img src=\"/images/critical_path_schedule_alg.png\" alt=\"\"></p>\n<h2 id=\"Modified-Critical-Path-MCP-algorithm\"><a href=\"#Modified-Critical-Path-MCP-algorithm\" class=\"headerlink\" title=\"Modified Critical-Path (MCP) algorithm\"></a>Modified Critical-Path (MCP) algorithm</h2><blockquote>\n<p><em>Hypertool A Programming Aid for Message-Passing Systems (1990)</em><br><em>MCP Revisited (2000)</em><br>每次选择 $ALAP$ 时间最小的节点进行调度, 当有多台机器可用时, 选择调度后整体通信开销最小的</p>\n</blockquote>\n<p><img src=\"/images/mcp_schedule_alg.png\" alt=\"\"></p>\n<h2 id=\"Dynamic-Level-Scheduling-DLS-algorithm\"><a href=\"#Dynamic-Level-Scheduling-DLS-algorithm\" class=\"headerlink\" title=\"Dynamic-Level Scheduling (DLS) algorithm\"></a>Dynamic-Level Scheduling (DLS) algorithm</h2><blockquote>\n<p><em>A Compile-Time Scheduling Heuristic for Interconnection-Constrained Heterogeneous Processor Architectures (1993)</em><br><em>Highest Levels First with Estimated Times (HLEFT) algorithm</em> : Just like <em>Critical-Path algorithm</em><br><em>Highest Dynamic Levels First with Estimated Times (HDLEFT) algorithm</em><br>先选就绪<em>P</em>, 再选合适的<em>task</em>, 或者两个同时考虑一起选的方式较优<br><em>HDLEFT’s inherent flaw</em>: 限制了一个可执行的任务只能从当前就绪的处理器中选择一个执行. 因为有 <em>global clock</em> 的存在<br><em>Dynamic Level Scheduling (DLS) algorithm</em><br><em>Static Level</em>: 当前节点到 <em>exit</em> 节点的所有执行时间之和, 不包括通信时间<br><em>Dynamic Level</em>: $DL(N_i, P_j, \\sum) = SL(N_i) - \\max [DA(N_i, P_j, \\sum), TF(P_j, \\sum)]$</p>\n</blockquote>\n"},{"title":"《统计学习方法》一. 概论","date":"2018-11-07T13:04:54.000Z","mathjax":true,"_content":"\n前言\n===========\n+ 只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向\n+ 学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 --- Herbert A. Simon\n\n\n统计学习\n===========\n+ 统计学习的特点，对象，目的，方法，研究\n+ 本章主要将监督学习\n\n## 监督学习\n+ 从给定有限的训练数据出发, 假定数据是独立同分布的, 而且假设模型属于某个假设空间, 应用某一评价准则, 从假设空间中选取一个最优的模型, 使它对已给训练数据及未知测试数据再给定评价标准意义下有最准确的预测.\n+ 基本概念：**input space, output space, feature space**\n+ 其它名词：**instance, feature vector, 联合概率分布**\n+ 假设空间: $ \\mathcal{F} = \\\\{ f\\;|  \\mathit{Y} = f(X) \\\\} $\n+ 最终变成求 $\\min\\limits_{f\\in\\mathcal{F}}R_{emp}(f)$ 或 $min_{f\\in\\mathcal{F}}R_{srm}(f)$ 的问题\n\n\n<!-- more -->\n\n## 统计学习三要素\n+ 方法 = 模型 + 策略 + 算法\n\n### 策略\n+ 损失函数: 0-1, quadratic, absolute, logarithmic\n+ 风险函数(期望损失): $ R_{exp}(f) = E_{p}[L(Y, f(X))] = \\int_{x\\times y}L(y, f(x))P(x,y)dxdy $\n+ 经验风险(经验损失)(empirical loss): $\\displaystyle R_{emp}(f) = \\frac{1}{N}\\sum_{i=1}^{N}L(y_i, f(x_i)) $\n+ 根据大数定理, 可用$R_{emp}(f)$估计$R_{exp}(f)$, 但由于现实中样本有限, 甚至很少，所以需要矫正$R_{emp}(f)$\n+ 经验风险最小化(ERM)和结构风险最小化(SRM)\n  + ERM: 用最优化方法求解$\\min\\limits_{f\\in\\mathcal{F}}R_{emp}(f)$\n    + 样本容量很小时容易过拟合(over-fitting), 但样本容量大时，学习效果很好\n    + 当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计(MLE)([证明](http://datahonor.com/2017/03/03/最大似然估计与经验风险最小化/)). \n  + SRM: 等价于正则化(regularizer), 即求 $\\min\\limits_{f\\in\\mathcal{F}}R_{srm}(f)$\n    + 结构风险: $\\displaystyle R_{srm}(f) = R_{emp}(f) + \\lambda J(f)$ \n      + 其中 $\\lambda J(f)$ 位正则化项或罚项(penalty term)\n      + $J(f)$是模型空间复杂度, 为定义在$\\mathcal{F}$上的泛函. $f$越复杂, $J(f)$越大.\n      + $\\lambda \\ge 0$是系数, 用以权衡经验风险和模型复杂度\n      + $R_{srm}(f)$小要求$R_{emp}(f)$和$J(f)$同时小, $R_{srm}(f)$小的模型往往对训练数据以及未知的测试数据都有较好的预测\n      + 当模型是条件概率分布, 损失函数是对数损失函数, 模型复杂度由模型的先验概率分布表示时，结构风险最小化就等价于最大后验概率估计(MAP)(证明)\n\n## 模型评估与选择\n+ 训练误差(**tranning error**): 模型关于训练数据集的平均损失\n+ 测试误差(**test error**): 模型关于测试数据集的平均损失, 反映了模型的预测能力(泛化能力 **generalization ability**)\n+ 过拟合: 所选模型参数过多, 对训练数据预测的很好, 对测试数据预测的很差\n+ 模型选择时要选择复杂度适当的模型, 防止过拟合.\n\n## 正则化与交叉验证\n+ 此为常用的两种模型选择方法\n\n### 正则化\n+ $\\min\\limits_{f\\in\\mathcal{F}}R_{srm}(f)$\n+ 正则化项: 一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大\n> 如参数向量$w$的$L_1$范数$\\parallel w_1 \\parallel$或$L_2$范数$\\frac{1}{2}\\parallel w_1 \\parallel^2$\n+ 模型越复杂, 先验概率越大\n\n### 交叉验证\n+ 样本充足时, 可随机切成训练集(用于训练模型), 验证集(用于模型选择, 选择预测误差最小的模型)和测试集(模型评估)\n+ 交叉验证: 重复使用数据, 反复切, 反复训练, 测试及模型选择\n+ 简单交叉验证: 随机切成训练集和测试集, 选测试误差最小的模型\n+ $S$折交叉验证(S-fold cross validation): 切成$S$份, 每次选$S-1$份训练, $1$份测试, 重复$S$次\n+ 留一交叉验证: $S=N$, 数据集为$N$, 数据集较少时用\n\n## 泛化能力\n+ 即模型$\\hat{f}$的预测能力, 用$R_{exp}(\\hat{f})$来表示\n+ 泛化误差上界: $R(f) \\le \\hat{R}(f) + \\varepsilon(d, N, \\delta)$\n> $R(f)$为泛化误差\n> $\\le$右边为泛化误差上界\n> $\\hat{R}(f)$为训练误差\n> $\\varepsilon(d, N, \\delta) = \\sqrt{\\frac{1}{2N}(\\log d + \\log \\frac{1}{\\delta})}$\n+ 训练误差小的模型, 泛化误差也会小\n\n## 生成模型与判别模型\n+ 监督学习的方法可以分为: 生成方法(**generative approach**)和判别方法(**discriminative approach**)\n+ 生成方法: 先学习$P(X,Y)$再求出$P(Y|X) = \\frac{P(X,Y)}{P(X)}$\n> 如:朴素贝叶斯法和隐马尔可夫模型\n+ 判别方法: 直接学习$f(X)$或$P(Y|X)$\n> 如:$k$近邻法, 感知机, 决策树,  逻辑斯蒂回归模型, 最大熵模型, 支持向量机, 提升方法和条件随机场等\n> 存在隐变量时, 判别方法不能用\n\n## 分类问题\n+ $P(Y|X)$作为分类器 \n+ 分类准确率(**accuracy**): 对于给定的测试数据集, 分类正确的样本数与总样本数之比\n+ 精确率(**precision**):$P = \\frac{TP}{TP+FP}$ \n> True, False, Positive, Negative\n+ 召回率(**recall**): $R = \\frac{TP}{TP+FN}$\n+ $P$和$R$的调和均值$F_1$: $\\frac{1}{F_1} = \\frac{1}{P} + \\frac{1}{R}$, 即$F_1 = \\frac{2TP}{2TP+FP+FN}$\n+ 许多统计学习方法可以用于分类\n> 如: $k$近邻法, 感知机, 朴素贝叶斯法, 决策树, 决策列表, 逻辑斯蒂回归模型, 支持向量机, 提升方法, 贝叶斯网络, 神经网络, Winnow等\n\n## 标注(tagging)问题\n+ 可以认为书分类问题的推广，也是更复杂的结构预测(**structure prediction**)问题的简单形式\n+ 输入一个观测序列$x_{N+1} = (x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, ... ,x_{N+1}^{(n)})^T$, 找到使条件概率$$P((y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, ... ,y_{N+1}^{(n)})|(x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, ... ,x_{N+1}^{(n)})$$最大的标记序列$y_{N+1} = (y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, ... ,y_{N+1}^{(n)})^T$\n> 常用的标注方法:隐马尔科夫模型`和条件随机场\n\n## 回归问题\n+ 等价于函数拟合: 选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据\n+ 分类\n> 按输入变量的个数: 一元回归和多元回归\n> 输入与输出变量的关系模型: 线性回归和非线性回归\n> 损失函数是平方损失函数时: 可用最小二乘法(**least squares**)求解\n\n\n","source":"_posts/statistical-learning-method-1.md","raw":"---\ntitle: 《统计学习方法》一. 概论\ntags:\n  - 统计学习方法\n  - machine learning\n  - book\ncategories:\n  - 统计学习方法\ndate: 2018-11-07 21:04:54\nmathjax: true\n---\n\n前言\n===========\n+ 只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向\n+ 学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 --- Herbert A. Simon\n\n\n统计学习\n===========\n+ 统计学习的特点，对象，目的，方法，研究\n+ 本章主要将监督学习\n\n## 监督学习\n+ 从给定有限的训练数据出发, 假定数据是独立同分布的, 而且假设模型属于某个假设空间, 应用某一评价准则, 从假设空间中选取一个最优的模型, 使它对已给训练数据及未知测试数据再给定评价标准意义下有最准确的预测.\n+ 基本概念：**input space, output space, feature space**\n+ 其它名词：**instance, feature vector, 联合概率分布**\n+ 假设空间: $ \\mathcal{F} = \\\\{ f\\;|  \\mathit{Y} = f(X) \\\\} $\n+ 最终变成求 $\\min\\limits_{f\\in\\mathcal{F}}R_{emp}(f)$ 或 $min_{f\\in\\mathcal{F}}R_{srm}(f)$ 的问题\n\n\n<!-- more -->\n\n## 统计学习三要素\n+ 方法 = 模型 + 策略 + 算法\n\n### 策略\n+ 损失函数: 0-1, quadratic, absolute, logarithmic\n+ 风险函数(期望损失): $ R_{exp}(f) = E_{p}[L(Y, f(X))] = \\int_{x\\times y}L(y, f(x))P(x,y)dxdy $\n+ 经验风险(经验损失)(empirical loss): $\\displaystyle R_{emp}(f) = \\frac{1}{N}\\sum_{i=1}^{N}L(y_i, f(x_i)) $\n+ 根据大数定理, 可用$R_{emp}(f)$估计$R_{exp}(f)$, 但由于现实中样本有限, 甚至很少，所以需要矫正$R_{emp}(f)$\n+ 经验风险最小化(ERM)和结构风险最小化(SRM)\n  + ERM: 用最优化方法求解$\\min\\limits_{f\\in\\mathcal{F}}R_{emp}(f)$\n    + 样本容量很小时容易过拟合(over-fitting), 但样本容量大时，学习效果很好\n    + 当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计(MLE)([证明](http://datahonor.com/2017/03/03/最大似然估计与经验风险最小化/)). \n  + SRM: 等价于正则化(regularizer), 即求 $\\min\\limits_{f\\in\\mathcal{F}}R_{srm}(f)$\n    + 结构风险: $\\displaystyle R_{srm}(f) = R_{emp}(f) + \\lambda J(f)$ \n      + 其中 $\\lambda J(f)$ 位正则化项或罚项(penalty term)\n      + $J(f)$是模型空间复杂度, 为定义在$\\mathcal{F}$上的泛函. $f$越复杂, $J(f)$越大.\n      + $\\lambda \\ge 0$是系数, 用以权衡经验风险和模型复杂度\n      + $R_{srm}(f)$小要求$R_{emp}(f)$和$J(f)$同时小, $R_{srm}(f)$小的模型往往对训练数据以及未知的测试数据都有较好的预测\n      + 当模型是条件概率分布, 损失函数是对数损失函数, 模型复杂度由模型的先验概率分布表示时，结构风险最小化就等价于最大后验概率估计(MAP)(证明)\n\n## 模型评估与选择\n+ 训练误差(**tranning error**): 模型关于训练数据集的平均损失\n+ 测试误差(**test error**): 模型关于测试数据集的平均损失, 反映了模型的预测能力(泛化能力 **generalization ability**)\n+ 过拟合: 所选模型参数过多, 对训练数据预测的很好, 对测试数据预测的很差\n+ 模型选择时要选择复杂度适当的模型, 防止过拟合.\n\n## 正则化与交叉验证\n+ 此为常用的两种模型选择方法\n\n### 正则化\n+ $\\min\\limits_{f\\in\\mathcal{F}}R_{srm}(f)$\n+ 正则化项: 一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大\n> 如参数向量$w$的$L_1$范数$\\parallel w_1 \\parallel$或$L_2$范数$\\frac{1}{2}\\parallel w_1 \\parallel^2$\n+ 模型越复杂, 先验概率越大\n\n### 交叉验证\n+ 样本充足时, 可随机切成训练集(用于训练模型), 验证集(用于模型选择, 选择预测误差最小的模型)和测试集(模型评估)\n+ 交叉验证: 重复使用数据, 反复切, 反复训练, 测试及模型选择\n+ 简单交叉验证: 随机切成训练集和测试集, 选测试误差最小的模型\n+ $S$折交叉验证(S-fold cross validation): 切成$S$份, 每次选$S-1$份训练, $1$份测试, 重复$S$次\n+ 留一交叉验证: $S=N$, 数据集为$N$, 数据集较少时用\n\n## 泛化能力\n+ 即模型$\\hat{f}$的预测能力, 用$R_{exp}(\\hat{f})$来表示\n+ 泛化误差上界: $R(f) \\le \\hat{R}(f) + \\varepsilon(d, N, \\delta)$\n> $R(f)$为泛化误差\n> $\\le$右边为泛化误差上界\n> $\\hat{R}(f)$为训练误差\n> $\\varepsilon(d, N, \\delta) = \\sqrt{\\frac{1}{2N}(\\log d + \\log \\frac{1}{\\delta})}$\n+ 训练误差小的模型, 泛化误差也会小\n\n## 生成模型与判别模型\n+ 监督学习的方法可以分为: 生成方法(**generative approach**)和判别方法(**discriminative approach**)\n+ 生成方法: 先学习$P(X,Y)$再求出$P(Y|X) = \\frac{P(X,Y)}{P(X)}$\n> 如:朴素贝叶斯法和隐马尔可夫模型\n+ 判别方法: 直接学习$f(X)$或$P(Y|X)$\n> 如:$k$近邻法, 感知机, 决策树,  逻辑斯蒂回归模型, 最大熵模型, 支持向量机, 提升方法和条件随机场等\n> 存在隐变量时, 判别方法不能用\n\n## 分类问题\n+ $P(Y|X)$作为分类器 \n+ 分类准确率(**accuracy**): 对于给定的测试数据集, 分类正确的样本数与总样本数之比\n+ 精确率(**precision**):$P = \\frac{TP}{TP+FP}$ \n> True, False, Positive, Negative\n+ 召回率(**recall**): $R = \\frac{TP}{TP+FN}$\n+ $P$和$R$的调和均值$F_1$: $\\frac{1}{F_1} = \\frac{1}{P} + \\frac{1}{R}$, 即$F_1 = \\frac{2TP}{2TP+FP+FN}$\n+ 许多统计学习方法可以用于分类\n> 如: $k$近邻法, 感知机, 朴素贝叶斯法, 决策树, 决策列表, 逻辑斯蒂回归模型, 支持向量机, 提升方法, 贝叶斯网络, 神经网络, Winnow等\n\n## 标注(tagging)问题\n+ 可以认为书分类问题的推广，也是更复杂的结构预测(**structure prediction**)问题的简单形式\n+ 输入一个观测序列$x_{N+1} = (x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, ... ,x_{N+1}^{(n)})^T$, 找到使条件概率$$P((y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, ... ,y_{N+1}^{(n)})|(x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, ... ,x_{N+1}^{(n)})$$最大的标记序列$y_{N+1} = (y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, ... ,y_{N+1}^{(n)})^T$\n> 常用的标注方法:隐马尔科夫模型`和条件随机场\n\n## 回归问题\n+ 等价于函数拟合: 选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据\n+ 分类\n> 按输入变量的个数: 一元回归和多元回归\n> 输入与输出变量的关系模型: 线性回归和非线性回归\n> 损失函数是平方损失函数时: 可用最小二乘法(**least squares**)求解\n\n\n","slug":"statistical-learning-method-1","published":1,"updated":"2019-01-28T01:41:31.241Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr7e0009ap3n7j81hphs","content":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><ul>\n<li>只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向</li>\n<li>学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 — Herbert A. Simon</li>\n</ul>\n<h1 id=\"统计学习\"><a href=\"#统计学习\" class=\"headerlink\" title=\"统计学习\"></a>统计学习</h1><ul>\n<li>统计学习的特点，对象，目的，方法，研究</li>\n<li>本章主要将监督学习</li>\n</ul>\n<h2 id=\"监督学习\"><a href=\"#监督学习\" class=\"headerlink\" title=\"监督学习\"></a>监督学习</h2><ul>\n<li>从给定有限的训练数据出发, 假定数据是独立同分布的, 而且假设模型属于某个假设空间, 应用某一评价准则, 从假设空间中选取一个最优的模型, 使它对已给训练数据及未知测试数据再给定评价标准意义下有最准确的预测.</li>\n<li>基本概念：<strong>input space, output space, feature space</strong></li>\n<li>其它名词：<strong>instance, feature vector, 联合概率分布</strong></li>\n<li>假设空间: $ \\mathcal{F} = \\{ f\\;|  \\mathit{Y} = f(X) \\} $</li>\n<li>最终变成求 $\\min\\limits_{f\\in\\mathcal{F}}R_{emp}(f)$ 或 $min_{f\\in\\mathcal{F}}R_{srm}(f)$ 的问题</li>\n</ul>\n<a id=\"more\"></a>\n<h2 id=\"统计学习三要素\"><a href=\"#统计学习三要素\" class=\"headerlink\" title=\"统计学习三要素\"></a>统计学习三要素</h2><ul>\n<li>方法 = 模型 + 策略 + 算法</li>\n</ul>\n<h3 id=\"策略\"><a href=\"#策略\" class=\"headerlink\" title=\"策略\"></a>策略</h3><ul>\n<li>损失函数: 0-1, quadratic, absolute, logarithmic</li>\n<li>风险函数(期望损失): $ R_{exp}(f) = E_{p}[L(Y, f(X))] = \\int_{x\\times y}L(y, f(x))P(x,y)dxdy $</li>\n<li>经验风险(经验损失)(empirical loss): $\\displaystyle R_{emp}(f) = \\frac{1}{N}\\sum_{i=1}^{N}L(y_i, f(x_i)) $</li>\n<li>根据大数定理, 可用$R_{emp}(f)$估计$R_{exp}(f)$, 但由于现实中样本有限, 甚至很少，所以需要矫正$R_{emp}(f)$</li>\n<li>经验风险最小化(ERM)和结构风险最小化(SRM)<ul>\n<li>ERM: 用最优化方法求解$\\min\\limits_{f\\in\\mathcal{F}}R_{emp}(f)$<ul>\n<li>样本容量很小时容易过拟合(over-fitting), 但样本容量大时，学习效果很好</li>\n<li>当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计(MLE)(<a href=\"http://datahonor.com/2017/03/03/最大似然估计与经验风险最小化/\" target=\"_blank\" rel=\"noopener\">证明</a>). </li>\n</ul>\n</li>\n<li>SRM: 等价于正则化(regularizer), 即求 $\\min\\limits_{f\\in\\mathcal{F}}R_{srm}(f)$<ul>\n<li>结构风险: $\\displaystyle R_{srm}(f) = R_{emp}(f) + \\lambda J(f)$ <ul>\n<li>其中 $\\lambda J(f)$ 位正则化项或罚项(penalty term)</li>\n<li>$J(f)$是模型空间复杂度, 为定义在$\\mathcal{F}$上的泛函. $f$越复杂, $J(f)$越大.</li>\n<li>$\\lambda \\ge 0$是系数, 用以权衡经验风险和模型复杂度</li>\n<li>$R_{srm}(f)$小要求$R_{emp}(f)$和$J(f)$同时小, $R_{srm}(f)$小的模型往往对训练数据以及未知的测试数据都有较好的预测</li>\n<li>当模型是条件概率分布, 损失函数是对数损失函数, 模型复杂度由模型的先验概率分布表示时，结构风险最小化就等价于最大后验概率估计(MAP)(证明)</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"模型评估与选择\"><a href=\"#模型评估与选择\" class=\"headerlink\" title=\"模型评估与选择\"></a>模型评估与选择</h2><ul>\n<li>训练误差(<strong>tranning error</strong>): 模型关于训练数据集的平均损失</li>\n<li>测试误差(<strong>test error</strong>): 模型关于测试数据集的平均损失, 反映了模型的预测能力(泛化能力 <strong>generalization ability</strong>)</li>\n<li>过拟合: 所选模型参数过多, 对训练数据预测的很好, 对测试数据预测的很差</li>\n<li>模型选择时要选择复杂度适当的模型, 防止过拟合.</li>\n</ul>\n<h2 id=\"正则化与交叉验证\"><a href=\"#正则化与交叉验证\" class=\"headerlink\" title=\"正则化与交叉验证\"></a>正则化与交叉验证</h2><ul>\n<li>此为常用的两种模型选择方法</li>\n</ul>\n<h3 id=\"正则化\"><a href=\"#正则化\" class=\"headerlink\" title=\"正则化\"></a>正则化</h3><ul>\n<li>$\\min\\limits_{f\\in\\mathcal{F}}R_{srm}(f)$</li>\n<li>正则化项: 一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大<blockquote>\n<p>如参数向量$w$的$L_1$范数$\\parallel w_1 \\parallel$或$L_2$范数$\\frac{1}{2}\\parallel w_1 \\parallel^2$</p>\n</blockquote>\n</li>\n<li>模型越复杂, 先验概率越大</li>\n</ul>\n<h3 id=\"交叉验证\"><a href=\"#交叉验证\" class=\"headerlink\" title=\"交叉验证\"></a>交叉验证</h3><ul>\n<li>样本充足时, 可随机切成训练集(用于训练模型), 验证集(用于模型选择, 选择预测误差最小的模型)和测试集(模型评估)</li>\n<li>交叉验证: 重复使用数据, 反复切, 反复训练, 测试及模型选择</li>\n<li>简单交叉验证: 随机切成训练集和测试集, 选测试误差最小的模型</li>\n<li>$S$折交叉验证(S-fold cross validation): 切成$S$份, 每次选$S-1$份训练, $1$份测试, 重复$S$次</li>\n<li>留一交叉验证: $S=N$, 数据集为$N$, 数据集较少时用</li>\n</ul>\n<h2 id=\"泛化能力\"><a href=\"#泛化能力\" class=\"headerlink\" title=\"泛化能力\"></a>泛化能力</h2><ul>\n<li>即模型$\\hat{f}$的预测能力, 用$R_{exp}(\\hat{f})$来表示</li>\n<li>泛化误差上界: $R(f) \\le \\hat{R}(f) + \\varepsilon(d, N, \\delta)$<blockquote>\n<p>$R(f)$为泛化误差<br>$\\le$右边为泛化误差上界<br>$\\hat{R}(f)$为训练误差<br>$\\varepsilon(d, N, \\delta) = \\sqrt{\\frac{1}{2N}(\\log d + \\log \\frac{1}{\\delta})}$</p>\n</blockquote>\n</li>\n<li>训练误差小的模型, 泛化误差也会小</li>\n</ul>\n<h2 id=\"生成模型与判别模型\"><a href=\"#生成模型与判别模型\" class=\"headerlink\" title=\"生成模型与判别模型\"></a>生成模型与判别模型</h2><ul>\n<li>监督学习的方法可以分为: 生成方法(<strong>generative approach</strong>)和判别方法(<strong>discriminative approach</strong>)</li>\n<li>生成方法: 先学习$P(X,Y)$再求出$P(Y|X) = \\frac{P(X,Y)}{P(X)}$<blockquote>\n<p>如:朴素贝叶斯法和隐马尔可夫模型</p>\n</blockquote>\n</li>\n<li>判别方法: 直接学习$f(X)$或$P(Y|X)$<blockquote>\n<p>如:$k$近邻法, 感知机, 决策树,  逻辑斯蒂回归模型, 最大熵模型, 支持向量机, 提升方法和条件随机场等<br>存在隐变量时, 判别方法不能用</p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"分类问题\"><a href=\"#分类问题\" class=\"headerlink\" title=\"分类问题\"></a>分类问题</h2><ul>\n<li>$P(Y|X)$作为分类器 </li>\n<li>分类准确率(<strong>accuracy</strong>): 对于给定的测试数据集, 分类正确的样本数与总样本数之比</li>\n<li>精确率(<strong>precision</strong>):$P = \\frac{TP}{TP+FP}$ <blockquote>\n<p>True, False, Positive, Negative</p>\n</blockquote>\n</li>\n<li>召回率(<strong>recall</strong>): $R = \\frac{TP}{TP+FN}$</li>\n<li>$P$和$R$的调和均值$F_1$: $\\frac{1}{F_1} = \\frac{1}{P} + \\frac{1}{R}$, 即$F_1 = \\frac{2TP}{2TP+FP+FN}$</li>\n<li>许多统计学习方法可以用于分类<blockquote>\n<p>如: $k$近邻法, 感知机, 朴素贝叶斯法, 决策树, 决策列表, 逻辑斯蒂回归模型, 支持向量机, 提升方法, 贝叶斯网络, 神经网络, Winnow等</p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"标注-tagging-问题\"><a href=\"#标注-tagging-问题\" class=\"headerlink\" title=\"标注(tagging)问题\"></a>标注(tagging)问题</h2><ul>\n<li>可以认为书分类问题的推广，也是更复杂的结构预测(<strong>structure prediction</strong>)问题的简单形式</li>\n<li>输入一个观测序列$x_{N+1} = (x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, … ,x_{N+1}^{(n)})^T$, 找到使条件概率$$P((y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, … ,y_{N+1}^{(n)})|(x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, … ,x_{N+1}^{(n)})$$最大的标记序列$y_{N+1} = (y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, … ,y_{N+1}^{(n)})^T$<blockquote>\n<p>常用的标注方法:隐马尔科夫模型`和条件随机场</p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"回归问题\"><a href=\"#回归问题\" class=\"headerlink\" title=\"回归问题\"></a>回归问题</h2><ul>\n<li>等价于函数拟合: 选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据</li>\n<li>分类<blockquote>\n<p>按输入变量的个数: 一元回归和多元回归<br>输入与输出变量的关系模型: 线性回归和非线性回归<br>损失函数是平方损失函数时: 可用最小二乘法(<strong>least squares</strong>)求解</p>\n</blockquote>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><ul>\n<li>只摘录关键知识点，不做详细笔记，仅为方便日后复习有个方向</li>\n<li>学习: 如果一个系统能够通过执行某个过程改进它的性能，这就是学习。 — Herbert A. Simon</li>\n</ul>\n<h1 id=\"统计学习\"><a href=\"#统计学习\" class=\"headerlink\" title=\"统计学习\"></a>统计学习</h1><ul>\n<li>统计学习的特点，对象，目的，方法，研究</li>\n<li>本章主要将监督学习</li>\n</ul>\n<h2 id=\"监督学习\"><a href=\"#监督学习\" class=\"headerlink\" title=\"监督学习\"></a>监督学习</h2><ul>\n<li>从给定有限的训练数据出发, 假定数据是独立同分布的, 而且假设模型属于某个假设空间, 应用某一评价准则, 从假设空间中选取一个最优的模型, 使它对已给训练数据及未知测试数据再给定评价标准意义下有最准确的预测.</li>\n<li>基本概念：<strong>input space, output space, feature space</strong></li>\n<li>其它名词：<strong>instance, feature vector, 联合概率分布</strong></li>\n<li>假设空间: $ \\mathcal{F} = \\{ f\\;|  \\mathit{Y} = f(X) \\} $</li>\n<li>最终变成求 $\\min\\limits_{f\\in\\mathcal{F}}R_{emp}(f)$ 或 $min_{f\\in\\mathcal{F}}R_{srm}(f)$ 的问题</li>\n</ul>","more":"<h2 id=\"统计学习三要素\"><a href=\"#统计学习三要素\" class=\"headerlink\" title=\"统计学习三要素\"></a>统计学习三要素</h2><ul>\n<li>方法 = 模型 + 策略 + 算法</li>\n</ul>\n<h3 id=\"策略\"><a href=\"#策略\" class=\"headerlink\" title=\"策略\"></a>策略</h3><ul>\n<li>损失函数: 0-1, quadratic, absolute, logarithmic</li>\n<li>风险函数(期望损失): $ R_{exp}(f) = E_{p}[L(Y, f(X))] = \\int_{x\\times y}L(y, f(x))P(x,y)dxdy $</li>\n<li>经验风险(经验损失)(empirical loss): $\\displaystyle R_{emp}(f) = \\frac{1}{N}\\sum_{i=1}^{N}L(y_i, f(x_i)) $</li>\n<li>根据大数定理, 可用$R_{emp}(f)$估计$R_{exp}(f)$, 但由于现实中样本有限, 甚至很少，所以需要矫正$R_{emp}(f)$</li>\n<li>经验风险最小化(ERM)和结构风险最小化(SRM)<ul>\n<li>ERM: 用最优化方法求解$\\min\\limits_{f\\in\\mathcal{F}}R_{emp}(f)$<ul>\n<li>样本容量很小时容易过拟合(over-fitting), 但样本容量大时，学习效果很好</li>\n<li>当模型是条件概率分布，损失函数是对数损失函数时，经验风险最小化就等价于极大似然估计(MLE)(<a href=\"http://datahonor.com/2017/03/03/最大似然估计与经验风险最小化/\" target=\"_blank\" rel=\"noopener\">证明</a>). </li>\n</ul>\n</li>\n<li>SRM: 等价于正则化(regularizer), 即求 $\\min\\limits_{f\\in\\mathcal{F}}R_{srm}(f)$<ul>\n<li>结构风险: $\\displaystyle R_{srm}(f) = R_{emp}(f) + \\lambda J(f)$ <ul>\n<li>其中 $\\lambda J(f)$ 位正则化项或罚项(penalty term)</li>\n<li>$J(f)$是模型空间复杂度, 为定义在$\\mathcal{F}$上的泛函. $f$越复杂, $J(f)$越大.</li>\n<li>$\\lambda \\ge 0$是系数, 用以权衡经验风险和模型复杂度</li>\n<li>$R_{srm}(f)$小要求$R_{emp}(f)$和$J(f)$同时小, $R_{srm}(f)$小的模型往往对训练数据以及未知的测试数据都有较好的预测</li>\n<li>当模型是条件概率分布, 损失函数是对数损失函数, 模型复杂度由模型的先验概率分布表示时，结构风险最小化就等价于最大后验概率估计(MAP)(证明)</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"模型评估与选择\"><a href=\"#模型评估与选择\" class=\"headerlink\" title=\"模型评估与选择\"></a>模型评估与选择</h2><ul>\n<li>训练误差(<strong>tranning error</strong>): 模型关于训练数据集的平均损失</li>\n<li>测试误差(<strong>test error</strong>): 模型关于测试数据集的平均损失, 反映了模型的预测能力(泛化能力 <strong>generalization ability</strong>)</li>\n<li>过拟合: 所选模型参数过多, 对训练数据预测的很好, 对测试数据预测的很差</li>\n<li>模型选择时要选择复杂度适当的模型, 防止过拟合.</li>\n</ul>\n<h2 id=\"正则化与交叉验证\"><a href=\"#正则化与交叉验证\" class=\"headerlink\" title=\"正则化与交叉验证\"></a>正则化与交叉验证</h2><ul>\n<li>此为常用的两种模型选择方法</li>\n</ul>\n<h3 id=\"正则化\"><a href=\"#正则化\" class=\"headerlink\" title=\"正则化\"></a>正则化</h3><ul>\n<li>$\\min\\limits_{f\\in\\mathcal{F}}R_{srm}(f)$</li>\n<li>正则化项: 一般是模型复杂度的单调递增函数，模型越复杂，正则化值越大<blockquote>\n<p>如参数向量$w$的$L_1$范数$\\parallel w_1 \\parallel$或$L_2$范数$\\frac{1}{2}\\parallel w_1 \\parallel^2$</p>\n</blockquote>\n</li>\n<li>模型越复杂, 先验概率越大</li>\n</ul>\n<h3 id=\"交叉验证\"><a href=\"#交叉验证\" class=\"headerlink\" title=\"交叉验证\"></a>交叉验证</h3><ul>\n<li>样本充足时, 可随机切成训练集(用于训练模型), 验证集(用于模型选择, 选择预测误差最小的模型)和测试集(模型评估)</li>\n<li>交叉验证: 重复使用数据, 反复切, 反复训练, 测试及模型选择</li>\n<li>简单交叉验证: 随机切成训练集和测试集, 选测试误差最小的模型</li>\n<li>$S$折交叉验证(S-fold cross validation): 切成$S$份, 每次选$S-1$份训练, $1$份测试, 重复$S$次</li>\n<li>留一交叉验证: $S=N$, 数据集为$N$, 数据集较少时用</li>\n</ul>\n<h2 id=\"泛化能力\"><a href=\"#泛化能力\" class=\"headerlink\" title=\"泛化能力\"></a>泛化能力</h2><ul>\n<li>即模型$\\hat{f}$的预测能力, 用$R_{exp}(\\hat{f})$来表示</li>\n<li>泛化误差上界: $R(f) \\le \\hat{R}(f) + \\varepsilon(d, N, \\delta)$<blockquote>\n<p>$R(f)$为泛化误差<br>$\\le$右边为泛化误差上界<br>$\\hat{R}(f)$为训练误差<br>$\\varepsilon(d, N, \\delta) = \\sqrt{\\frac{1}{2N}(\\log d + \\log \\frac{1}{\\delta})}$</p>\n</blockquote>\n</li>\n<li>训练误差小的模型, 泛化误差也会小</li>\n</ul>\n<h2 id=\"生成模型与判别模型\"><a href=\"#生成模型与判别模型\" class=\"headerlink\" title=\"生成模型与判别模型\"></a>生成模型与判别模型</h2><ul>\n<li>监督学习的方法可以分为: 生成方法(<strong>generative approach</strong>)和判别方法(<strong>discriminative approach</strong>)</li>\n<li>生成方法: 先学习$P(X,Y)$再求出$P(Y|X) = \\frac{P(X,Y)}{P(X)}$<blockquote>\n<p>如:朴素贝叶斯法和隐马尔可夫模型</p>\n</blockquote>\n</li>\n<li>判别方法: 直接学习$f(X)$或$P(Y|X)$<blockquote>\n<p>如:$k$近邻法, 感知机, 决策树,  逻辑斯蒂回归模型, 最大熵模型, 支持向量机, 提升方法和条件随机场等<br>存在隐变量时, 判别方法不能用</p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"分类问题\"><a href=\"#分类问题\" class=\"headerlink\" title=\"分类问题\"></a>分类问题</h2><ul>\n<li>$P(Y|X)$作为分类器 </li>\n<li>分类准确率(<strong>accuracy</strong>): 对于给定的测试数据集, 分类正确的样本数与总样本数之比</li>\n<li>精确率(<strong>precision</strong>):$P = \\frac{TP}{TP+FP}$ <blockquote>\n<p>True, False, Positive, Negative</p>\n</blockquote>\n</li>\n<li>召回率(<strong>recall</strong>): $R = \\frac{TP}{TP+FN}$</li>\n<li>$P$和$R$的调和均值$F_1$: $\\frac{1}{F_1} = \\frac{1}{P} + \\frac{1}{R}$, 即$F_1 = \\frac{2TP}{2TP+FP+FN}$</li>\n<li>许多统计学习方法可以用于分类<blockquote>\n<p>如: $k$近邻法, 感知机, 朴素贝叶斯法, 决策树, 决策列表, 逻辑斯蒂回归模型, 支持向量机, 提升方法, 贝叶斯网络, 神经网络, Winnow等</p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"标注-tagging-问题\"><a href=\"#标注-tagging-问题\" class=\"headerlink\" title=\"标注(tagging)问题\"></a>标注(tagging)问题</h2><ul>\n<li>可以认为书分类问题的推广，也是更复杂的结构预测(<strong>structure prediction</strong>)问题的简单形式</li>\n<li>输入一个观测序列$x_{N+1} = (x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, … ,x_{N+1}^{(n)})^T$, 找到使条件概率$$P((y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, … ,y_{N+1}^{(n)})|(x_{N+1}^{(1)}, x_{N+1}^{(2)}, x_{N+1}^{(3)}, … ,x_{N+1}^{(n)})$$最大的标记序列$y_{N+1} = (y_{N+1}^{(1)}, y_{N+1}^{(2)}, y_{N+1}^{(3)}, … ,y_{N+1}^{(n)})^T$<blockquote>\n<p>常用的标注方法:隐马尔科夫模型`和条件随机场</p>\n</blockquote>\n</li>\n</ul>\n<h2 id=\"回归问题\"><a href=\"#回归问题\" class=\"headerlink\" title=\"回归问题\"></a>回归问题</h2><ul>\n<li>等价于函数拟合: 选择一条函数曲线使其很好地拟合已知数据且很好地预测未知数据</li>\n<li>分类<blockquote>\n<p>按输入变量的个数: 一元回归和多元回归<br>输入与输出变量的关系模型: 线性回归和非线性回归<br>损失函数是平方损失函数时: 可用最小二乘法(<strong>least squares</strong>)求解</p>\n</blockquote>\n</li>\n</ul>"},{"title":"《统计学习方法》二. 感知机","date":"2018-11-09T02:51:47.000Z","mathjax":true,"_content":"\n感知机(preceptron)\n=============\n> 属于判别模型, 输入为实例的特征向量, 输出为实例的类别\n> 是一种线性分类模型\n\n## 感知机模型\n+ $f(x) = sign(\\omega\\cdot x + b), 其中sign(x) = \\begin{cases} +1, &{x \\ge 0} \\\\ -1, &{x \\lt 0} \\end{cases} $\n+ 线性分类器: $f(x) = \\lbrace f|f(x) = \\omega\\cdot x + b \\rbrace$\n\n## 感知机学习策略\n+ 数据集的线性可分性: 存在某个超平面$ S: \\omega\\cdot x + b = 0 $能够将数据集的正实例点和负实例点完全正确的划分到超平面的两侧\n> 即对所有实例$i$有: $y_i = \\begin{cases} +1, &{\\omega\\cdot x + b \\ge 0} \\\\ -1, &{\\omega\\cdot x + b\\lt 0} \\end{cases} $\n+ 感知机就是要找出这样一个超平面，即确定$\\omega$和$b$, 定义(经验)损失函数并将损失函数极小化\n> 损失函数: $\\displaystyle L(\\omega, b) = -\\sum_{x_i \\in M} y_i(\\omega\\cdot x_i + b)$\n> 其中$M$为所有误分类点的集合\n\n<!-- more -->\n\n## 感知机学习算法\n+ 即求解$\\displaystyle \\min_{\\omega, b} L(\\omega, b)$的最优化问题\n> 任意选取一个超平面$\\omega_0, b_0$, 然后用梯度下降法不断地极小化目标函数\n> 选取$y_i(\\omega\\cdot x_i + b) \\le 0$\n> $$ \\omega \\gets \\omega + \\eta y_i x_i$$ $$ b \\gets b + \\eta y_i $$\n> $\\eta(0\\le\\eta\\lt 0)$是步长, 又称为学习率\n+ 算法的收敛性证明\n> 即证明: 设数据集是线性可分的, 经过有限次迭代可以得到一个将训练数据集完全正确划分的分离超平面及感知机模型\n> 最终得到误分类次数$k \\le (\\frac{R}{\\gamma})^2$, 其中$\\displaystyle R = \\max_{1\\le i \\le N}\\parallel \\hat{x}_i \\parallel$\n> 当训练集线性不可分时, 算法不收敛, 迭代结果会发生震荡\n+ 对偶形式\n> 感知机模型$\\displaystyle f(x) = sign(\\sum_{j=1}^N \\alpha_j y_j x_j\\cdot x + b)$\n> 其中$\\alpha_i = n_i\\eta$, 且迭代过程为: $\\begin{cases} \\alpha_i & \\gets \\alpha_i + \\eta \\\\ b & \\gets b + \\eta y_i \\end{cases}$\n\n","source":"_posts/statistical-learning-method-2.md","raw":"---\ntitle: 《统计学习方法》二. 感知机\ntags:\n  - 统计学习方法\n  - machine learning\n  - book\ncategories:\n  - 统计学习方法\ndate: 2018-11-09 10:51:47\nmathjax: true\n---\n\n感知机(preceptron)\n=============\n> 属于判别模型, 输入为实例的特征向量, 输出为实例的类别\n> 是一种线性分类模型\n\n## 感知机模型\n+ $f(x) = sign(\\omega\\cdot x + b), 其中sign(x) = \\begin{cases} +1, &{x \\ge 0} \\\\ -1, &{x \\lt 0} \\end{cases} $\n+ 线性分类器: $f(x) = \\lbrace f|f(x) = \\omega\\cdot x + b \\rbrace$\n\n## 感知机学习策略\n+ 数据集的线性可分性: 存在某个超平面$ S: \\omega\\cdot x + b = 0 $能够将数据集的正实例点和负实例点完全正确的划分到超平面的两侧\n> 即对所有实例$i$有: $y_i = \\begin{cases} +1, &{\\omega\\cdot x + b \\ge 0} \\\\ -1, &{\\omega\\cdot x + b\\lt 0} \\end{cases} $\n+ 感知机就是要找出这样一个超平面，即确定$\\omega$和$b$, 定义(经验)损失函数并将损失函数极小化\n> 损失函数: $\\displaystyle L(\\omega, b) = -\\sum_{x_i \\in M} y_i(\\omega\\cdot x_i + b)$\n> 其中$M$为所有误分类点的集合\n\n<!-- more -->\n\n## 感知机学习算法\n+ 即求解$\\displaystyle \\min_{\\omega, b} L(\\omega, b)$的最优化问题\n> 任意选取一个超平面$\\omega_0, b_0$, 然后用梯度下降法不断地极小化目标函数\n> 选取$y_i(\\omega\\cdot x_i + b) \\le 0$\n> $$ \\omega \\gets \\omega + \\eta y_i x_i$$ $$ b \\gets b + \\eta y_i $$\n> $\\eta(0\\le\\eta\\lt 0)$是步长, 又称为学习率\n+ 算法的收敛性证明\n> 即证明: 设数据集是线性可分的, 经过有限次迭代可以得到一个将训练数据集完全正确划分的分离超平面及感知机模型\n> 最终得到误分类次数$k \\le (\\frac{R}{\\gamma})^2$, 其中$\\displaystyle R = \\max_{1\\le i \\le N}\\parallel \\hat{x}_i \\parallel$\n> 当训练集线性不可分时, 算法不收敛, 迭代结果会发生震荡\n+ 对偶形式\n> 感知机模型$\\displaystyle f(x) = sign(\\sum_{j=1}^N \\alpha_j y_j x_j\\cdot x + b)$\n> 其中$\\alpha_i = n_i\\eta$, 且迭代过程为: $\\begin{cases} \\alpha_i & \\gets \\alpha_i + \\eta \\\\ b & \\gets b + \\eta y_i \\end{cases}$\n\n","slug":"statistical-learning-method-2","published":1,"updated":"2019-01-28T01:41:31.241Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr7n000bap3nzi6mbfzu","content":"<h1 id=\"感知机-preceptron\"><a href=\"#感知机-preceptron\" class=\"headerlink\" title=\"感知机(preceptron)\"></a>感知机(preceptron)</h1><blockquote>\n<p>属于判别模型, 输入为实例的特征向量, 输出为实例的类别<br>是一种线性分类模型</p>\n</blockquote>\n<h2 id=\"感知机模型\"><a href=\"#感知机模型\" class=\"headerlink\" title=\"感知机模型\"></a>感知机模型</h2><ul>\n<li>$f(x) = sign(\\omega\\cdot x + b), 其中sign(x) = \\begin{cases} +1, &amp;{x \\ge 0} \\\\ -1, &amp;{x \\lt 0} \\end{cases} $</li>\n<li>线性分类器: $f(x) = \\lbrace f|f(x) = \\omega\\cdot x + b \\rbrace$</li>\n</ul>\n<h2 id=\"感知机学习策略\"><a href=\"#感知机学习策略\" class=\"headerlink\" title=\"感知机学习策略\"></a>感知机学习策略</h2><ul>\n<li>数据集的线性可分性: 存在某个超平面$ S: \\omega\\cdot x + b = 0 $能够将数据集的正实例点和负实例点完全正确的划分到超平面的两侧<blockquote>\n<p>即对所有实例$i$有: $y_i = \\begin{cases} +1, &amp;{\\omega\\cdot x + b \\ge 0} \\\\ -1, &amp;{\\omega\\cdot x + b\\lt 0} \\end{cases} $</p>\n</blockquote>\n</li>\n<li>感知机就是要找出这样一个超平面，即确定$\\omega$和$b$, 定义(经验)损失函数并将损失函数极小化<blockquote>\n<p>损失函数: $\\displaystyle L(\\omega, b) = -\\sum_{x_i \\in M} y_i(\\omega\\cdot x_i + b)$<br>其中$M$为所有误分类点的集合</p>\n</blockquote>\n</li>\n</ul>\n<a id=\"more\"></a>\n<h2 id=\"感知机学习算法\"><a href=\"#感知机学习算法\" class=\"headerlink\" title=\"感知机学习算法\"></a>感知机学习算法</h2><ul>\n<li>即求解$\\displaystyle \\min_{\\omega, b} L(\\omega, b)$的最优化问题<blockquote>\n<p>任意选取一个超平面$\\omega_0, b_0$, 然后用梯度下降法不断地极小化目标函数<br>选取$y_i(\\omega\\cdot x_i + b) \\le 0$<br>$$ \\omega \\gets \\omega + \\eta y_i x_i$$ $$ b \\gets b + \\eta y_i $$<br>$\\eta(0\\le\\eta\\lt 0)$是步长, 又称为学习率</p>\n</blockquote>\n</li>\n<li>算法的收敛性证明<blockquote>\n<p>即证明: 设数据集是线性可分的, 经过有限次迭代可以得到一个将训练数据集完全正确划分的分离超平面及感知机模型<br>最终得到误分类次数$k \\le (\\frac{R}{\\gamma})^2$, 其中$\\displaystyle R = \\max_{1\\le i \\le N}\\parallel \\hat{x}_i \\parallel$<br>当训练集线性不可分时, 算法不收敛, 迭代结果会发生震荡</p>\n</blockquote>\n</li>\n<li>对偶形式<blockquote>\n<p>感知机模型$\\displaystyle f(x) = sign(\\sum_{j=1}^N \\alpha_j y_j x_j\\cdot x + b)$<br>其中$\\alpha_i = n_i\\eta$, 且迭代过程为: $\\begin{cases} \\alpha_i &amp; \\gets \\alpha_i + \\eta \\\\ b &amp; \\gets b + \\eta y_i \\end{cases}$</p>\n</blockquote>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"<h1 id=\"感知机-preceptron\"><a href=\"#感知机-preceptron\" class=\"headerlink\" title=\"感知机(preceptron)\"></a>感知机(preceptron)</h1><blockquote>\n<p>属于判别模型, 输入为实例的特征向量, 输出为实例的类别<br>是一种线性分类模型</p>\n</blockquote>\n<h2 id=\"感知机模型\"><a href=\"#感知机模型\" class=\"headerlink\" title=\"感知机模型\"></a>感知机模型</h2><ul>\n<li>$f(x) = sign(\\omega\\cdot x + b), 其中sign(x) = \\begin{cases} +1, &amp;{x \\ge 0} \\\\ -1, &amp;{x \\lt 0} \\end{cases} $</li>\n<li>线性分类器: $f(x) = \\lbrace f|f(x) = \\omega\\cdot x + b \\rbrace$</li>\n</ul>\n<h2 id=\"感知机学习策略\"><a href=\"#感知机学习策略\" class=\"headerlink\" title=\"感知机学习策略\"></a>感知机学习策略</h2><ul>\n<li>数据集的线性可分性: 存在某个超平面$ S: \\omega\\cdot x + b = 0 $能够将数据集的正实例点和负实例点完全正确的划分到超平面的两侧<blockquote>\n<p>即对所有实例$i$有: $y_i = \\begin{cases} +1, &amp;{\\omega\\cdot x + b \\ge 0} \\\\ -1, &amp;{\\omega\\cdot x + b\\lt 0} \\end{cases} $</p>\n</blockquote>\n</li>\n<li>感知机就是要找出这样一个超平面，即确定$\\omega$和$b$, 定义(经验)损失函数并将损失函数极小化<blockquote>\n<p>损失函数: $\\displaystyle L(\\omega, b) = -\\sum_{x_i \\in M} y_i(\\omega\\cdot x_i + b)$<br>其中$M$为所有误分类点的集合</p>\n</blockquote>\n</li>\n</ul>","more":"<h2 id=\"感知机学习算法\"><a href=\"#感知机学习算法\" class=\"headerlink\" title=\"感知机学习算法\"></a>感知机学习算法</h2><ul>\n<li>即求解$\\displaystyle \\min_{\\omega, b} L(\\omega, b)$的最优化问题<blockquote>\n<p>任意选取一个超平面$\\omega_0, b_0$, 然后用梯度下降法不断地极小化目标函数<br>选取$y_i(\\omega\\cdot x_i + b) \\le 0$<br>$$ \\omega \\gets \\omega + \\eta y_i x_i$$ $$ b \\gets b + \\eta y_i $$<br>$\\eta(0\\le\\eta\\lt 0)$是步长, 又称为学习率</p>\n</blockquote>\n</li>\n<li>算法的收敛性证明<blockquote>\n<p>即证明: 设数据集是线性可分的, 经过有限次迭代可以得到一个将训练数据集完全正确划分的分离超平面及感知机模型<br>最终得到误分类次数$k \\le (\\frac{R}{\\gamma})^2$, 其中$\\displaystyle R = \\max_{1\\le i \\le N}\\parallel \\hat{x}_i \\parallel$<br>当训练集线性不可分时, 算法不收敛, 迭代结果会发生震荡</p>\n</blockquote>\n</li>\n<li>对偶形式<blockquote>\n<p>感知机模型$\\displaystyle f(x) = sign(\\sum_{j=1}^N \\alpha_j y_j x_j\\cdot x + b)$<br>其中$\\alpha_i = n_i\\eta$, 且迭代过程为: $\\begin{cases} \\alpha_i &amp; \\gets \\alpha_i + \\eta \\\\ b &amp; \\gets b + \\eta y_i \\end{cases}$</p>\n</blockquote>\n</li>\n</ul>"},{"title":"《统计学习方法》三. K近邻法","date":"2018-11-09T08:43:15.000Z","mathjax":true,"_content":"\n$k$-NN ($k$-nearest neighbor)\n==============\n> 一种基本的分类与回归的方法\n\n\n## 算法\n+ 实例 $x$ 所属的类$y$, 有: \n$$\\displaystyle y = \\arg\\max_{c_j}\\sum_{x_i \\in N_k(x)} I(y_i = c_j), \\;\\;\\;\\; i = 1,2,\\cdots ,N; \\;\\; j=1,2,\\cdots ,K$$\n+ $k=1$时为最近邻法\n\n## $k$近邻模型\n+ 模型三要素: 距离度量, $k$值的选择和分类决策规则的确定\n+ 距离度量\n  + 一般用欧式距离, 也可以是其它距离, 如$L_p$距离(Minkowski距离): $\\displaystyle L_p(x_i, x_j) = \\left(\\sum_{l = 1}^n |x_i^{(l)} - x_j^{(l)}|^p\\right)^{\\frac{1}{p}}$\n  > 欧式距离: $p=2$\n  > 曼哈顿距离: $p=1$\n  > 各个坐标距离的最大值: $p=\\infty$\n+ $k$的选择\n  + 较小: 近似误差小, 估计误差大\n  + 较大: 近似误差大, 估计误差小\n  + 应用中通常选取较小的$k$值, 采用交叉验证法选取最优的$k$值\n+ 分类决策规则\n  + 经验风险最小化: 即$\\displaystyle \\sum_{x_i \\in N_k(x)} I(y_i = c_j)$最大化\n\n## $k$近邻法的实现: $kd$树\n+ $kd$树是一种对$k$维空间进行存储以便对其进行快速检索的树形数据结构.\n+ $kd$树的每个节点对应于一个$k$维超矩形区域.\n+ 此处的$k$与$k$近邻法的$k$不同.\n+ $kd$树搜索的平均时间复杂度为$O(\\log N)$, 更适用于训练实例数远大于空间维数时的$k$近邻搜索.\n+ 当空间维数接近训练实例数时, 它的效率会迅速下降, 几乎接近线性扫描.\n\n","source":"_posts/statistical-learning-method-3.md","raw":"---\ntitle: 《统计学习方法》三. K近邻法\ntags:\n  - 统计学习方法\n  - machine learning\n  - book\ncategories:\n  - 统计学习方法\ndate: 2018-11-09 16:43:15\nmathjax: true\n---\n\n$k$-NN ($k$-nearest neighbor)\n==============\n> 一种基本的分类与回归的方法\n\n\n## 算法\n+ 实例 $x$ 所属的类$y$, 有: \n$$\\displaystyle y = \\arg\\max_{c_j}\\sum_{x_i \\in N_k(x)} I(y_i = c_j), \\;\\;\\;\\; i = 1,2,\\cdots ,N; \\;\\; j=1,2,\\cdots ,K$$\n+ $k=1$时为最近邻法\n\n## $k$近邻模型\n+ 模型三要素: 距离度量, $k$值的选择和分类决策规则的确定\n+ 距离度量\n  + 一般用欧式距离, 也可以是其它距离, 如$L_p$距离(Minkowski距离): $\\displaystyle L_p(x_i, x_j) = \\left(\\sum_{l = 1}^n |x_i^{(l)} - x_j^{(l)}|^p\\right)^{\\frac{1}{p}}$\n  > 欧式距离: $p=2$\n  > 曼哈顿距离: $p=1$\n  > 各个坐标距离的最大值: $p=\\infty$\n+ $k$的选择\n  + 较小: 近似误差小, 估计误差大\n  + 较大: 近似误差大, 估计误差小\n  + 应用中通常选取较小的$k$值, 采用交叉验证法选取最优的$k$值\n+ 分类决策规则\n  + 经验风险最小化: 即$\\displaystyle \\sum_{x_i \\in N_k(x)} I(y_i = c_j)$最大化\n\n## $k$近邻法的实现: $kd$树\n+ $kd$树是一种对$k$维空间进行存储以便对其进行快速检索的树形数据结构.\n+ $kd$树的每个节点对应于一个$k$维超矩形区域.\n+ 此处的$k$与$k$近邻法的$k$不同.\n+ $kd$树搜索的平均时间复杂度为$O(\\log N)$, 更适用于训练实例数远大于空间维数时的$k$近邻搜索.\n+ 当空间维数接近训练实例数时, 它的效率会迅速下降, 几乎接近线性扫描.\n\n","slug":"statistical-learning-method-3","published":1,"updated":"2019-01-28T01:41:31.241Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr7q000fap3nukat0q7e","content":"<h1 id=\"k-NN-k-nearest-neighbor\"><a href=\"#k-NN-k-nearest-neighbor\" class=\"headerlink\" title=\"$k$-NN ($k$-nearest neighbor)\"></a>$k$-NN ($k$-nearest neighbor)</h1><blockquote>\n<p>一种基本的分类与回归的方法</p>\n</blockquote>\n<h2 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h2><ul>\n<li>实例 $x$ 所属的类$y$, 有:<br>$$\\displaystyle y = \\arg\\max_{c_j}\\sum_{x_i \\in N_k(x)} I(y_i = c_j), \\;\\;\\;\\; i = 1,2,\\cdots ,N; \\;\\; j=1,2,\\cdots ,K$$</li>\n<li>$k=1$时为最近邻法</li>\n</ul>\n<h2 id=\"k-近邻模型\"><a href=\"#k-近邻模型\" class=\"headerlink\" title=\"$k$近邻模型\"></a>$k$近邻模型</h2><ul>\n<li>模型三要素: 距离度量, $k$值的选择和分类决策规则的确定</li>\n<li>距离度量<ul>\n<li>一般用欧式距离, 也可以是其它距离, 如$L_p$距离(Minkowski距离): $\\displaystyle L_p(x_i, x_j) = \\left(\\sum_{l = 1}^n |x_i^{(l)} - x_j^{(l)}|^p\\right)^{\\frac{1}{p}}$<blockquote>\n<p>欧式距离: $p=2$<br>曼哈顿距离: $p=1$<br>各个坐标距离的最大值: $p=\\infty$</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>$k$的选择<ul>\n<li>较小: 近似误差小, 估计误差大</li>\n<li>较大: 近似误差大, 估计误差小</li>\n<li>应用中通常选取较小的$k$值, 采用交叉验证法选取最优的$k$值</li>\n</ul>\n</li>\n<li>分类决策规则<ul>\n<li>经验风险最小化: 即$\\displaystyle \\sum_{x_i \\in N_k(x)} I(y_i = c_j)$最大化</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"k-近邻法的实现-kd-树\"><a href=\"#k-近邻法的实现-kd-树\" class=\"headerlink\" title=\"$k$近邻法的实现: $kd$树\"></a>$k$近邻法的实现: $kd$树</h2><ul>\n<li>$kd$树是一种对$k$维空间进行存储以便对其进行快速检索的树形数据结构.</li>\n<li>$kd$树的每个节点对应于一个$k$维超矩形区域.</li>\n<li>此处的$k$与$k$近邻法的$k$不同.</li>\n<li>$kd$树搜索的平均时间复杂度为$O(\\log N)$, 更适用于训练实例数远大于空间维数时的$k$近邻搜索.</li>\n<li>当空间维数接近训练实例数时, 它的效率会迅速下降, 几乎接近线性扫描.</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"k-NN-k-nearest-neighbor\"><a href=\"#k-NN-k-nearest-neighbor\" class=\"headerlink\" title=\"$k$-NN ($k$-nearest neighbor)\"></a>$k$-NN ($k$-nearest neighbor)</h1><blockquote>\n<p>一种基本的分类与回归的方法</p>\n</blockquote>\n<h2 id=\"算法\"><a href=\"#算法\" class=\"headerlink\" title=\"算法\"></a>算法</h2><ul>\n<li>实例 $x$ 所属的类$y$, 有:<br>$$\\displaystyle y = \\arg\\max_{c_j}\\sum_{x_i \\in N_k(x)} I(y_i = c_j), \\;\\;\\;\\; i = 1,2,\\cdots ,N; \\;\\; j=1,2,\\cdots ,K$$</li>\n<li>$k=1$时为最近邻法</li>\n</ul>\n<h2 id=\"k-近邻模型\"><a href=\"#k-近邻模型\" class=\"headerlink\" title=\"$k$近邻模型\"></a>$k$近邻模型</h2><ul>\n<li>模型三要素: 距离度量, $k$值的选择和分类决策规则的确定</li>\n<li>距离度量<ul>\n<li>一般用欧式距离, 也可以是其它距离, 如$L_p$距离(Minkowski距离): $\\displaystyle L_p(x_i, x_j) = \\left(\\sum_{l = 1}^n |x_i^{(l)} - x_j^{(l)}|^p\\right)^{\\frac{1}{p}}$<blockquote>\n<p>欧式距离: $p=2$<br>曼哈顿距离: $p=1$<br>各个坐标距离的最大值: $p=\\infty$</p>\n</blockquote>\n</li>\n</ul>\n</li>\n<li>$k$的选择<ul>\n<li>较小: 近似误差小, 估计误差大</li>\n<li>较大: 近似误差大, 估计误差小</li>\n<li>应用中通常选取较小的$k$值, 采用交叉验证法选取最优的$k$值</li>\n</ul>\n</li>\n<li>分类决策规则<ul>\n<li>经验风险最小化: 即$\\displaystyle \\sum_{x_i \\in N_k(x)} I(y_i = c_j)$最大化</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"k-近邻法的实现-kd-树\"><a href=\"#k-近邻法的实现-kd-树\" class=\"headerlink\" title=\"$k$近邻法的实现: $kd$树\"></a>$k$近邻法的实现: $kd$树</h2><ul>\n<li>$kd$树是一种对$k$维空间进行存储以便对其进行快速检索的树形数据结构.</li>\n<li>$kd$树的每个节点对应于一个$k$维超矩形区域.</li>\n<li>此处的$k$与$k$近邻法的$k$不同.</li>\n<li>$kd$树搜索的平均时间复杂度为$O(\\log N)$, 更适用于训练实例数远大于空间维数时的$k$近邻搜索.</li>\n<li>当空间维数接近训练实例数时, 它的效率会迅速下降, 几乎接近线性扫描.</li>\n</ul>\n"},{"title":"《统计学习方法》四. 朴素贝叶斯法","date":"2018-11-10T07:23:25.000Z","mathjax":true,"_content":"\n\n朴素贝叶斯法 \n=================\n+ 朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法 \n+ 朴素贝叶斯法与贝叶斯估计时不同的概念\n\n## 朴素贝叶斯法的学习与分类\n+ 朴素贝叶斯分类器可以表示为: \n$$\\displaystyle y = \\arg\\max_{c_k} P(Y=c_k) \\prod_j P(X^{(j)}=x^{(j)}|Y=c_k) $$   \n+ 即后验概率最大化\n+ 后验概率最大化的含义: 根据期望风险最小化准则可以得到后验概率最大化准则 \n\n## 朴素贝叶斯法的参数估计\n+ 极大似然法\n  + 在朴素贝叶斯法中, 学习意味着估计$P(Y=c_k)$和$P(X^{(j)}=x^{(j)}|Y=c_k)$\n  + 先验概率$P(Y=c_k)$的极大似然估计为: $\\displaystyle P(Y=c_k) = \\frac{\\displaystyle\\sum_{i=1}^N I(y_i = c_k)}{N}, \\;\\; k=1,2,\\cdots,K$\n  + 设第$j$个特征$x^{(j)}$可能取值的集合为$\\lbrace a_j1, a_j2, \\cdots, a_{jS_j} \\rbrace$, 条件概率$P(x^{(j)}=a_{jl} |y=c_k)$的极大似然估计是:\n  $$P(X^{(j)}=a_{jl} |Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k)}{\\displaystyle\\sum_{i=1}^N I(y_i = c_k)}$$\n  $$j=1,2,\\cdots,n; \\;\\; l=1,2,\\cdots,S_j; \\;\\; k=1,2,\\cdots,K$$\n \n+ 朴素贝叶斯算法\n+ 贝叶斯估计:\n> 极大似然估计可能出现所要估计的概率为$0$的情况, 这会影响到后验概率的计算结果, 使分类产生偏差, 解决这一问题的方法是采用贝叶斯估计\n  $$P_\\lambda (X^{(j)}=a_{jl} |Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k) + \\lambda}{\\displaystyle\\sum_{i=1}^N I(y_i = c_k) + S_j \\lambda } \\;\\;\\;\\;$$ \n  $$P_\\lambda (Y=c_k) = \\frac{\\displaystyle\\sum_{i=1}^N I(y_i = c_k) + \\lambda}{N + K\\lambda}$$\n  其中$\\lambda \\ge 0$, $\\lambda = 0$是极大似然估计, $\\lambda = 1$是拉普拉斯平滑(**Laplace smoothing**)\n\n\n\n\n\n\n\n\n","source":"_posts/statistical-learning-method-4.md","raw":"---\ntitle: 《统计学习方法》四. 朴素贝叶斯法\ntags:\n  - 统计学习方法\n  - machine learning\n  - book\ncategories:\n  - 统计学习方法\ndate: 2018-11-10 15:23:25\nmathjax: true\n---\n\n\n朴素贝叶斯法 \n=================\n+ 朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法 \n+ 朴素贝叶斯法与贝叶斯估计时不同的概念\n\n## 朴素贝叶斯法的学习与分类\n+ 朴素贝叶斯分类器可以表示为: \n$$\\displaystyle y = \\arg\\max_{c_k} P(Y=c_k) \\prod_j P(X^{(j)}=x^{(j)}|Y=c_k) $$   \n+ 即后验概率最大化\n+ 后验概率最大化的含义: 根据期望风险最小化准则可以得到后验概率最大化准则 \n\n## 朴素贝叶斯法的参数估计\n+ 极大似然法\n  + 在朴素贝叶斯法中, 学习意味着估计$P(Y=c_k)$和$P(X^{(j)}=x^{(j)}|Y=c_k)$\n  + 先验概率$P(Y=c_k)$的极大似然估计为: $\\displaystyle P(Y=c_k) = \\frac{\\displaystyle\\sum_{i=1}^N I(y_i = c_k)}{N}, \\;\\; k=1,2,\\cdots,K$\n  + 设第$j$个特征$x^{(j)}$可能取值的集合为$\\lbrace a_j1, a_j2, \\cdots, a_{jS_j} \\rbrace$, 条件概率$P(x^{(j)}=a_{jl} |y=c_k)$的极大似然估计是:\n  $$P(X^{(j)}=a_{jl} |Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k)}{\\displaystyle\\sum_{i=1}^N I(y_i = c_k)}$$\n  $$j=1,2,\\cdots,n; \\;\\; l=1,2,\\cdots,S_j; \\;\\; k=1,2,\\cdots,K$$\n \n+ 朴素贝叶斯算法\n+ 贝叶斯估计:\n> 极大似然估计可能出现所要估计的概率为$0$的情况, 这会影响到后验概率的计算结果, 使分类产生偏差, 解决这一问题的方法是采用贝叶斯估计\n  $$P_\\lambda (X^{(j)}=a_{jl} |Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k) + \\lambda}{\\displaystyle\\sum_{i=1}^N I(y_i = c_k) + S_j \\lambda } \\;\\;\\;\\;$$ \n  $$P_\\lambda (Y=c_k) = \\frac{\\displaystyle\\sum_{i=1}^N I(y_i = c_k) + \\lambda}{N + K\\lambda}$$\n  其中$\\lambda \\ge 0$, $\\lambda = 0$是极大似然估计, $\\lambda = 1$是拉普拉斯平滑(**Laplace smoothing**)\n\n\n\n\n\n\n\n\n","slug":"statistical-learning-method-4","published":1,"updated":"2019-01-28T01:41:31.241Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr7s000hap3ncw4a88gq","content":"<h1 id=\"朴素贝叶斯法\"><a href=\"#朴素贝叶斯法\" class=\"headerlink\" title=\"朴素贝叶斯法 \"></a>朴素贝叶斯法 </h1><ul>\n<li>朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法 </li>\n<li>朴素贝叶斯法与贝叶斯估计时不同的概念</li>\n</ul>\n<h2 id=\"朴素贝叶斯法的学习与分类\"><a href=\"#朴素贝叶斯法的学习与分类\" class=\"headerlink\" title=\"朴素贝叶斯法的学习与分类\"></a>朴素贝叶斯法的学习与分类</h2><ul>\n<li>朴素贝叶斯分类器可以表示为:<br>$$\\displaystyle y = \\arg\\max_{c_k} P(Y=c_k) \\prod_j P(X^{(j)}=x^{(j)}|Y=c_k) $$   </li>\n<li>即后验概率最大化</li>\n<li>后验概率最大化的含义: 根据期望风险最小化准则可以得到后验概率最大化准则 </li>\n</ul>\n<h2 id=\"朴素贝叶斯法的参数估计\"><a href=\"#朴素贝叶斯法的参数估计\" class=\"headerlink\" title=\"朴素贝叶斯法的参数估计\"></a>朴素贝叶斯法的参数估计</h2><ul>\n<li><p>极大似然法</p>\n<ul>\n<li>在朴素贝叶斯法中, 学习意味着估计$P(Y=c_k)$和$P(X^{(j)}=x^{(j)}|Y=c_k)$</li>\n<li>先验概率$P(Y=c_k)$的极大似然估计为: $\\displaystyle P(Y=c_k) = \\frac{\\displaystyle\\sum_{i=1}^N I(y_i = c_k)}{N}, \\;\\; k=1,2,\\cdots,K$</li>\n<li>设第$j$个特征$x^{(j)}$可能取值的集合为$\\lbrace a_j1, a_j2, \\cdots, a_{jS_j} \\rbrace$, 条件概率$P(x^{(j)}=a_{jl} |y=c_k)$的极大似然估计是:<br>$$P(X^{(j)}=a_{jl} |Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k)}{\\displaystyle\\sum_{i=1}^N I(y_i = c_k)}$$<br>$$j=1,2,\\cdots,n; \\;\\; l=1,2,\\cdots,S_j; \\;\\; k=1,2,\\cdots,K$$</li>\n</ul>\n</li>\n<li><p>朴素贝叶斯算法</p>\n</li>\n<li>贝叶斯估计:<blockquote>\n<p>极大似然估计可能出现所要估计的概率为$0$的情况, 这会影响到后验概率的计算结果, 使分类产生偏差, 解决这一问题的方法是采用贝叶斯估计<br>$$P_\\lambda (X^{(j)}=a_{jl} |Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k) + \\lambda}{\\displaystyle\\sum_{i=1}^N I(y_i = c_k) + S_j \\lambda } \\;\\;\\;\\;$$<br>$$P_\\lambda (Y=c_k) = \\frac{\\displaystyle\\sum_{i=1}^N I(y_i = c_k) + \\lambda}{N + K\\lambda}$$<br>其中$\\lambda \\ge 0$, $\\lambda = 0$是极大似然估计, $\\lambda = 1$是拉普拉斯平滑(<strong>Laplace smoothing</strong>)</p>\n</blockquote>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"朴素贝叶斯法\"><a href=\"#朴素贝叶斯法\" class=\"headerlink\" title=\"朴素贝叶斯法 \"></a>朴素贝叶斯法 </h1><ul>\n<li>朴素贝叶斯法是基于贝叶斯定理与特征条件独立假设的分类方法 </li>\n<li>朴素贝叶斯法与贝叶斯估计时不同的概念</li>\n</ul>\n<h2 id=\"朴素贝叶斯法的学习与分类\"><a href=\"#朴素贝叶斯法的学习与分类\" class=\"headerlink\" title=\"朴素贝叶斯法的学习与分类\"></a>朴素贝叶斯法的学习与分类</h2><ul>\n<li>朴素贝叶斯分类器可以表示为:<br>$$\\displaystyle y = \\arg\\max_{c_k} P(Y=c_k) \\prod_j P(X^{(j)}=x^{(j)}|Y=c_k) $$   </li>\n<li>即后验概率最大化</li>\n<li>后验概率最大化的含义: 根据期望风险最小化准则可以得到后验概率最大化准则 </li>\n</ul>\n<h2 id=\"朴素贝叶斯法的参数估计\"><a href=\"#朴素贝叶斯法的参数估计\" class=\"headerlink\" title=\"朴素贝叶斯法的参数估计\"></a>朴素贝叶斯法的参数估计</h2><ul>\n<li><p>极大似然法</p>\n<ul>\n<li>在朴素贝叶斯法中, 学习意味着估计$P(Y=c_k)$和$P(X^{(j)}=x^{(j)}|Y=c_k)$</li>\n<li>先验概率$P(Y=c_k)$的极大似然估计为: $\\displaystyle P(Y=c_k) = \\frac{\\displaystyle\\sum_{i=1}^N I(y_i = c_k)}{N}, \\;\\; k=1,2,\\cdots,K$</li>\n<li>设第$j$个特征$x^{(j)}$可能取值的集合为$\\lbrace a_j1, a_j2, \\cdots, a_{jS_j} \\rbrace$, 条件概率$P(x^{(j)}=a_{jl} |y=c_k)$的极大似然估计是:<br>$$P(X^{(j)}=a_{jl} |Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k)}{\\displaystyle\\sum_{i=1}^N I(y_i = c_k)}$$<br>$$j=1,2,\\cdots,n; \\;\\; l=1,2,\\cdots,S_j; \\;\\; k=1,2,\\cdots,K$$</li>\n</ul>\n</li>\n<li><p>朴素贝叶斯算法</p>\n</li>\n<li>贝叶斯估计:<blockquote>\n<p>极大似然估计可能出现所要估计的概率为$0$的情况, 这会影响到后验概率的计算结果, 使分类产生偏差, 解决这一问题的方法是采用贝叶斯估计<br>$$P_\\lambda (X^{(j)}=a_{jl} |Y=c_k) = \\frac{\\displaystyle \\sum_{i=1}^N I(x_i^{(j)}=a_{jl} , y_i=c_k) + \\lambda}{\\displaystyle\\sum_{i=1}^N I(y_i = c_k) + S_j \\lambda } \\;\\;\\;\\;$$<br>$$P_\\lambda (Y=c_k) = \\frac{\\displaystyle\\sum_{i=1}^N I(y_i = c_k) + \\lambda}{N + K\\lambda}$$<br>其中$\\lambda \\ge 0$, $\\lambda = 0$是极大似然估计, $\\lambda = 1$是拉普拉斯平滑(<strong>Laplace smoothing</strong>)</p>\n</blockquote>\n</li>\n</ul>\n"},{"title":"《统计学习方法》五.决策树","date":"2018-11-10T12:03:11.000Z","mathjax":true,"_content":"\n\n决策树\n================\n+ 决策树是一种基本的分类与回归方法\n+ 本质上是从训练数据集归纳出一组分类规则\n+ 决策树学习通常包括三个步骤: 特征选择, 决策树的生成和决策树的修剪\n+ 内部节点表示一个特征或属性, 叶节点表示一个类\n\n决策树模型与学习\n--------------------\n+ 损失函数通常是正则化的极大似然函数\n+ 需要自下而上进行剪枝, 去掉过于细分的叶节点, 使其回退到父节点, 甚至更高的节点, 避免过拟合, 使其有更好的泛化能力\n+ 决策树的生成只考虑局部最优, 决策树的生成则考虑全局最优\n\n特征选择\n--------------------\n+ 通常的特征选择的准则是信息增益或信息增益比\n+ 熵(**entropy**): $\\displaystyle H(p) = \\sum_{i=1}^n p_i \\log p_i$\n+ 条件熵(**conditional entropy**): $\\displaystyle H(Y|X) = \\sum_{i=1}^n p_i H(Y|X=x_i)$\n+ 当熵和条件熵中的概率由数据估计(特别是极大似然估计得到)时, 所对应的熵与条件熵分别称为经验熵与经验条件熵\n+ 信息增益表示得知特征$X$的信息而使得类$Y$的信息的不确定性减少的程度\n+ 特征$A$对训练数据集$D$的信息增益$g(D,A) = H(D) - H(D|A)$, 也成为互信息(**mutual information**)\n+ 信息增益比: \n  $$g_R (D,A) = \\frac{g(D,A)}{H_A(D)}$$ \n  其中，$H_A (D)$表示训练数据集$D$关于特征$A$的值的熵\n  $$\\displaystyle H_A (D) = -\\sum_{i=1}^n \\frac{|D_i|}{D} \\log_2 \\frac{|D_i|}{D}$$\n\n决策树的生成\n--------------------\n\n### ID3算法\n> 输入: 训练数据集D, 特征集A, 阈值\\varepsilon\n> 每次选择$ g(D,A) $最大的特征点递归构建, 直到所有特征的$g(D,A)$均很小($\\lt\\varepsilon$)或没有特征可以选择为止\n\n### C4.5算法\n+ 用信息增益比来选择特征\n\n\n决策树的剪枝\n--------------------\n+ 损失函数: $C_\\alpha (T) = C(T) + \\alpha |T|$, 其中 \n$$\\displaystyle C(T) = \\sum_{t=1}^{|T|}N_t H_t (T) \\;\\;\\;\\;\\;  H_t (T) = -\\sum_k \\frac{N_{tk}}{N_t} \\log \\frac{N_{tk}}{N_t}$$\n$N_{tk}$表示树$T$的某一叶节点$t$的第$k$类样本点的数量\n+ 若一组叶节点回缩前后的树分别为$T_B$和$T_A$, 当$C_\\alpha (T_A) \\le C_\\alpha (T_B)$时进行剪枝, 将父节点变为新的叶节点\n+ 利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择 \n\n\nCART算法\n-------------------\n> 分类与回归树(Classification and Regression Trees)\n> 递归构建二叉决策树再剪枝\n> 具体见《统计学习方法》\n\n### CART生成\n+ 回归树的生成: 用平方误差最小化准则, 最小二乘回归树生成算法\n+ 分类树的生成: 用基尼系数选择最优特征, 同时决定该特征的最优二值切分点\n\n### CART剪枝\n+ 首先从生成算法产生的决策树$T_0$底端开始不断剪枝, 直到$T_0$的根节点, 形成一个子树序列$\\lbrace T_0, T_1, \\cdots, T_n \\rbrace$; \n然后通过交叉验证法再独立的验证数据集上对子树序列进行测试, 从中选择最优子树\n\n\n\n\n\n\n","source":"_posts/statistical-learning-method-5.md","raw":"---\ntitle: 《统计学习方法》五.决策树\ntags:\n  - 统计学习方法\n  - machine learning\n  - book\ncategories:\n  - 统计学习方法\ndate: 2018-11-10 20:03:11\nmathjax: true\n---\n\n\n决策树\n================\n+ 决策树是一种基本的分类与回归方法\n+ 本质上是从训练数据集归纳出一组分类规则\n+ 决策树学习通常包括三个步骤: 特征选择, 决策树的生成和决策树的修剪\n+ 内部节点表示一个特征或属性, 叶节点表示一个类\n\n决策树模型与学习\n--------------------\n+ 损失函数通常是正则化的极大似然函数\n+ 需要自下而上进行剪枝, 去掉过于细分的叶节点, 使其回退到父节点, 甚至更高的节点, 避免过拟合, 使其有更好的泛化能力\n+ 决策树的生成只考虑局部最优, 决策树的生成则考虑全局最优\n\n特征选择\n--------------------\n+ 通常的特征选择的准则是信息增益或信息增益比\n+ 熵(**entropy**): $\\displaystyle H(p) = \\sum_{i=1}^n p_i \\log p_i$\n+ 条件熵(**conditional entropy**): $\\displaystyle H(Y|X) = \\sum_{i=1}^n p_i H(Y|X=x_i)$\n+ 当熵和条件熵中的概率由数据估计(特别是极大似然估计得到)时, 所对应的熵与条件熵分别称为经验熵与经验条件熵\n+ 信息增益表示得知特征$X$的信息而使得类$Y$的信息的不确定性减少的程度\n+ 特征$A$对训练数据集$D$的信息增益$g(D,A) = H(D) - H(D|A)$, 也成为互信息(**mutual information**)\n+ 信息增益比: \n  $$g_R (D,A) = \\frac{g(D,A)}{H_A(D)}$$ \n  其中，$H_A (D)$表示训练数据集$D$关于特征$A$的值的熵\n  $$\\displaystyle H_A (D) = -\\sum_{i=1}^n \\frac{|D_i|}{D} \\log_2 \\frac{|D_i|}{D}$$\n\n决策树的生成\n--------------------\n\n### ID3算法\n> 输入: 训练数据集D, 特征集A, 阈值\\varepsilon\n> 每次选择$ g(D,A) $最大的特征点递归构建, 直到所有特征的$g(D,A)$均很小($\\lt\\varepsilon$)或没有特征可以选择为止\n\n### C4.5算法\n+ 用信息增益比来选择特征\n\n\n决策树的剪枝\n--------------------\n+ 损失函数: $C_\\alpha (T) = C(T) + \\alpha |T|$, 其中 \n$$\\displaystyle C(T) = \\sum_{t=1}^{|T|}N_t H_t (T) \\;\\;\\;\\;\\;  H_t (T) = -\\sum_k \\frac{N_{tk}}{N_t} \\log \\frac{N_{tk}}{N_t}$$\n$N_{tk}$表示树$T$的某一叶节点$t$的第$k$类样本点的数量\n+ 若一组叶节点回缩前后的树分别为$T_B$和$T_A$, 当$C_\\alpha (T_A) \\le C_\\alpha (T_B)$时进行剪枝, 将父节点变为新的叶节点\n+ 利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择 \n\n\nCART算法\n-------------------\n> 分类与回归树(Classification and Regression Trees)\n> 递归构建二叉决策树再剪枝\n> 具体见《统计学习方法》\n\n### CART生成\n+ 回归树的生成: 用平方误差最小化准则, 最小二乘回归树生成算法\n+ 分类树的生成: 用基尼系数选择最优特征, 同时决定该特征的最优二值切分点\n\n### CART剪枝\n+ 首先从生成算法产生的决策树$T_0$底端开始不断剪枝, 直到$T_0$的根节点, 形成一个子树序列$\\lbrace T_0, T_1, \\cdots, T_n \\rbrace$; \n然后通过交叉验证法再独立的验证数据集上对子树序列进行测试, 从中选择最优子树\n\n\n\n\n\n\n","slug":"statistical-learning-method-5","published":1,"updated":"2019-01-28T01:59:45.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr7v000map3novxo4mub","content":"<h1 id=\"决策树\"><a href=\"#决策树\" class=\"headerlink\" title=\"决策树\"></a>决策树</h1><ul>\n<li>决策树是一种基本的分类与回归方法</li>\n<li>本质上是从训练数据集归纳出一组分类规则</li>\n<li>决策树学习通常包括三个步骤: 特征选择, 决策树的生成和决策树的修剪</li>\n<li>内部节点表示一个特征或属性, 叶节点表示一个类</li>\n</ul>\n<h2 id=\"决策树模型与学习\"><a href=\"#决策树模型与学习\" class=\"headerlink\" title=\"决策树模型与学习\"></a>决策树模型与学习</h2><ul>\n<li>损失函数通常是正则化的极大似然函数</li>\n<li>需要自下而上进行剪枝, 去掉过于细分的叶节点, 使其回退到父节点, 甚至更高的节点, 避免过拟合, 使其有更好的泛化能力</li>\n<li>决策树的生成只考虑局部最优, 决策树的生成则考虑全局最优</li>\n</ul>\n<h2 id=\"特征选择\"><a href=\"#特征选择\" class=\"headerlink\" title=\"特征选择\"></a>特征选择</h2><ul>\n<li>通常的特征选择的准则是信息增益或信息增益比</li>\n<li>熵(<strong>entropy</strong>): $\\displaystyle H(p) = \\sum_{i=1}^n p_i \\log p_i$</li>\n<li>条件熵(<strong>conditional entropy</strong>): $\\displaystyle H(Y|X) = \\sum_{i=1}^n p_i H(Y|X=x_i)$</li>\n<li>当熵和条件熵中的概率由数据估计(特别是极大似然估计得到)时, 所对应的熵与条件熵分别称为经验熵与经验条件熵</li>\n<li>信息增益表示得知特征$X$的信息而使得类$Y$的信息的不确定性减少的程度</li>\n<li>特征$A$对训练数据集$D$的信息增益$g(D,A) = H(D) - H(D|A)$, 也成为互信息(<strong>mutual information</strong>)</li>\n<li>信息增益比:<br>$$g_R (D,A) = \\frac{g(D,A)}{H_A(D)}$$<br>其中，$H_A (D)$表示训练数据集$D$关于特征$A$的值的熵<br>$$\\displaystyle H_A (D) = -\\sum_{i=1}^n \\frac{|D_i|}{D} \\log_2 \\frac{|D_i|}{D}$$</li>\n</ul>\n<h2 id=\"决策树的生成\"><a href=\"#决策树的生成\" class=\"headerlink\" title=\"决策树的生成\"></a>决策树的生成</h2><h3 id=\"ID3算法\"><a href=\"#ID3算法\" class=\"headerlink\" title=\"ID3算法\"></a>ID3算法</h3><blockquote>\n<p>输入: 训练数据集D, 特征集A, 阈值\\varepsilon<br>每次选择$ g(D,A) $最大的特征点递归构建, 直到所有特征的$g(D,A)$均很小($\\lt\\varepsilon$)或没有特征可以选择为止</p>\n</blockquote>\n<h3 id=\"C4-5算法\"><a href=\"#C4-5算法\" class=\"headerlink\" title=\"C4.5算法\"></a>C4.5算法</h3><ul>\n<li>用信息增益比来选择特征</li>\n</ul>\n<h2 id=\"决策树的剪枝\"><a href=\"#决策树的剪枝\" class=\"headerlink\" title=\"决策树的剪枝\"></a>决策树的剪枝</h2><ul>\n<li>损失函数: $C_\\alpha (T) = C(T) + \\alpha |T|$, 其中<br>$$\\displaystyle C(T) = \\sum_{t=1}^{|T|}N_t H_t (T) \\;\\;\\;\\;\\;  H_t (T) = -\\sum_k \\frac{N_{tk}}{N_t} \\log \\frac{N_{tk}}{N_t}$$<br>$N_{tk}$表示树$T$的某一叶节点$t$的第$k$类样本点的数量</li>\n<li>若一组叶节点回缩前后的树分别为$T_B$和$T_A$, 当$C_\\alpha (T_A) \\le C_\\alpha (T_B)$时进行剪枝, 将父节点变为新的叶节点</li>\n<li>利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择 </li>\n</ul>\n<h2 id=\"CART算法\"><a href=\"#CART算法\" class=\"headerlink\" title=\"CART算法\"></a>CART算法</h2><blockquote>\n<p>分类与回归树(Classification and Regression Trees)<br>递归构建二叉决策树再剪枝<br>具体见《统计学习方法》</p>\n</blockquote>\n<h3 id=\"CART生成\"><a href=\"#CART生成\" class=\"headerlink\" title=\"CART生成\"></a>CART生成</h3><ul>\n<li>回归树的生成: 用平方误差最小化准则, 最小二乘回归树生成算法</li>\n<li>分类树的生成: 用基尼系数选择最优特征, 同时决定该特征的最优二值切分点</li>\n</ul>\n<h3 id=\"CART剪枝\"><a href=\"#CART剪枝\" class=\"headerlink\" title=\"CART剪枝\"></a>CART剪枝</h3><ul>\n<li>首先从生成算法产生的决策树$T_0$底端开始不断剪枝, 直到$T_0$的根节点, 形成一个子树序列$\\lbrace T_0, T_1, \\cdots, T_n \\rbrace$;<br>然后通过交叉验证法再独立的验证数据集上对子树序列进行测试, 从中选择最优子树</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"决策树\"><a href=\"#决策树\" class=\"headerlink\" title=\"决策树\"></a>决策树</h1><ul>\n<li>决策树是一种基本的分类与回归方法</li>\n<li>本质上是从训练数据集归纳出一组分类规则</li>\n<li>决策树学习通常包括三个步骤: 特征选择, 决策树的生成和决策树的修剪</li>\n<li>内部节点表示一个特征或属性, 叶节点表示一个类</li>\n</ul>\n<h2 id=\"决策树模型与学习\"><a href=\"#决策树模型与学习\" class=\"headerlink\" title=\"决策树模型与学习\"></a>决策树模型与学习</h2><ul>\n<li>损失函数通常是正则化的极大似然函数</li>\n<li>需要自下而上进行剪枝, 去掉过于细分的叶节点, 使其回退到父节点, 甚至更高的节点, 避免过拟合, 使其有更好的泛化能力</li>\n<li>决策树的生成只考虑局部最优, 决策树的生成则考虑全局最优</li>\n</ul>\n<h2 id=\"特征选择\"><a href=\"#特征选择\" class=\"headerlink\" title=\"特征选择\"></a>特征选择</h2><ul>\n<li>通常的特征选择的准则是信息增益或信息增益比</li>\n<li>熵(<strong>entropy</strong>): $\\displaystyle H(p) = \\sum_{i=1}^n p_i \\log p_i$</li>\n<li>条件熵(<strong>conditional entropy</strong>): $\\displaystyle H(Y|X) = \\sum_{i=1}^n p_i H(Y|X=x_i)$</li>\n<li>当熵和条件熵中的概率由数据估计(特别是极大似然估计得到)时, 所对应的熵与条件熵分别称为经验熵与经验条件熵</li>\n<li>信息增益表示得知特征$X$的信息而使得类$Y$的信息的不确定性减少的程度</li>\n<li>特征$A$对训练数据集$D$的信息增益$g(D,A) = H(D) - H(D|A)$, 也成为互信息(<strong>mutual information</strong>)</li>\n<li>信息增益比:<br>$$g_R (D,A) = \\frac{g(D,A)}{H_A(D)}$$<br>其中，$H_A (D)$表示训练数据集$D$关于特征$A$的值的熵<br>$$\\displaystyle H_A (D) = -\\sum_{i=1}^n \\frac{|D_i|}{D} \\log_2 \\frac{|D_i|}{D}$$</li>\n</ul>\n<h2 id=\"决策树的生成\"><a href=\"#决策树的生成\" class=\"headerlink\" title=\"决策树的生成\"></a>决策树的生成</h2><h3 id=\"ID3算法\"><a href=\"#ID3算法\" class=\"headerlink\" title=\"ID3算法\"></a>ID3算法</h3><blockquote>\n<p>输入: 训练数据集D, 特征集A, 阈值\\varepsilon<br>每次选择$ g(D,A) $最大的特征点递归构建, 直到所有特征的$g(D,A)$均很小($\\lt\\varepsilon$)或没有特征可以选择为止</p>\n</blockquote>\n<h3 id=\"C4-5算法\"><a href=\"#C4-5算法\" class=\"headerlink\" title=\"C4.5算法\"></a>C4.5算法</h3><ul>\n<li>用信息增益比来选择特征</li>\n</ul>\n<h2 id=\"决策树的剪枝\"><a href=\"#决策树的剪枝\" class=\"headerlink\" title=\"决策树的剪枝\"></a>决策树的剪枝</h2><ul>\n<li>损失函数: $C_\\alpha (T) = C(T) + \\alpha |T|$, 其中<br>$$\\displaystyle C(T) = \\sum_{t=1}^{|T|}N_t H_t (T) \\;\\;\\;\\;\\;  H_t (T) = -\\sum_k \\frac{N_{tk}}{N_t} \\log \\frac{N_{tk}}{N_t}$$<br>$N_{tk}$表示树$T$的某一叶节点$t$的第$k$类样本点的数量</li>\n<li>若一组叶节点回缩前后的树分别为$T_B$和$T_A$, 当$C_\\alpha (T_A) \\le C_\\alpha (T_B)$时进行剪枝, 将父节点变为新的叶节点</li>\n<li>利用损失函数最小原则进行剪枝就是用正则化的极大似然估计进行模型选择 </li>\n</ul>\n<h2 id=\"CART算法\"><a href=\"#CART算法\" class=\"headerlink\" title=\"CART算法\"></a>CART算法</h2><blockquote>\n<p>分类与回归树(Classification and Regression Trees)<br>递归构建二叉决策树再剪枝<br>具体见《统计学习方法》</p>\n</blockquote>\n<h3 id=\"CART生成\"><a href=\"#CART生成\" class=\"headerlink\" title=\"CART生成\"></a>CART生成</h3><ul>\n<li>回归树的生成: 用平方误差最小化准则, 最小二乘回归树生成算法</li>\n<li>分类树的生成: 用基尼系数选择最优特征, 同时决定该特征的最优二值切分点</li>\n</ul>\n<h3 id=\"CART剪枝\"><a href=\"#CART剪枝\" class=\"headerlink\" title=\"CART剪枝\"></a>CART剪枝</h3><ul>\n<li>首先从生成算法产生的决策树$T_0$底端开始不断剪枝, 直到$T_0$的根节点, 形成一个子树序列$\\lbrace T_0, T_1, \\cdots, T_n \\rbrace$;<br>然后通过交叉验证法再独立的验证数据集上对子树序列进行测试, 从中选择最优子树</li>\n</ul>\n"},{"title":"《统计学习方法》六. 逻辑斯蒂回归与最大熵模型","date":"2018-11-11T08:54:25.000Z","mathjax":true,"_content":"\n\n逻辑斯蒂回归与最大熵模型\n=============================\n> 逻辑斯蒂回归(**logistic regression**)是统计学习中的经典**分类**方法\n> 最大熵是概率学习的一个准则, 将其推广到分类问题得到最大熵模型(**maximum entropy model**)\n> 两者都属于对数线性模型\n\n\n\n逻辑斯蒂回归\n-----------------------------\n+ 设$X$是连续随机变量, $X$服从逻辑斯蒂分布是指$X$具有下列分布函数和密度函数: \n$$ F(x) = P(X \\le x) = \\frac{1}{1+e^{-(x-\\mu)/\\gamma}} $$\n$$ f(x) = F'(x) = \\frac{e^{-(x-\\mu)/\\gamma}}{\\gamma(1+e^{-(x-\\mu)/\\gamma})^2} $$\n+ 该曲线是以点$(\\mu, \\frac{1}{2})$为中心堆成的$S$型曲线\n\n\n","source":"_posts/statistical-learning-method-6.md","raw":"---\ntitle: 《统计学习方法》六. 逻辑斯蒂回归与最大熵模型\ntags:\n  - 统计学习方法\n  - machine learning\n  - book\ncategories:\n  - 统计学习方法\ndate: 2018-11-11 16:54:25\nmathjax: true\n---\n\n\n逻辑斯蒂回归与最大熵模型\n=============================\n> 逻辑斯蒂回归(**logistic regression**)是统计学习中的经典**分类**方法\n> 最大熵是概率学习的一个准则, 将其推广到分类问题得到最大熵模型(**maximum entropy model**)\n> 两者都属于对数线性模型\n\n\n\n逻辑斯蒂回归\n-----------------------------\n+ 设$X$是连续随机变量, $X$服从逻辑斯蒂分布是指$X$具有下列分布函数和密度函数: \n$$ F(x) = P(X \\le x) = \\frac{1}{1+e^{-(x-\\mu)/\\gamma}} $$\n$$ f(x) = F'(x) = \\frac{e^{-(x-\\mu)/\\gamma}}{\\gamma(1+e^{-(x-\\mu)/\\gamma})^2} $$\n+ 该曲线是以点$(\\mu, \\frac{1}{2})$为中心堆成的$S$型曲线\n\n\n","slug":"statistical-learning-method-6","published":1,"updated":"2019-01-28T01:59:45.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr7x000oap3n9me2m15h","content":"<h1 id=\"逻辑斯蒂回归与最大熵模型\"><a href=\"#逻辑斯蒂回归与最大熵模型\" class=\"headerlink\" title=\"逻辑斯蒂回归与最大熵模型\"></a>逻辑斯蒂回归与最大熵模型</h1><blockquote>\n<p>逻辑斯蒂回归(<strong>logistic regression</strong>)是统计学习中的经典<strong>分类</strong>方法<br>最大熵是概率学习的一个准则, 将其推广到分类问题得到最大熵模型(<strong>maximum entropy model</strong>)<br>两者都属于对数线性模型</p>\n</blockquote>\n<h2 id=\"逻辑斯蒂回归\"><a href=\"#逻辑斯蒂回归\" class=\"headerlink\" title=\"逻辑斯蒂回归\"></a>逻辑斯蒂回归</h2><ul>\n<li>设$X$是连续随机变量, $X$服从逻辑斯蒂分布是指$X$具有下列分布函数和密度函数:<br>$$ F(x) = P(X \\le x) = \\frac{1}{1+e^{-(x-\\mu)/\\gamma}} $$<br>$$ f(x) = F’(x) = \\frac{e^{-(x-\\mu)/\\gamma}}{\\gamma(1+e^{-(x-\\mu)/\\gamma})^2} $$</li>\n<li>该曲线是以点$(\\mu, \\frac{1}{2})$为中心堆成的$S$型曲线</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"逻辑斯蒂回归与最大熵模型\"><a href=\"#逻辑斯蒂回归与最大熵模型\" class=\"headerlink\" title=\"逻辑斯蒂回归与最大熵模型\"></a>逻辑斯蒂回归与最大熵模型</h1><blockquote>\n<p>逻辑斯蒂回归(<strong>logistic regression</strong>)是统计学习中的经典<strong>分类</strong>方法<br>最大熵是概率学习的一个准则, 将其推广到分类问题得到最大熵模型(<strong>maximum entropy model</strong>)<br>两者都属于对数线性模型</p>\n</blockquote>\n<h2 id=\"逻辑斯蒂回归\"><a href=\"#逻辑斯蒂回归\" class=\"headerlink\" title=\"逻辑斯蒂回归\"></a>逻辑斯蒂回归</h2><ul>\n<li>设$X$是连续随机变量, $X$服从逻辑斯蒂分布是指$X$具有下列分布函数和密度函数:<br>$$ F(x) = P(X \\le x) = \\frac{1}{1+e^{-(x-\\mu)/\\gamma}} $$<br>$$ f(x) = F’(x) = \\frac{e^{-(x-\\mu)/\\gamma}}{\\gamma(1+e^{-(x-\\mu)/\\gamma})^2} $$</li>\n<li>该曲线是以点$(\\mu, \\frac{1}{2})$为中心堆成的$S$型曲线</li>\n</ul>\n"},{"title":"《统计学习方法》七. 支持向量机","date":"2018-11-12T01:50:36.000Z","mathjax":true,"_content":"\n\n支持向量机\n=======================\n> 支持向量机(**support vector machines SVM**)是一种二分类模型\n\n\n线性可分支持向量机与硬间隔最大化\n-----------------------\n+ 线性可分支持向量机\n> 给定线性可分的训练数据集, 通过间隔最大化或等价地求解相应的凸二次规划问题学习得到的分离超平面为 $$ w^\\ast \\cdot x + b^\\ast = 0 $$ 以及相应的分类决策函数 $$ f(x) = sign(w^\\ast \\cdot x + b^\\ast) $$ 称为线性可分支持向量机\n+ 函数间隔: \n> 对于给定的训练数据集$T$和超平面$(w,b)$, 定义超平面$(w,b)$关于样本点$(x_i, y_i)$的函数间隔为$$\\hat{\\gamma_i} = y_i(w\\dot x_i + b)$$\n> 定义超平面$(w,b)$关于训练数据集$T$函数间隔为超平面$(w,b)$关于$T$中所有样本点$(x_i, y_i)$的函数间隔之最小值, 即$$\\displaystyle \\hat{\\gamma} =  \\min_{i=1,2,\\cdots,N} \\hat{\\gamma_i}$$\n+ 几何间隔: $$\\gamma_i = y_i\\left(\\frac{w}{\\parallel w \\parallel} \\cdot x_i + \\frac{b}{\\parallel w \\parallel} \\right)$$ $$\\displaystyle \\gamma = \\min_{i=1,2,\\cdots,N} \\gamma_i$$\n+ 间隔最大化\n","source":"_posts/statistical-learning-method-7.md","raw":"---\ntitle: 《统计学习方法》七. 支持向量机\ntags:\n  - 统计学习方法\n  - machine learning\n  - book\ncategories:\n  - 统计学习方法\ndate: 2018-11-12 09:50:36\nmathjax: true\n---\n\n\n支持向量机\n=======================\n> 支持向量机(**support vector machines SVM**)是一种二分类模型\n\n\n线性可分支持向量机与硬间隔最大化\n-----------------------\n+ 线性可分支持向量机\n> 给定线性可分的训练数据集, 通过间隔最大化或等价地求解相应的凸二次规划问题学习得到的分离超平面为 $$ w^\\ast \\cdot x + b^\\ast = 0 $$ 以及相应的分类决策函数 $$ f(x) = sign(w^\\ast \\cdot x + b^\\ast) $$ 称为线性可分支持向量机\n+ 函数间隔: \n> 对于给定的训练数据集$T$和超平面$(w,b)$, 定义超平面$(w,b)$关于样本点$(x_i, y_i)$的函数间隔为$$\\hat{\\gamma_i} = y_i(w\\dot x_i + b)$$\n> 定义超平面$(w,b)$关于训练数据集$T$函数间隔为超平面$(w,b)$关于$T$中所有样本点$(x_i, y_i)$的函数间隔之最小值, 即$$\\displaystyle \\hat{\\gamma} =  \\min_{i=1,2,\\cdots,N} \\hat{\\gamma_i}$$\n+ 几何间隔: $$\\gamma_i = y_i\\left(\\frac{w}{\\parallel w \\parallel} \\cdot x_i + \\frac{b}{\\parallel w \\parallel} \\right)$$ $$\\displaystyle \\gamma = \\min_{i=1,2,\\cdots,N} \\gamma_i$$\n+ 间隔最大化\n","slug":"statistical-learning-method-7","published":1,"updated":"2019-01-28T01:59:45.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr7z000tap3nksjo0hd9","content":"<h1 id=\"支持向量机\"><a href=\"#支持向量机\" class=\"headerlink\" title=\"支持向量机\"></a>支持向量机</h1><blockquote>\n<p>支持向量机(<strong>support vector machines SVM</strong>)是一种二分类模型</p>\n</blockquote>\n<h2 id=\"线性可分支持向量机与硬间隔最大化\"><a href=\"#线性可分支持向量机与硬间隔最大化\" class=\"headerlink\" title=\"线性可分支持向量机与硬间隔最大化\"></a>线性可分支持向量机与硬间隔最大化</h2><ul>\n<li>线性可分支持向量机<blockquote>\n<p>给定线性可分的训练数据集, 通过间隔最大化或等价地求解相应的凸二次规划问题学习得到的分离超平面为 $$ w^\\ast \\cdot x + b^\\ast = 0 $$ 以及相应的分类决策函数 $$ f(x) = sign(w^\\ast \\cdot x + b^\\ast) $$ 称为线性可分支持向量机</p>\n</blockquote>\n</li>\n<li>函数间隔: <blockquote>\n<p>对于给定的训练数据集$T$和超平面$(w,b)$, 定义超平面$(w,b)$关于样本点$(x_i, y_i)$的函数间隔为$$\\hat{\\gamma_i} = y_i(w\\dot x_i + b)$$<br>定义超平面$(w,b)$关于训练数据集$T$函数间隔为超平面$(w,b)$关于$T$中所有样本点$(x_i, y_i)$的函数间隔之最小值, 即$$\\displaystyle \\hat{\\gamma} =  \\min_{i=1,2,\\cdots,N} \\hat{\\gamma_i}$$</p>\n</blockquote>\n</li>\n<li>几何间隔: $$\\gamma_i = y_i\\left(\\frac{w}{\\parallel w \\parallel} \\cdot x_i + \\frac{b}{\\parallel w \\parallel} \\right)$$ $$\\displaystyle \\gamma = \\min_{i=1,2,\\cdots,N} \\gamma_i$$</li>\n<li>间隔最大化</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"支持向量机\"><a href=\"#支持向量机\" class=\"headerlink\" title=\"支持向量机\"></a>支持向量机</h1><blockquote>\n<p>支持向量机(<strong>support vector machines SVM</strong>)是一种二分类模型</p>\n</blockquote>\n<h2 id=\"线性可分支持向量机与硬间隔最大化\"><a href=\"#线性可分支持向量机与硬间隔最大化\" class=\"headerlink\" title=\"线性可分支持向量机与硬间隔最大化\"></a>线性可分支持向量机与硬间隔最大化</h2><ul>\n<li>线性可分支持向量机<blockquote>\n<p>给定线性可分的训练数据集, 通过间隔最大化或等价地求解相应的凸二次规划问题学习得到的分离超平面为 $$ w^\\ast \\cdot x + b^\\ast = 0 $$ 以及相应的分类决策函数 $$ f(x) = sign(w^\\ast \\cdot x + b^\\ast) $$ 称为线性可分支持向量机</p>\n</blockquote>\n</li>\n<li>函数间隔: <blockquote>\n<p>对于给定的训练数据集$T$和超平面$(w,b)$, 定义超平面$(w,b)$关于样本点$(x_i, y_i)$的函数间隔为$$\\hat{\\gamma_i} = y_i(w\\dot x_i + b)$$<br>定义超平面$(w,b)$关于训练数据集$T$函数间隔为超平面$(w,b)$关于$T$中所有样本点$(x_i, y_i)$的函数间隔之最小值, 即$$\\displaystyle \\hat{\\gamma} =  \\min_{i=1,2,\\cdots,N} \\hat{\\gamma_i}$$</p>\n</blockquote>\n</li>\n<li>几何间隔: $$\\gamma_i = y_i\\left(\\frac{w}{\\parallel w \\parallel} \\cdot x_i + \\frac{b}{\\parallel w \\parallel} \\right)$$ $$\\displaystyle \\gamma = \\min_{i=1,2,\\cdots,N} \\gamma_i$$</li>\n<li>间隔最大化</li>\n</ul>\n"},{"title":"TPCH test scripts","date":"2018-11-19T03:10:07.000Z","mathjax":true,"_content":"\n\nUsage\n========================================\n\n```bash\ncd tpch/dbgen\ncp makefile.suite Makefile\n# modify the Makefile\n#  CC = gcc\n#  DATABASE = ORACLE\n#  MACHINE = LINUX\nmake\n./dbgen -h\n./dbgen -vf -s 1 \n```\n+ for postgresql\n```\nfind -name \"*.tbl\" | xargs sed -i \"s/|$//\"\n\n```\n\n\n","source":"_posts/tpch.md","raw":"---\ntitle: TPCH test scripts\ntags: \n  - tpch\ncategories:\n  - database\ndate: 2018-11-19 11:10:07\nmathjax: true\n---\n\n\nUsage\n========================================\n\n```bash\ncd tpch/dbgen\ncp makefile.suite Makefile\n# modify the Makefile\n#  CC = gcc\n#  DATABASE = ORACLE\n#  MACHINE = LINUX\nmake\n./dbgen -h\n./dbgen -vf -s 1 \n```\n+ for postgresql\n```\nfind -name \"*.tbl\" | xargs sed -i \"s/|$//\"\n\n```\n\n\n","slug":"tpch","published":1,"updated":"2019-01-28T01:59:45.382Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjrfpkr80000vap3nnk8ls238","content":"<h1 id=\"Usage\"><a href=\"#Usage\" class=\"headerlink\" title=\"Usage\"></a>Usage</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> tpch/dbgen</span><br><span class=\"line\">cp makefile.suite Makefile</span><br><span class=\"line\"><span class=\"comment\"># modify the Makefile</span></span><br><span class=\"line\"><span class=\"comment\">#  CC = gcc</span></span><br><span class=\"line\"><span class=\"comment\">#  DATABASE = ORACLE</span></span><br><span class=\"line\"><span class=\"comment\">#  MACHINE = LINUX</span></span><br><span class=\"line\">make</span><br><span class=\"line\">./dbgen -h</span><br><span class=\"line\">./dbgen -vf -s 1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>for postgresql<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find -name &quot;*.tbl&quot; | xargs sed -i &quot;s/|$//&quot;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Usage\"><a href=\"#Usage\" class=\"headerlink\" title=\"Usage\"></a>Usage</h1><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"built_in\">cd</span> tpch/dbgen</span><br><span class=\"line\">cp makefile.suite Makefile</span><br><span class=\"line\"><span class=\"comment\"># modify the Makefile</span></span><br><span class=\"line\"><span class=\"comment\">#  CC = gcc</span></span><br><span class=\"line\"><span class=\"comment\">#  DATABASE = ORACLE</span></span><br><span class=\"line\"><span class=\"comment\">#  MACHINE = LINUX</span></span><br><span class=\"line\">make</span><br><span class=\"line\">./dbgen -h</span><br><span class=\"line\">./dbgen -vf -s 1</span><br></pre></td></tr></table></figure>\n<ul>\n<li>for postgresql<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">find -name &quot;*.tbl&quot; | xargs sed -i &quot;s/|$//&quot;</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cjrfpkr6f0001ap3nr5sz4u7x","category_id":"cjrfpkr780005ap3noej2c7sh","_id":"cjrfpkr7t000iap3nd8e5hzfs"},{"post_id":"cjrfpkr700003ap3nr16do0jg","category_id":"cjrfpkr7o000cap3nxe35v7mh","_id":"cjrfpkr7y000qap3n22u4fr73"},{"post_id":"cjrfpkr7b0007ap3n28kht67z","category_id":"cjrfpkr7u000kap3nbouaqd0s","_id":"cjrfpkr81000wap3n7efh2wet"},{"post_id":"cjrfpkr7z000tap3nksjo0hd9","category_id":"cjrfpkr7y000rap3nie0djtyd","_id":"cjrfpkr850010ap3nyp7y3bnz"},{"post_id":"cjrfpkr7e0009ap3n7j81hphs","category_id":"cjrfpkr7y000rap3nie0djtyd","_id":"cjrfpkr860012ap3nupy0l4ke"},{"post_id":"cjrfpkr7n000bap3nzi6mbfzu","category_id":"cjrfpkr7y000rap3nie0djtyd","_id":"cjrfpkr880015ap3nbllhit0t"},{"post_id":"cjrfpkr7q000fap3nukat0q7e","category_id":"cjrfpkr7y000rap3nie0djtyd","_id":"cjrfpkr890018ap3ne1tuc646"},{"post_id":"cjrfpkr7s000hap3ncw4a88gq","category_id":"cjrfpkr7y000rap3nie0djtyd","_id":"cjrfpkr8b001cap3n0zrsdz8s"},{"post_id":"cjrfpkr7v000map3novxo4mub","category_id":"cjrfpkr7y000rap3nie0djtyd","_id":"cjrfpkr8d001hap3nsup9dps6"},{"post_id":"cjrfpkr7x000oap3n9me2m15h","category_id":"cjrfpkr7y000rap3nie0djtyd","_id":"cjrfpkr8e001jap3nja101uxw"},{"post_id":"cjrfpkr80000vap3nnk8ls238","category_id":"cjrfpkr8c001gap3nw22c7epr","_id":"cjrfpkr8f001map3nv20yalw6"}],"PostTag":[{"post_id":"cjrfpkr6f0001ap3nr5sz4u7x","tag_id":"cjrfpkr7b0006ap3nmdgvhzaf","_id":"cjrfpkr7w000nap3n9kv3ytvg"},{"post_id":"cjrfpkr6f0001ap3nr5sz4u7x","tag_id":"cjrfpkr7p000dap3nzz9wsg35","_id":"cjrfpkr7y000pap3nluhb5bl1"},{"post_id":"cjrfpkr700003ap3nr16do0jg","tag_id":"cjrfpkr7u000lap3nlhszvrku","_id":"cjrfpkr80000uap3n5zzr22lh"},{"post_id":"cjrfpkr7b0007ap3n28kht67z","tag_id":"cjrfpkr7y000sap3nos5aka42","_id":"cjrfpkr85000zap3ny0ef7f7m"},{"post_id":"cjrfpkr7e0009ap3n7j81hphs","tag_id":"cjrfpkr82000yap3nqb1ddo99","_id":"cjrfpkr8a001aap3nx1yewwlz"},{"post_id":"cjrfpkr7e0009ap3n7j81hphs","tag_id":"cjrfpkr870013ap3n1ods73co","_id":"cjrfpkr8b001dap3neu03lmop"},{"post_id":"cjrfpkr7e0009ap3n7j81hphs","tag_id":"cjrfpkr880016ap3nwbw27c14","_id":"cjrfpkr8c001fap3nixyqzp1r"},{"post_id":"cjrfpkr7n000bap3nzi6mbfzu","tag_id":"cjrfpkr82000yap3nqb1ddo99","_id":"cjrfpkr8f001lap3npla5efl4"},{"post_id":"cjrfpkr7n000bap3nzi6mbfzu","tag_id":"cjrfpkr870013ap3n1ods73co","_id":"cjrfpkr8f001nap3ny6c3mx3j"},{"post_id":"cjrfpkr7n000bap3nzi6mbfzu","tag_id":"cjrfpkr880016ap3nwbw27c14","_id":"cjrfpkr8g001pap3n7p5r0c7s"},{"post_id":"cjrfpkr7q000fap3nukat0q7e","tag_id":"cjrfpkr82000yap3nqb1ddo99","_id":"cjrfpkr8i001sap3nadme8rvj"},{"post_id":"cjrfpkr7q000fap3nukat0q7e","tag_id":"cjrfpkr870013ap3n1ods73co","_id":"cjrfpkr8i001tap3nmmbxn0st"},{"post_id":"cjrfpkr7q000fap3nukat0q7e","tag_id":"cjrfpkr880016ap3nwbw27c14","_id":"cjrfpkr8j001vap3nysl78g5y"},{"post_id":"cjrfpkr7s000hap3ncw4a88gq","tag_id":"cjrfpkr82000yap3nqb1ddo99","_id":"cjrfpkr8l001yap3np4rk8nin"},{"post_id":"cjrfpkr7s000hap3ncw4a88gq","tag_id":"cjrfpkr870013ap3n1ods73co","_id":"cjrfpkr8m001zap3n5cyv0p5w"},{"post_id":"cjrfpkr7s000hap3ncw4a88gq","tag_id":"cjrfpkr880016ap3nwbw27c14","_id":"cjrfpkr8n0021ap3nrgvfc75e"},{"post_id":"cjrfpkr7v000map3novxo4mub","tag_id":"cjrfpkr82000yap3nqb1ddo99","_id":"cjrfpkr8p0024ap3n2dsczhb6"},{"post_id":"cjrfpkr7v000map3novxo4mub","tag_id":"cjrfpkr870013ap3n1ods73co","_id":"cjrfpkr8p0025ap3ney595tnb"},{"post_id":"cjrfpkr7v000map3novxo4mub","tag_id":"cjrfpkr880016ap3nwbw27c14","_id":"cjrfpkr8q0027ap3nq9in6m4h"},{"post_id":"cjrfpkr7x000oap3n9me2m15h","tag_id":"cjrfpkr82000yap3nqb1ddo99","_id":"cjrfpkr8z002aap3nr0jeshps"},{"post_id":"cjrfpkr7x000oap3n9me2m15h","tag_id":"cjrfpkr870013ap3n1ods73co","_id":"cjrfpkr90002bap3nvqrk6r9f"},{"post_id":"cjrfpkr7x000oap3n9me2m15h","tag_id":"cjrfpkr880016ap3nwbw27c14","_id":"cjrfpkr91002dap3ngv02ertu"},{"post_id":"cjrfpkr7z000tap3nksjo0hd9","tag_id":"cjrfpkr82000yap3nqb1ddo99","_id":"cjrfpkr93002gap3nc2rhpxvy"},{"post_id":"cjrfpkr7z000tap3nksjo0hd9","tag_id":"cjrfpkr870013ap3n1ods73co","_id":"cjrfpkr93002hap3nf5at2wim"},{"post_id":"cjrfpkr7z000tap3nksjo0hd9","tag_id":"cjrfpkr880016ap3nwbw27c14","_id":"cjrfpkr94002iap3nh2mpx426"},{"post_id":"cjrfpkr80000vap3nnk8ls238","tag_id":"cjrfpkr93002fap3n82va3j3f","_id":"cjrfpkr94002jap3nikhi7flc"}],"Tag":[{"name":"paper reading","_id":"cjrfpkr7b0006ap3nmdgvhzaf"},{"name":"database","_id":"cjrfpkr7p000dap3nzz9wsg35"},{"name":"operating system","_id":"cjrfpkr7u000lap3nlhszvrku"},{"name":"scheduling algorithm","_id":"cjrfpkr7y000sap3nos5aka42"},{"name":"统计学习方法","_id":"cjrfpkr82000yap3nqb1ddo99"},{"name":"machine learning","_id":"cjrfpkr870013ap3n1ods73co"},{"name":"book","_id":"cjrfpkr880016ap3nwbw27c14"},{"name":"tpch","_id":"cjrfpkr93002fap3n82va3j3f"}]}}